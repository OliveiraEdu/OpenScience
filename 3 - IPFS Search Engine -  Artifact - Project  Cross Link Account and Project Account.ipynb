{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a1c5a2-75c3-482e-999c-70eb25226078",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from iroha import IrohaCrypto\n",
    "from iroha.ed25519 import H\n",
    "import integration_helpers\n",
    "from iroha.primitive_pb2 import can_set_my_account_detail\n",
    "import json\n",
    "from iroha_helper import *\n",
    "from new_helper import *\n",
    "from super_helper import *\n",
    "from ipfs_functions import *\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cad05321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for objects in both user account and project account JSON-LDs.\n",
    "json_ld_index = 1\n",
    "\n",
    "# Local path for file upload\n",
    "directory_path = \"upload\"\n",
    "\n",
    "# Directory for file downloads\n",
    "download_path = \"download\"\n",
    "\n",
    "# Read accounts from JSON-LD\n",
    "user_accounts = read_user_accounts_from_jsonld('datasets/accounts.json')\n",
    "project_accounts = read_project_accounts_from_jsonld('datasets/projects.json')\n",
    "\n",
    "#for the index system\n",
    "index_path = \"indexdir\"\n",
    "index = open_dir(index_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "089523ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customize the logger format\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sink=lambda msg: print(msg, end=\"\"),\n",
    "    format=\"<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | \"\n",
    "           \"<level>{level: <8}</level> | \"\n",
    "           \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - \"\n",
    "           \"{message}\",\n",
    "    colorize=True,  # Enable colors for supported terminals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14eaf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually resets the index on execution\n",
    "# recreate_index() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a043d51-4a22-4186-975e-7e3e8a4b54ef",
   "metadata": {},
   "source": [
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e6442fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:08:54.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m34\u001b[0m - \tEntering \"create_detail_contract\"\n",
      "\u001b[32m2025-01-13 23:08:54.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mcreate_detail_contract\u001b[0m:\u001b[36m55\u001b[0m - ('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "\u001b[32m2025-01-13 23:08:54.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mcreate_detail_contract\u001b[0m:\u001b[36m55\u001b[0m - ('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "\u001b[32m2025-01-13 23:08:56.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mcreate_detail_contract\u001b[0m:\u001b[36m55\u001b[0m - ('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "\u001b[32m2025-01-13 23:08:56.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mcreate_detail_contract\u001b[0m:\u001b[36m55\u001b[0m - ('COMMITTED', 5, 0)\n",
      "\u001b[32m2025-01-13 23:08:56.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m36\u001b[0m - \tLeaving \"create_detail_contract\"\n",
      "\u001b[32m2025-01-13 23:08:56.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m34\u001b[0m - \tEntering \"get_engine_receipts_result\"\n",
      "\u001b[32m2025-01-13 23:08:57.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mget_engine_receipts_result\u001b[0m:\u001b[36m92\u001b[0m - \n",
      "\u001b[32m2025-01-13 23:08:57.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m36\u001b[0m - \tLeaving \"get_engine_receipts_result\"\n"
     ]
    }
   ],
   "source": [
    "hash = create_detail_contract()\n",
    "integration_helpers.get_engine_receipts_result(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea1051-cb1c-4c29-97e5-38ba90248081",
   "metadata": {},
   "source": [
    "2 - Data extraction from JSON-LD.\n",
    "\n",
    "Extracts account ids from `datasets/accounts.json` and `datasets/projects.json`.\n",
    "\n",
    "Must update `json_ld_index` with a entry number related to an existing object in `datasets/accounts.json` and `datasets/projects.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e068d0-2247-4fd3-827f-4144b66965e1",
   "metadata": {},
   "source": [
    "4 - Sets details for both User and Project accounts providing a logical link between them for later references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1304dbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:08:57.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m34\u001b[0m - \tEntering \"get_engine_receipts_address\"\n",
      "\u001b[32m2025-01-13 23:08:57.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m36\u001b[0m - \tLeaving \"get_engine_receipts_address\"\n",
      "\u001b[32m2025-01-13 23:08:57.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m244\u001b[0m - \tEntering \"set_account_detail\"\n",
      "\u001b[32m2025-01-13 23:08:57.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m296\u001b[0m - None\n",
      "\u001b[32m2025-01-13 23:08:57.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "\u001b[32m2025-01-13 23:08:57.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "\u001b[32m2025-01-13 23:09:00.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "\u001b[32m2025-01-13 23:09:00.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('COMMITTED', 5, 0)\n",
      "\u001b[32m2025-01-13 23:09:00.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m246\u001b[0m - \tLeaving \"set_account_detail\"\n",
      "\u001b[32m2025-01-13 23:09:00.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m244\u001b[0m - \tEntering \"set_account_detail\"\n",
      "\u001b[32m2025-01-13 23:09:00.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m296\u001b[0m - None\n",
      "\u001b[32m2025-01-13 23:09:00.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "\u001b[32m2025-01-13 23:09:00.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "\u001b[32m2025-01-13 23:09:03.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "\u001b[32m2025-01-13 23:09:03.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('COMMITTED', 5, 0)\n",
      "\u001b[32m2025-01-13 23:09:03.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m246\u001b[0m - \tLeaving \"set_account_detail\"\n",
      "\u001b[32m2025-01-13 23:09:03.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mupdate_user_account_link\u001b[0m:\u001b[36m160\u001b[0m - Updated user account romantic_johnson@test with linked project 77323@test\n",
      "\u001b[32m2025-01-13 23:09:03.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mupdate_project_account_link\u001b[0m:\u001b[36m191\u001b[0m - Updated project account 77323@test with linked user romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:03.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - User account romantic_johnson@test linked to project 77323@test\n",
      "\u001b[32m2025-01-13 23:09:03.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - Project account 77323@test linked to user romantic_johnson@test\n"
     ]
    }
   ],
   "source": [
    "# Example execution of the previous snippet\n",
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "\n",
    "# Assuming json_ld_index is defined\n",
    "user_account = user_accounts[json_ld_index]\n",
    "project_account = project_accounts[json_ld_index]\n",
    "\n",
    "# Set project_id as a detail for the user account\n",
    "hash_user_to_project = set_account_detail(\n",
    "    address, \n",
    "    user_account['account_id'], \n",
    "    \"linked_project\", \n",
    "    project_account['account_id']\n",
    ")\n",
    "\n",
    "# Set user_account_id as a detail for the project account\n",
    "hash_project_to_user = set_account_detail(\n",
    "    address, \n",
    "    project_account['account_id'], \n",
    "    \"linked_user\", \n",
    "    user_account['account_id']\n",
    ")\n",
    "\n",
    "# Update the JSON-LD files with the linked details\n",
    "update_user_account_link(user_account['account_id'], project_account['account_id'])\n",
    "update_project_account_link(project_account['account_id'], user_account['account_id'])\n",
    "\n",
    "# Confirming the operation\n",
    "logger.info(f\"User account {user_account['account_id']} linked to project {project_account['account_id']}\")\n",
    "logger.info(f\"Project account {project_account['account_id']} linked to user {user_account['account_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562857c-d86d-42cf-a24b-23a5c3f5cb4e",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for User account and checks its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b52e47a4-b1c5-4ebe-a2d8-8edae10063d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:03.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - User Account id = {'account_id': 'romantic_johnson@test'}, { \"admin@test\" : { \"linked_project\" : \"77323@test\", \"user_json_ld_cid\" : \"QmdTLM5zBQe4CivjMxW5wXJMzErPo3qWXYvXgHHG3yTqbe\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=user_account['account_id'])\n",
    "# logger.info(query)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# logger.info(response)\n",
    "\n",
    "user_data = response.account_detail_response\n",
    "user_details = user_data.detail\n",
    "\n",
    "logger.info(f'User Account id = {user_account}, {user_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f33098-43df-47f3-8708-f3212dec1c0f",
   "metadata": {},
   "source": [
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "374843b3-6862-4a93-b298-1bdd0320c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:03.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - {'admin@test': {'linked_project': '77323@test', 'user_json_ld_cid': 'QmdTLM5zBQe4CivjMxW5wXJMzErPo3qWXYvXgHHG3yTqbe'}}\n",
      "\u001b[32m2025-01-13 23:09:03.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - 77323@test\n"
     ]
    }
   ],
   "source": [
    "# Process the account details response\n",
    "user_details_dict = json.loads(user_details)  # Convert the string to a JSON object\n",
    "logger.info(user_details_dict)\n",
    "\n",
    "# Now you can access the specific key like this\n",
    "project_id = user_details_dict[\"admin@test\"][\"linked_project\"]\n",
    "logger.info(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f06a221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:03.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - <Schema: ['abstract', 'created', 'creator', 'date', 'description', 'file_cid', 'format', 'full_text', 'language', 'metadata_cid', 'modified', 'project_id', 'publisher', 'subject', 'title']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:03.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m244\u001b[0m - \tEntering \"create_contract\"\n",
      "\u001b[32m2025-01-13 23:09:03.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mcreate_contract\u001b[0m:\u001b[36m263\u001b[0m - ('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "\u001b[32m2025-01-13 23:09:03.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mcreate_contract\u001b[0m:\u001b[36m263\u001b[0m - ('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "\u001b[32m2025-01-13 23:09:06.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mcreate_contract\u001b[0m:\u001b[36m263\u001b[0m - ('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "\u001b[32m2025-01-13 23:09:06.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mcreate_contract\u001b[0m:\u001b[36m263\u001b[0m - ('COMMITTED', 5, 0)\n",
      "\u001b[32m2025-01-13 23:09:06.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m246\u001b[0m - \tLeaving \"create_contract\"\n",
      "\u001b[32m2025-01-13 23:09:06.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m34\u001b[0m - \tEntering \"get_engine_receipts_address\"\n",
      "\u001b[32m2025-01-13 23:09:06.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mintegration_helpers\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m36\u001b[0m - \tLeaving \"get_engine_receipts_address\"\n",
      "\u001b[32m2025-01-13 23:09:06.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m244\u001b[0m - \tEntering \"set_account_detail\"\n",
      "\u001b[32m2025-01-13 23:09:06.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m296\u001b[0m - None\n",
      "\u001b[32m2025-01-13 23:09:06.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "\u001b[32m2025-01-13 23:09:06.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "\u001b[32m2025-01-13 23:09:09.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "\u001b[32m2025-01-13 23:09:09.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('COMMITTED', 5, 0)\n",
      "\u001b[32m2025-01-13 23:09:09.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m246\u001b[0m - \tLeaving \"set_account_detail\"\n",
      "\u001b[32m2025-01-13 23:09:09.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msetup_index\u001b[0m:\u001b[36m353\u001b[0m - Opened existing index.\n",
      "\u001b[32m2025-01-13 23:09:09.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mindex_metadata\u001b[0m:\u001b[36m212\u001b[0m - Metadata indexed successfully: Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\n",
      "\u001b[32m2025-01-13 23:09:09.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m244\u001b[0m - \tEntering \"set_account_detail\"\n",
      "\u001b[32m2025-01-13 23:09:09.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m296\u001b[0m - None\n",
      "\u001b[32m2025-01-13 23:09:09.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "\u001b[32m2025-01-13 23:09:09.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "\u001b[32m2025-01-13 23:09:12.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "\u001b[32m2025-01-13 23:09:12.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mset_account_detail\u001b[0m:\u001b[36m298\u001b[0m - ('COMMITTED', 5, 0)\n",
      "\u001b[32m2025-01-13 23:09:12.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36miroha_helper\u001b[0m:\u001b[36mtracer\u001b[0m:\u001b[36m246\u001b[0m - \tLeaving \"set_account_detail\"\n",
      "\u001b[32m2025-01-13 23:09:12.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msetup_index\u001b[0m:\u001b[36m353\u001b[0m - Opened existing index.\n",
      "\u001b[32m2025-01-13 23:09:12.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mindex_metadata\u001b[0m:\u001b[36m212\u001b[0m - Metadata indexed successfully: QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\n"
     ]
    }
   ],
   "source": [
    "schema = get_schema() #super_helper.py\n",
    "\n",
    "logger.info(schema)\n",
    "\n",
    "processed_data = process_files(directory_path, project_id, schema) #new_helper.py\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a01a3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:13.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - 77323@test, { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\", \"file_2\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\", \"linked_user\" : \"romantic_johnson@test\", \"project_metadata_cid\" : \"QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\" } }\n"
     ]
    }
   ],
   "source": [
    "account_detail = get_account_detail(project_id)\n",
    "logger.info(f\"{project_id}, {account_detail}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "192bca4c-e506-414d-aee5-f9a58ff3105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:13.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m230\u001b[0m - Starting keyword search...\n",
      "\u001b[32m2025-01-13 23:09:13.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m231\u001b[0m - Keyword: 'paper'\n",
      "\u001b[32m2025-01-13 23:09:13.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m242\u001b[0m - Search successful: Found 16 result(s).\n",
      "\u001b[32m2025-01-13 23:09:13.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 1. Project Id: 77323@test, File CID: QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, Metadata CID: QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9, Title: deep learning in insurance: accuracy and model interpretability using tabnet\n",
      "\u001b[32m2025-01-13 23:09:13.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 2. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmQvGdmxoDtMFN3ciARqKANbJ6EGsXowfncs59LKb356s4, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 3. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 4. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 5. Project Id: 77323@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 6. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmNf9v11kNmrrrFw58VdMnS7GAjdfss6aiBaVkKq4ghdn7, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 7. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmedM2sDbqRi5VmoWAUvwbuPrtSkLjHzYqor4FWK4223FV, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 8. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 9. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmTDECsHqEHEthrKVChmpeo1VXS1fpptph3EhLCMKZNxCy, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 10. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmcEd1CvbCB98BjtV48ufLfJXH6nkRkfhySonJddo4kXub, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 11. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: Qmda3UGvN1Ywmc2FkxuKSEHK8iy5vW5YrRFE9sqKKxdUVw, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 12. Project Id: 73243@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmNjaCTeNdmrJfLYUpD8qhpjndXXX7QrWagRMhNSAtQkC6, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 13. Project Id: 73243@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmdyAE132FSeSQaqUHzE5GtMrEwy821ScAYKEXsxpWSnV5, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 14. Project Id: 73243@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 15. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmWcdZFjgVaocJrPvDqKzf5KSFDcxypn5Ffyq9SNxQM1dN, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n",
      "\u001b[32m2025-01-13 23:09:13.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36msearch_index\u001b[0m:\u001b[36m244\u001b[0m - 16. Project Id: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ, Title: covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\n"
     ]
    }
   ],
   "source": [
    "# Perform a keyword search\n",
    "keyword = \"paper\"\n",
    "search_results, project_ids_with_cids = search_index(index, keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d09a150d-7e23-4e81-9b77-fa6febdc43c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:13.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 77323@test\n",
      "\u001b[32m2025-01-13 23:09:13.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q\n",
      "\u001b[32m2025-01-13 23:09:13.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\n",
      "\u001b[32m2025-01-13 23:09:13.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 77323@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\", \"file_2\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\", \"linked_user\" : \"romantic_johnson@test\", \"project_metadata_cid\" : \"QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q\n",
      "\u001b[32m2025-01-13 23:09:13.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q found under file_2.\n",
      "\u001b[32m2025-01-13 23:09:13.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 77323@test is {'is_valid': True, 'project_metadata_cid': 'QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7', 'linked_user': 'romantic_johnson@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 77323@test.\n",
      "\u001b[32m2025-01-13 23:09:13.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\n",
      "\u001b[32m2025-01-13 23:09:13.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:13.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\n",
      "\u001b[32m2025-01-13 23:09:13.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how gene therapy influences energy storage, providing insights into how to maximize its personalized medicine.', 'schema:endDate': '2028-06-19', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'National Geographic Society'}, 'schema:keywords': ['gene therapy', 'energy storage', 'personalized medicine'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Accra, Ghana'}, 'schema:name': 'Analyzing the Influence of gene therapy on energy storage', 'schema:startDate': '2018-10-29'}\n",
      "\u001b[32m2025-01-13 23:09:13.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:13.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmdTLM5zBQe4CivjMxW5wXJMzErPo3qWXYvXgHHG3yTqbe\n",
      "\u001b[32m2025-01-13 23:09:13.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'romantic_johnson@test', 'schema:publicKey': '6cc2015624b935cd3c7aed3b6848528bc4b841ad196c0dc0abdf0e8c84032626', 'schema:roleName': 'author'}, 'foaf:mbox': 'romantic_johnson@email.com', 'foaf:name': 'Romantic Johnson', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Paktia University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '1027-3561-0949-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\n",
      "\u001b[32m2025-01-13 23:09:13.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/77323@test\n",
      "\u001b[32m2025-01-13 23:09:13.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/77323@test/Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:13.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\n",
      "\u001b[32m2025-01-13 23:09:13.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '1697865', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '62', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Kevin McDonnell', 'Finbarr Murphy', 'Barry Sheehan', 'Leandro Masello', 'German Castignani'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en', 'dc:subject': ['Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543'], 'dc:title': 'Deep learning in insurance: Accuracy and model interpretability using TabNet', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T17:36:19Z', 'doi': '10.1016/j.eswa.2023.119543', 'meta:keyword': 'Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4694', '9144', '7582', '7133', '5283', '4337', '8096', '3645', '8070', '6797'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Kevin McDonnell', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119543', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'pdf:docinfo:modified': '2023-02-07T17:36:19Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543', 'pdf:docinfo:title': 'Deep learning in insurance: Accuracy and model interpretability using TabNet', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'true', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T17:36:19Z', 'xmp:ModifyDate': '2023-02-07T17:36:19Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '10'}\n",
      "\u001b[32m2025-01-13 23:09:13.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmQvGdmxoDtMFN3ciARqKANbJ6EGsXowfncs59LKb356s4\n",
      "\u001b[32m2025-01-13 23:09:13.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:13.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:13.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:13.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmQvGdmxoDtMFN3ciARqKANbJ6EGsXowfncs59LKb356s4\n",
      "\u001b[32m2025-01-13 23:09:13.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmQvGdmxoDtMFN3ciARqKANbJ6EGsXowfncs59LKb356s4\n",
      "\u001b[32m2025-01-13 23:09:13.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '149', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:13.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF\n",
      "\u001b[32m2025-01-13 23:09:13.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:13.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:13.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:13.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF\n",
      "\u001b[32m2025-01-13 23:09:13.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF\n",
      "\u001b[32m2025-01-13 23:09:13.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '134', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:13.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:13.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:13.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:13.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:13.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:13.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:13.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '122', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:13.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 77323@test\n",
      "\u001b[32m2025-01-13 23:09:13.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\n",
      "\u001b[32m2025-01-13 23:09:13.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 77323@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\", \"file_2\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\", \"linked_user\" : \"romantic_johnson@test\", \"project_metadata_cid\" : \"QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 77323@test is {'is_valid': True, 'project_metadata_cid': 'QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7', 'linked_user': 'romantic_johnson@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 77323@test.\n",
      "\u001b[32m2025-01-13 23:09:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\n",
      "\u001b[32m2025-01-13 23:09:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\n",
      "\u001b[32m2025-01-13 23:09:13.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how gene therapy influences energy storage, providing insights into how to maximize its personalized medicine.', 'schema:endDate': '2028-06-19', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'National Geographic Society'}, 'schema:keywords': ['gene therapy', 'energy storage', 'personalized medicine'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Accra, Ghana'}, 'schema:name': 'Analyzing the Influence of gene therapy on energy storage', 'schema:startDate': '2018-10-29'}\n",
      "\u001b[32m2025-01-13 23:09:13.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:13.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmdTLM5zBQe4CivjMxW5wXJMzErPo3qWXYvXgHHG3yTqbe\n",
      "\u001b[32m2025-01-13 23:09:13.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'romantic_johnson@test', 'schema:publicKey': '6cc2015624b935cd3c7aed3b6848528bc4b841ad196c0dc0abdf0e8c84032626', 'schema:roleName': 'author'}, 'foaf:mbox': 'romantic_johnson@email.com', 'foaf:name': 'Romantic Johnson', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Paktia University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '1027-3561-0949-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\n",
      "\u001b[32m2025-01-13 23:09:13.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/77323@test\n",
      "\u001b[32m2025-01-13 23:09:13.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/77323@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\n",
      "\u001b[32m2025-01-13 23:09:13.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '124', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:13.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmNf9v11kNmrrrFw58VdMnS7GAjdfss6aiBaVkKq4ghdn7\n",
      "\u001b[32m2025-01-13 23:09:13.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:13.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:13.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:13.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmNf9v11kNmrrrFw58VdMnS7GAjdfss6aiBaVkKq4ghdn7\n",
      "\u001b[32m2025-01-13 23:09:13.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmNf9v11kNmrrrFw58VdMnS7GAjdfss6aiBaVkKq4ghdn7\n",
      "\u001b[32m2025-01-13 23:09:13.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '128', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:13.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmedM2sDbqRi5VmoWAUvwbuPrtSkLjHzYqor4FWK4223FV\n",
      "\u001b[32m2025-01-13 23:09:13.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:13.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:13.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:13.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmedM2sDbqRi5VmoWAUvwbuPrtSkLjHzYqor4FWK4223FV\n",
      "\u001b[32m2025-01-13 23:09:13.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmedM2sDbqRi5VmoWAUvwbuPrtSkLjHzYqor4FWK4223FV\n",
      "\u001b[32m2025-01-13 23:09:13.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '110', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:13.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:13.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:13.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:13.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:13.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:13.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:13.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '122', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:13.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmTDECsHqEHEthrKVChmpeo1VXS1fpptph3EhLCMKZNxCy\n",
      "\u001b[32m2025-01-13 23:09:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:13.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:13.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:13.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmTDECsHqEHEthrKVChmpeo1VXS1fpptph3EhLCMKZNxCy\n",
      "\u001b[32m2025-01-13 23:09:13.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:13.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmTDECsHqEHEthrKVChmpeo1VXS1fpptph3EhLCMKZNxCy\n",
      "\u001b[32m2025-01-13 23:09:13.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '160', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:13.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:13.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:13.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmcEd1CvbCB98BjtV48ufLfJXH6nkRkfhySonJddo4kXub\n",
      "\u001b[32m2025-01-13 23:09:13.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:13.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:13.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:13.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:13.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:13.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:13.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:13.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:13.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:14.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmcEd1CvbCB98BjtV48ufLfJXH6nkRkfhySonJddo4kXub\n",
      "\u001b[32m2025-01-13 23:09:14.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmcEd1CvbCB98BjtV48ufLfJXH6nkRkfhySonJddo4kXub\n",
      "\u001b[32m2025-01-13 23:09:14.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '116', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:14.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:14.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: Qmda3UGvN1Ywmc2FkxuKSEHK8iy5vW5YrRFE9sqKKxdUVw\n",
      "\u001b[32m2025-01-13 23:09:14.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:14.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:14.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:14.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:14.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:14.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: Qmda3UGvN1Ywmc2FkxuKSEHK8iy5vW5YrRFE9sqKKxdUVw\n",
      "\u001b[32m2025-01-13 23:09:14.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: Qmda3UGvN1Ywmc2FkxuKSEHK8iy5vW5YrRFE9sqKKxdUVw\n",
      "\u001b[32m2025-01-13 23:09:14.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '132', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:14.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:14.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmNjaCTeNdmrJfLYUpD8qhpjndXXX7QrWagRMhNSAtQkC6\n",
      "\u001b[32m2025-01-13 23:09:14.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 73243@test is {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}.\n",
      "\u001b[32m2025-01-13 23:09:14.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 73243@test.\n",
      "\u001b[32m2025-01-13 23:09:14.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\n",
      "\u001b[32m2025-01-13 23:09:14.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:14.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\n",
      "\u001b[32m2025-01-13 23:09:14.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 23:09:14.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:14.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmS6HCQXDnFaZT4GJmR4Yv2j4vhdqRBdauXZYoazL3KKcf\n",
      "\u001b[32m2025-01-13 23:09:14.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmNjaCTeNdmrJfLYUpD8qhpjndXXX7QrWagRMhNSAtQkC6\n",
      "\u001b[32m2025-01-13 23:09:14.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmNjaCTeNdmrJfLYUpD8qhpjndXXX7QrWagRMhNSAtQkC6\n",
      "\u001b[32m2025-01-13 23:09:14.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '101', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:14.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:14.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmdyAE132FSeSQaqUHzE5GtMrEwy821ScAYKEXsxpWSnV5\n",
      "\u001b[32m2025-01-13 23:09:14.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 73243@test is {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}.\n",
      "\u001b[32m2025-01-13 23:09:14.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 73243@test.\n",
      "\u001b[32m2025-01-13 23:09:14.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\n",
      "\u001b[32m2025-01-13 23:09:14.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:14.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\n",
      "\u001b[32m2025-01-13 23:09:14.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 23:09:14.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:14.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmS6HCQXDnFaZT4GJmR4Yv2j4vhdqRBdauXZYoazL3KKcf\n",
      "\u001b[32m2025-01-13 23:09:14.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmdyAE132FSeSQaqUHzE5GtMrEwy821ScAYKEXsxpWSnV5\n",
      "\u001b[32m2025-01-13 23:09:14.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmdyAE132FSeSQaqUHzE5GtMrEwy821ScAYKEXsxpWSnV5\n",
      "\u001b[32m2025-01-13 23:09:14.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '121', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:14.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:14.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\n",
      "\u001b[32m2025-01-13 23:09:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 73243@test is {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}.\n",
      "\u001b[32m2025-01-13 23:09:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 73243@test.\n",
      "\u001b[32m2025-01-13 23:09:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\n",
      "\u001b[32m2025-01-13 23:09:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\n",
      "\u001b[32m2025-01-13 23:09:14.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 23:09:14.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:14.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmS6HCQXDnFaZT4GJmR4Yv2j4vhdqRBdauXZYoazL3KKcf\n",
      "\u001b[32m2025-01-13 23:09:14.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\n",
      "\u001b[32m2025-01-13 23:09:14.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\n",
      "\u001b[32m2025-01-13 23:09:14.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '133', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:14.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:14.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmWcdZFjgVaocJrPvDqKzf5KSFDcxypn5Ffyq9SNxQM1dN\n",
      "\u001b[32m2025-01-13 23:09:14.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:14.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:14.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:14.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:14.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:14.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmWcdZFjgVaocJrPvDqKzf5KSFDcxypn5Ffyq9SNxQM1dN\n",
      "\u001b[32m2025-01-13 23:09:14.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmWcdZFjgVaocJrPvDqKzf5KSFDcxypn5Ffyq9SNxQM1dN\n",
      "\u001b[32m2025-01-13 23:09:14.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '125', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:14.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n",
      "\u001b[32m2025-01-13 23:09:14.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - Processing Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m40\u001b[0m - Valid Result for 37355@test is {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}.\n",
      "\u001b[32m2025-01-13 23:09:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Valid File CID for 37355@test.\n",
      "\u001b[32m2025-01-13 23:09:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - Project Metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m54\u001b[0m - Processing project metadata CID: QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\n",
      "\u001b[32m2025-01-13 23:09:14.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - Processing linked user: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - User JSON-LD CID: QmasGHctfDbkzhaqebKGicpyDtVxhswtDaX99XpMnLvcXC\n",
      "\u001b[32m2025-01-13 23:09:14.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m76\u001b[0m - Processing metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:14.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Downloaded file metadata: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:14.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - file metadata: {'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'CreationDate--Text': '7th February 2023', 'CrossMarkDomains[1]': 'elsevier.com', 'CrossMarkDomains[2]': 'sciencedirect.com', 'CrossmarkDomainExclusive': 'true', 'CrossmarkMajorVersionDate': '2010-04-23', 'ElsevierWebPDFSpecifications': '7.0', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'X-TIKA:embedded_depth': '0', 'X-TIKA:parse_time_millis': '122', 'access_permission:assemble_document': 'true', 'access_permission:can_modify': 'true', 'access_permission:can_print': 'true', 'access_permission:can_print_degraded': 'true', 'access_permission:extract_content': 'true', 'access_permission:extract_for_accessibility': 'true', 'access_permission:fill_in_form': 'true', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:format': 'application/pdf; version=1.7', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'doi': '10.1016/j.eswa.2023.119549', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:PDFVersion': '1.7', 'pdf:annotationSubtypes': 'Link', 'pdf:annotationTypes': 'null', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'pdf:containsDamagedFont': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:encrypted': 'false', 'pdf:hasCollection': 'false', 'pdf:hasMarkedContent': 'false', 'pdf:hasXFA': 'false', 'pdf:hasXMP': 'true', 'pdf:num3DAnnotations': '0', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:totalUnmappedUnicodeChars': '0', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'robots': 'noindex', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'xmp:CreatorTool': 'Elsevier', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'xmpTPg:NPages': '16'}\n",
      "\u001b[32m2025-01-13 23:09:14.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m81\u001b[0m - file metadata JSON: None\n"
     ]
    }
   ],
   "source": [
    "# Check if there are no search results\n",
    "if not search_results:\n",
    "    logger.warning(f\"No search results found for keyword: '{keyword}'. Exiting the script.\")\n",
    "else:\n",
    "    # Process each dictionary in search results\n",
    "    for result_dict in search_results:\n",
    "        project_id = result_dict.get('project_id')\n",
    "        file_cid = result_dict.get('file_cid')\n",
    "        metadata_cid = result_dict.get('metadata_cid')\n",
    "\n",
    "        if not project_id or not file_cid or not metadata_cid:\n",
    "            logger.error(f\"Missing required data in result: {result_dict}\")\n",
    "            continue\n",
    "\n",
    "        # Log the retrieved project details\n",
    "        logger.info(f\"Processing Project ID: {project_id}\")\n",
    "        logger.info(f\"File CID: {file_cid}\")\n",
    "        logger.info(f\"Metadata CID: {metadata_cid}\")\n",
    "        # file_metadata_json = download_json_from_ipfs(metadata_cid)\n",
    "        # logger.info(\"file_metadata_json:\", file_metadata_json)\n",
    "        \n",
    "\n",
    "        # Fetch project details from the blockchain\n",
    "        project_details = get_account_detail(project_id)\n",
    "        if not project_details:\n",
    "            logger.error(f\"No project details found for Project ID: {project_id}.\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Fetched project details for {project_id}: {project_details}\")\n",
    "\n",
    "        # Parse blockchain data\n",
    "        try:\n",
    "            blockchain_data = json.loads(project_details)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"Error decoding project details JSON for {project_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Validate file CID and fetch project details\n",
    "        validation_result = fetch_project_details(file_cid, blockchain_data)\n",
    "        logger.info(f\"Valid Result for {project_id} is {validation_result}.\")\n",
    "        if validation_result[\"is_valid\"]:\n",
    "            project_metadata_cid = validation_result.get(\"project_metadata_cid\")\n",
    "            linked_user = validation_result.get(\"linked_user\")\n",
    "            file_metadata_cid = validation_result.get(\"metadata_cid\")\n",
    "            \n",
    "            # download_file(file_metadata_json, download_path, project_id, file_cid)\n",
    "\n",
    "            logger.info(f\"Valid File CID for {project_id}.\")\n",
    "            logger.info(f\"Project Metadata CID: {project_metadata_cid}\")\n",
    "            logger.info(f\"Linked User: {linked_user}\")\n",
    "\n",
    "            # Fetch and process metadata and user details\n",
    "            if project_metadata_cid:\n",
    "                logger.info(f\"Processing project metadata CID: {project_metadata_cid}\")\n",
    "                project_metadata = download_json_from_ipfs(project_metadata_cid)\n",
    "                logger.info(f\"Downloaded project metadata: {project_metadata}\")\n",
    "\n",
    "            if linked_user:\n",
    "                logger.info(f\"Processing linked user: {linked_user}\")\n",
    "                user_details = get_account_detail(linked_user)\n",
    "                try:\n",
    "                    user_details = json.loads(user_details)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(f\"Error decoding user details JSON for {linked_user}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                user_json_ld_cid = user_details.get(\"admin@test\", {}).get(\"user_json_ld_cid\", None)\n",
    "                if user_json_ld_cid:\n",
    "                    logger.info(f\"User JSON-LD CID: {user_json_ld_cid}\")\n",
    "                    user_metadata = download_json_from_ipfs(user_json_ld_cid)\n",
    "                    logger.info(f\"Downloaded user metadata: {user_metadata}\")\n",
    "                else:\n",
    "                    logger.warning(f\"User JSON-LD CID not found for linked user {linked_user}.\")\n",
    "            \n",
    "            if metadata_cid:\n",
    "                logger.info(f\"Processing metadata CID: {metadata_cid}\")\n",
    "                file_metadata = download_json_from_ipfs(metadata_cid)\n",
    "                file_metadata_json = download_file(file_metadata, download_path, project_id, file_cid)\n",
    "                logger.info(f\"Downloaded file metadata: {metadata_cid}\")\n",
    "                logger.info(f\"file metadata: {file_metadata}\")\n",
    "                logger.info(f\"file metadata JSON: {file_metadata_json}\")\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            logger.warning(f\"Invalid File CID for Project ID: {project_id}. Skipping metadata processing.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1e9bcdd-2f1c-4323-a2c3-686cf3c58b82",
   "metadata": {},
   "source": [
    "With Reusable Helper Function for Block Separation and Tracing\n",
    "\n",
    "A helper function, with_logging_block, which accepts a block name, the code block to execute, and optional parameters for context-specific tracing.\n",
    "\n",
    "Cleanly separates each logical block, improving readability, modularity, and error tracing.\n",
    "\n",
    "Includes the output of the search results explicitly logged within the Keyword Search block. This will ensure all search results are printed for visibility and debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e230d1d0-2265-4b8d-a7af-9c6b0d736d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 23:09:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Keyword Search\n",
      "\u001b[32m2025-01-13 23:09:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m45\u001b[0m - Total search results found for keyword 'paper': 16\n",
      "\u001b[32m2025-01-13 23:09:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - Listing all search results:\n",
      "\u001b[32m2025-01-13 23:09:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 1: Project ID: 77323@test, File CID: QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q\n",
      "\u001b[32m2025-01-13 23:09:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 2: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 3: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 4: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 5: Project ID: 77323@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 6: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 7: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 8: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 9: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 10: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 11: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 12: Project ID: 73243@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 13: Project ID: 73243@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 14: Project ID: 73243@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 15: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - Result 16: Project ID: 37355@test, File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m55\u001b[0m - Full search results for keyword 'paper':\n",
      "\u001b[32m2025-01-13 23:09:14.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 1: {\n",
      "  \"abstract\": \"\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\",\n",
      "  \"creator\": \"kevin mcdonnell, finbarr murphy, barry sheehan, leandro masello, german castignani\",\n",
      "  \"date\": \"\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543\",\n",
      "  \"file_cid\": \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDeep learning in insurance: Accuracy and model interpretability using TabNet\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\nAvailable online 13 January 2023\\n0957-4174/\\u00a9 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\\n\\nDeep learning in insurance: Accuracy and model interpretability \\nusing TabNet \\n\\nKevin McDonnell a,*, Finbarr Murphy a, Barry Sheehan a, Leandro Masello a,b, \\nGerman Castignani b,c \\n\\na KB3-040, Kemmy Business School, University of Limerick, Limerick V94 PH93, Ireland \\nb Motion-S S.A., Mondorf-les-Bains L-5610, Luxembourg \\nc University of Luxembourg, Esch-sur-Alzette L-4365, Luxembourg   \\n\\nA R T I C L E  I N F O   \\n\\nKeywords: \\nDeep Learning \\nTelematics \\nConnected Vehicles \\nInsurance \\nGeneral Linear Model \\nXGBoost \\nMachine Learning \\nExplainable AI \\n\\nA B S T R A C T   \\n\\nGeneralized Linear Models (GLMs) and XGBoost are widely used in insurance risk pricing and claims prediction, \\nwith GLMs dominant in the insurance industry. The increasing prevalence of connected car data usage in in-\\nsurance requires highly accurate and interpretable models. Deep learning (DL) models have outperformed \\ntraditional Machine Learning (ML) models in multiple domains; despite this, they are underutilized in insurance \\nrisk pricing. This study introduces an alternative DL architecture, TabNet, suitable for insurance telematics \\ndatasets and claim prediction. This approach compares the TabNet DL model against XGBoost and Logistic \\nRegression on the task of claim prediction on a synthetic telematics dataset. TabNet outperformed these models, \\nproviding highly interpretable results and capturing the sparsity of the claims data with high accuracy. However, \\nTabNet requires considerable running time and effort in hyperparameter tuning to achieve these results. Despite \\nthese limitations, TabNet provides better pricing models for interpretable models in insurance when compared to \\nXGBoost and Logistic Regression models.   \\n\\n1. Introduction \\n\\nThe increasing prevalence of connected car data and advancements \\nin Deep Learning (DL) has enhanced the ability to model driving \\nbehavior accurately. Profiling driver risk (e.g., aggressive driving \\nbehavior, context-related risk), in particular, has a societal benefit, \\nreducing accidents and emissions. Safer driving behavior can be \\nencouraged by using bespoke insurance products (i.e., dynamically \\npriced insurance based on driver competency) or feedback to the driver. \\nThese bespoke insurance products such as pay-as/how-you-drive are \\nbecoming more prevalent in the motor insurance industry as insurers use \\na combination of telematics and Machine Learning (ML) methods for \\nrisk pricing. Traditional risk pricing models, such as the Generalized \\nLinear Models (GLM), still dominate the insurance industry, particularly \\nwithin non-life lines of business. However, in order to truly capture the \\nrelationships between the ever-expanding universe of non-traditional \\ndata (e.g. telematics, satellite, machine vision) and actuarial pricing \\nresponses (e.g., claims frequency and severity), innovative pricing \\n\\nmechanisms must be used. The DL method\\u2019s capacity to model complex, \\nnon-linear data overcomes many of the limitations of traditional pricing \\nmodels. Although, despite the increase in computational capabilities \\nafforded by DL and the availability of highly detailed telematics data, DL \\nis underutilized in insurance risk pricing and accident prediction. This \\nresearch demonstrates the usage of an alternative DL architecture, \\n\\u2018TabNet\\u2019, in insurance risk classification. \\n\\nDeep Learning is an ML model architecture that combines or con-\\nnects multiple layers to learn from data. This multi-layered approach \\nallows each layer to learn specific traits of the presented data (Good-\\nfellow, Bengio, & Courville, 2016). Advancements in DL have led to \\nhighly accurate models, outperforming traditional ML methods in \\nnumerous domains, such as autonomous driving, natural language \\nprocessing, and marketing (Goodfellow et al., 2016). In addition, these \\nDL models can learn complex data structures with minimal effort in pre- \\nprocessing and feature engineering (LeCun, Bengio, & Hinton, 2015). \\nHowever, insurance risk prediction models underutilize DL due to their \\n\\u2018black-box\\u2019 theoretical design/framework. As a result, the explainability \\n\\n* Corresponding author. \\nE-mail addresses: Kevin.McDonnell@ul.ie (K. McDonnell), Finbarr.Murphy@ul.ie (F. Murphy), Barry.Sheehan@ul.ie (B. Sheehan), Leandro.Masello@ul.ie \\n\\n(L. Masello), German.Castignani@motion-s.com (G. Castignani).  \\n\\nContents lists available at ScienceDirect \\n\\nExpert Systems With Applications \\n\\njournal homepage: www.elsevier.com/locate/eswa \\n\\nhttps://doi.org/10.1016/j.eswa.2023.119543 \\nReceived 26 January 2022; Received in revised form 8 July 2022; Accepted 9 January 2023   \\n\\nmailto:Kevin.McDonnell@ul.ie\\nmailto:Finbarr.Murphy@ul.ie\\nmailto:Barry.Sheehan@ul.ie\\nmailto:Leandro.Masello@ul.ie\\nmailto:German.Castignani@motion-s.com\\nwww.sciencedirect.com/science/journal/09574174\\nhttps://www.elsevier.com/locate/eswa\\nhttps://doi.org/10.1016/j.eswa.2023.119543\\nhttps://doi.org/10.1016/j.eswa.2023.119543\\nhttps://doi.org/10.1016/j.eswa.2023.119543\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119543&domain=pdf\\nhttp://creativecommons.org/licenses/by/4.0/\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n2\\n\\nor interpretability of DL insurance models is difficult to obtain (Baecke & \\nBocca, 2017; Paefgen, Staake, & Thiesse, 2013), which implies a chal-\\nlenge in terms of regulatory issues. Despite the ability of DL models to \\nlearn complex data structures, Deep Networks generalize poorly on \\ntabular datasets compared with other Classical ML models such as \\nSupport Vector Machines, Logistic Regression and naive Bayes classifier \\n(Arik & Pfister, 2021). Restrictions applied to granular telematics \\ndatasets cause further complications for using DL in insurance, as \\nnascent regulation requires the anonymization and processing of raw \\ntelematics data, ensuing that tabular datasets are commonplace in in-\\nsurance (Masello et al., 2022; McDonnell et al., 2021; Sheehan, Murphy, \\nRyan, Mullins, & Liu, 2017). Another significant limitation to their \\nadoption in insurance is their complex overparameterized configura-\\ntions (W\\u00fcthrich, 2020). \\n\\nModels used for risk pricing need to be interpretable in insurance to \\nbe accepted by financial authorities (Bibal, Lognoul, de Streel, & Fre\\u0301nay, \\n2021). GLMs and Ensemble methods have proven effective in deter-\\nmining and quantifying risk for certain driving profiles and are regularly \\nused in insurance risk pricing (Ayuso, Guillen, & Nielsen, 2019; Shan-\\nnon, Murphy, Mullins, & Eggert, 2018; Wang & Xi, 2016; Wu, Zhang, & \\nDong, 2016). Additionally, GLMs are interpretable, a fundamental \\nproperty required to create premium pricing models for insurance \\n(Guelman, 2012). However, the performance of GLM can be constrained \\nby highly complex or high dimensional data, as the linear predictor \\ncannot accurately model high-dimensional covariate effects (Klein, \\nDenuit, Lang, & Kneib, 2014). Ensemble methods such as Random Forest \\nor XGBoost can learn complex data structures while also returning high \\nlevels of accuracy. However, these ensemble learning methods have \\ndrawbacks as complicated processes for both model-tuning and model \\ninterpretability can lead them to be unattractive for insurers (Pesantez- \\nNarvaez, Guillen, & Alcan\\u0303iz, 2019). For this reason, \\u2018black-box\\u2019 models \\nare unfavorable. \\n\\nThe limitations of GLM, XGBoost and DL can have varying implica-\\ntions for an insurer\\u2019s effectiveness in providing accurate pricing models \\nfor motor insurance. Additionally, both XGBoost and DL differ from GLM \\nin their ability to provide fully explainable and interpretable pricing \\nmodels, further limiting their usage. TabNet, a state-of-the-art DL ar-\\nchitecture, addresses the limitations of DL models. Arik and Pfister \\n(2021) introduced TabNet in their paper, citing comparative accuracy to \\nXGBoost. TabNet utilizes single deep learning, multi-step processing, \\nsequential attention, and gradient descent, creating an architecture that \\ndiffers from traditional DL while maintaining high accuracy and \\nproviding model interpretability. The combination of these design \\nchoices makes TabNet a suitable DL model for insurance risk pricing and \\naddresses the limitations of the other models. \\n\\nTo the best of our knowledge, this paper provides the first adoption \\nof TabNet (Arik & Pfister, 2021) for insurance risk classification via \\nclaims prediction. In this article, TabNet is compared against GLM and \\nXGBoost to demonstrate its effectiveness in accuracy, interpretability, \\nand minimizing effort in feature training. For completeness, an addi-\\ntional experiment introduces a LightGBM and Neural Network to test \\nTabNet\\u2019s predictive qualities. This state-of-the-art DL architecture pro-\\nvides highly efficient policyholder risk prediction for insurers, using a \\ncombination of connected car data and traditional policyholder data. \\nThe implications of using this novel approach allow insurers to price \\nindividual drivers on their driving performances better when compared \\nto traditional pricing models. \\n\\nGLMs have widespread adoption in insurance risk classification and \\npricing due to their ability to capture the parameterized relationship \\nbetween variables in driver risk classification and their response or ef-\\nfects (McCullagh & Nelder, 2019; Renshaw, 1994). The occurrence of \\nclaims or accidents is infrequent; therefore, distributions such as the \\nnormal distribution inadequately model these sparsely distributed ac-\\ncidents and claims. The GLM can vary its assumptions about the distri-\\nbutions of its response variables, allowing for the usage of distributions, \\nsuch as Poisson regression (Ma, Zhu, Hu, & Chiu, 2018), that can better \\n\\napproximate relationships between risk factors and accidents. Addi-\\ntionally, GLMs are highly interpretable due to the generalized form of \\ndistribution and link-function selection. Due to these generalized terms, \\ninteractions between weights and variables of the GLM on a dataset can \\nbe easily interpreted (Molnar, 2020). \\n\\nCombining classical policyholder data with telematics data has \\nincreased an insurer\\u2019s ability to price policies accurately. Verbelen, \\nAntonio, and Claeskens (2018) demonstrate the effectiveness of this \\napproach by combining these traditional factors with telematics data to \\npredict claims. The authors utilized a variant of the GLM, a Generalized \\nAdditive Model, to model risk effectively through telematics data. The \\nGLM model highlighted exposure or mileage as a primary contributing \\nfactor to a policyholder\\u2019s risk. Another variant of GLM, Poisson \\nRegression, also provided accurate risk profile predictions for Ma et al. \\n(2018). When combining traditional and telematics data, their GLM \\nmodel identified mileage, traveling at peak times, and driving behaviors \\nsuch as harsh braking as highly correlated with driver accidents. Addi-\\ntionally, their model identified speeding and relative speed as risk fac-\\ntors. Thus, GLM models can provide premium pricing models for \\ninsurers while also providing interpretable results, exposing significant \\nfeatures contributing to a policyholder\\u2019s risk. \\n\\nAlthough GLMs have proven effective at driver risk identification \\nand premium pricing, there are limitations to using these models. Linear \\npredictors find difficulty obtaining optimal solutions when learning \\nfrom complex or high-dimensional data; this results in a GLM ineffi-\\nciently capturing the correlations in the dataset leading to poor gener-\\nalization (Klein et al., 2014). This limitation implies that models, which \\nuse linear predictors, may be unsuitable for predicting risky behaviors \\nfrom high-dimensional telematics data. GLMs also require tedious \\nmanual pre-processing, feature engineering and model building pro-\\ncesses to extract the relevant correlations and covariate effects on crash \\ndata or claims data (Henckaerts, Antonio, Clijsters, & Verbelen, 2018). \\n\\nEnsemble ML algorithms have risen in popularity in the insurance \\ndomain. These machine learners can learn complex data structures, \\nreducing the need for extensive feature engineering and provide inter-\\npretable results for insurers (Guelman, 2012). Ensemble methods \\ncombine base classifiers to produce one optimal predictive model. For \\nexample, a decision tree is a tree-based structure algorithm used to \\npredict a class or value by learning simple decision rules. Singular de-\\ncision trees, however, are prone to overfitting and variable selection bias \\n(Quan & Valdez, 2018). Combining decision trees in an ensemble \\nmethod such as Random Forest or Gradient Boosting improves the \\nperformance of these base classifiers, reducing overfitting tendencies \\nand significantly improving the accuracy of these models. \\n\\nEnsemble methods used in driver behavior risk scoring have greatly \\nimproved risk pricing models\\u2019 prediction accuracy, outperforming GLMs \\non the same task. An important waypoint in advocating the value of \\nensemble methods in risk pricing is Guelman (2012), who compared \\nGLM and Gradient Boosted Trees (GBT) on driver risk classification. The \\nGBT model could outperform the GLM on risk pricing based on tradi-\\ntional risk factors and accident data. A comprehensive study by Noll, \\nSalzmann, and Wuthrich (2018) compared variants of ensemble \\nmethods against Neural Networks and GLM. The study showed that \\nensemble methods performed better than GLM when predicting claims \\non traditional pricing features. In particular, GBT outperformed Random \\nForest on the same dataset. Recent studies by Pesantez-Narvaez et al. \\n(2019) and Maillart (2021) combine the predictive power of ensemble \\nmethods with driver behavioral data. In Mailart\\u2019s paper, ensemble \\nmethods were compared against a GLM, providing accurate and \\nexplainable results while reducing the need for extensive preprocessing \\nand feature engineering. \\n\\nThere are limitations to using ensemble methods for insurance risk \\npricing. Ensemble methods have basic levels of interpretability; for an \\ninsurer, gaining sufficient levels of model interpretability for auditing or \\nfinancial regulatory purposes from these models is a complex task \\n(Henckaerts, Co\\u0302te\\u0301, Antonio, & Verbelen, 2021; Noll et al., 2018). \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n3\\n\\nEnsemble methods can also be challenging to train. The fine-tuning of \\nthe hyper-parameters can be a difficult task and, when compared to \\nsimpler models such as Logistic Regression, the reward for the additional \\neffort can sometimes be negligible (Pesantez-Narvaez et al., 2019). \\n\\nDL has drastically changed the landscape of natural language pro-\\ncessing, image recognition, and autonomous driving. However, these \\npowerful models have limited usage in insurance pricing and risk clas-\\nsifications tasks. DL is a multi-layered approach to learning, where each \\nlayer extracts latent features and updates connected nodes and weights \\naccording to their relevance to scoring (Goodfellow et al., 2016). A \\nmixture of feed-forward and backpropagation steps ensures that each \\nweight is adjusted accordingly between the hidden layers of the \\nnetwork, where each layer outputs a vector of learned salient features, \\nfeeding this output vector to the next layer. \\n\\nStudies employing DL models in insurance risk classification and \\npricing are limited. However, there is growing adoption of these highly \\naccurate models. Before the growth of DL models, numerous studies \\ntested the feasibility of DL in insurance risk pricing. Paefgen et al. (2013) \\ndemonstrated the effectiveness of DL in predicting accident risk from \\ntelematics data. The authors compare a DL model with Logistic \\nRegression and Decision Tree models. Although the DL model out-\\nperformed the other models in various metrics, Paefgen et al. (2013) \\nchose Logistic Regression as their favored choice due to the low inter-\\npretability of the DL model. In a similar study, Baecke and Bocca (2017) \\ncompared a DL model with a Random Forest and Logistic Regression \\nmodel on driver risk classification using telematics data. Like Paefgen \\net al. (2013), Baecke and Bocca (2017) also decided that the Logistic \\nRegression model was the best choice, although the DL outperformed \\nthe other models on various categories. In addition to the above studies, \\nnumerous authors introduced specially tailored DL models for insur-\\nance. For instance, in their comparative model study, (Noll et al., 2018) \\nintroduced a shallow, deep Neural Network (NN) architecture for DL on \\na telematics dataset for intended insurance use. (Noll et al., 2018) made \\nsignificant changes to the NN model, with the highest performance \\nachieved by introducing an exposure feature layer to the network, out-\\nperforming GLM and Ensemble methods on the task of claim prediction. \\nAn alternative DL architecture by (Siami, Naderpour, & Lu, 2021) cre-\\nates a three-step approach to driver behavior extraction for subsequent \\nrisk analysis. In their paper, (Siami et al., 2021) reduce the complexity of \\ntelematics data processing the data using a self-organizing map (SOM). \\nA 9-layer deep autoencoder extracts relevant features before a k-means \\nalgorithm clusters the dataset in the final two steps. The resulting \\nclusters identify specific risky driver behaviors or patterns contributing \\nto a driver\\u2019s overall risk. \\n\\nLearning from tabular data can be challenging for DL models to find \\nan optimal solution, as the sparse and heterogeneous tabular datasets \\nlimit the DL model\\u2019s ability to find an appropriate inductive bias (Arik & \\nPfister, 2021; Shavitt & Segal, 2018; Xu, Skoularidou, Cuesta-Infante, & \\nVeeramachaneni, 2019). Additionally, due to regulation, the limitation \\nof access to granular telematics data combined with low interpretability \\nis a crucial obstacle to the widespread adoption of DL models in insur-\\nance risk pricing (Baecke & Bocca, 2017; McDonnell et al., 2021; Paef-\\ngen et al., 2013). \\n\\nThis research extends on the works of Arik and Pfister (2021), \\nPaefgen et al. (2013), and Pesantez-Narvaez et al. (2019) by using a DL \\nmodel, TabNet, for insurance risk pricing. Furthermore, this research \\nprovides the first comparison of TabNet, ML and traditional insurance \\npricing models. TabNet for insurance pricing offers accuracy with high \\nmodel interpretability and reduced effort in data pre-processing. In \\naddition, this model is capable of predicting accidents by combining \\ntelematics data and insurance claims. The rest of this paper is organized \\nas follows: Section 2 describes the dataset and pre-processing steps, \\nSection 3 outlines the methodology, Section 4 and Section 5 discusses \\nthe results in detail; finally, Section 6 provides a conclusion and future \\nwork. \\n\\n2. Data \\n\\nThe dataset used in this study is a synthetic telematics dataset pro-\\nvided by So et al. (2021). This synthetic data is modeled on a real dataset \\nprovided by a Canadian insurer and generated using Synthetic Minority \\nOversampling Tech (SMOTE) and a feedforward Neural Network (NN) \\nfor data simulation. For evaluation purposes, the usage of Poisson and \\nGamma Regression ensures that the distribution of claims data links to \\nthe sparsity of actual data claims. \\n\\nThe dataset contains 100,000 data samples and 52 variables divided \\ninto three categories: Traditional data (Car age, Insured Age, gender), \\nTelematic data (total miles driven, harsh acceleration, harsh braking), \\nand Response Data (number of claims and aggregate number of claims). \\nThe breakdown of features per category is 11 Traditional Features, 39 \\ntelematics features, and 2 response variables. Table 1 contains a sum-\\nmary of the features and datatypes. \\n\\nThe response column within this dataset contains two variables, \\nNB_Claim and AMT_claim. As per Table 1, AMT_Claim is the aggregated \\nsum of claims paid out from the insurance company, and NB_Claim is the \\nnumber of claims made by a policyholder account. A driver with \\nNB_Claim = 1 and AMT_Claim<\\u20ac1,000 may indicate first-party damage \\nrather than a high-risk driver with third-party damages. Therefore, \\ndistinguishing between risky and non-risky drivers requires the creation \\nof a new response column. The definition of this new response variable \\n\\u2019ClaimYN\\u2019 is as follows: where NB_Claim > 1 & AMT_Claim >\\u20ac1,000, \\n\\nTable 1 \\nSummary and descriptions of Traditional and Telematic variables in synthetic \\ndataset (So et al., 2021).  \\n\\nCategory Feature Names Description Datatype \\n\\nTraditional Marital \\nInsured.sex \\nCar.use \\nRegion \\nTerritory \\n\\nMarital Status  \\n\\nGender: Male/Female \\nPrivate/Commute/Farmer/ \\nCommercial \\nRural/Urban \\nLocation of Vehicle \\n\\nCategorical \\n\\nDuration \\nInsured.age \\nCar.age \\nCredit.score \\nAnnual.miles. \\ndrive \\nYears.noclaims \\n\\nPolicy in days  \\n\\nAge in years \\nVehicle age in years \\nCredit score of Policyholder \\nExpected miles of driver \\nYears without claims \\n\\nNumerical \\n\\nTelematic Total.miles.driven \\nAvgdays.week \\nAccel.xxmiles* \\nBrake.xxmiles* \\nLeft.turn. \\nintensityxx* \\nRight.turn. \\nintensityxx* \\n\\nTotal Miles \\nMean aggregated days per week \\nHarsh Acc in mph (xx) per 1000 \\nmiles \\nHarsh Brake in mph (xx) per \\n1000 miles \\nLeft turn per 1000 miles with \\nintensity xx  \\n\\nRight turn per 1000 miles with \\nintensity xx \\n\\nNumerical  \\n\\nAnnual.pct.driven \\nPct.drive.(day) \\nPct.drive.xhrs \\nPct.drive.wkxxx*  \\n\\nPct.drive.rushxx* \\n\\nAnnual percentage for time on \\nroad  \\n\\nDriving percentage for a given \\nday of week \\nHours of driving percentage for \\nhourly period \\nDriving percentage for a given \\nwk(end/day)  \\n\\nDriving percentage during rush \\nhour (am/pm) \\n\\nPercentage \\n\\nResponse NB_Claim \\nAMT_Claim \\nClaimYN** \\n\\nNum of policy claims \\nTotal claims amount \\nRisky drivers \\n\\nNumerical \\n\\n*xx values pre-defined buckets of values rather than random variables. \\n**Newly created variables, not in original dataset. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n4\\n\\nClaimYN = 1 (driver is a risk) else ClaimYn = 0 (driver is not a risk). \\nCreating the response variables as per the above definition yields 97,302 \\nClaimYN = 0 and 2698 ClaimYN = 1 values. \\n\\n3. Methodology \\n\\nThe following section describes the approach of classifying driver \\nrisk using driver behavioral data from telematics and comparing the \\nperformance of TabNet against GLM and XGBoost. Driver features are \\ndefined as x0, x1,\\u22ef, xn, where x is a driver\\u2019s feature (e.g. harsh accel-\\neration event, harsh braking event, distance traveled) and n is the total \\nnumber of features in the dataset. The target variable ClaimYN, for risk \\nclassification, is defined in section 2. \\n\\nTo demonstrate the intrinsic benefits of TabNet as a suitable risk \\npricing model, TabNet needs to achieve comparable or better perfor-\\nmance than traditional risk insurance models GLM & XGBoost. This \\nstudy\\u2019s evaluation of TabNet compares TabNet\\u2019s accuracy, model \\ninterpretability, and the reduced need for involved feature engineering \\nprocesses. Comparing the accuracy of each model will use additional \\nscoring metrics to gain further insights into each model\\u2019s predictive \\nprowess. These scoring metrics are: F1-Score, Precision, Recall, Area \\nUnder the Curve (AUC), Receiver Operating Characteristic (ROC), ac-\\ncuracy and Matthew\\u2019s Correlation Coefficient. Evaluation of model \\ninterpretability requires each model to provide clear and insightful de-\\nscriptions of data trends and identify reasonable significant risk factors. \\nAdditionally, three levels of pre-processing requirements evaluate each \\nmodel\\u2019s ability to provide accurate results with different levels of pre- \\nprocessing effort. Models, which require less effort to provide accurate \\nresults, indicate to insurers the model\\u2019s suitability for usage. Table 2 \\ncontains a summary of the evaluation methods used in this study. \\n\\n3.1. TabNet \\n\\nTabNet is a single deep learning model based on sequential multistep \\nprocessing (Arik & Pfister, 2021). This single deep architecture assists in \\nfeature selection and improves the capacity to learn high-dimensional \\nfeatures. Each nth step processes a D-dimensional feature vector, \\nwhere each step outputs to a Feature Transformer block. This Feature \\nTransformer block contains multiple layers, either shared across deci-\\nsion steps or unique to a decision step. Each block contains fully- \\nconnected layers, a batch normalization layer, and a Gated Liner Unit \\n(GLU) activation. Additionally, the GLU connects to a normalization \\n\\nresidual connection; this helps stabilize the variance throughout the \\nnetwork. This multi-layered block assists in feature selection and in-\\ncreases the parameter efficiency of the network. Fig. 1 provides a \\ndetailed description of TabNet architecture. \\n\\nThe Feature Transformer connects to the Attentive Transformer and \\nMask; these processes ensure robust feature selection per step. The \\nAttentive Transformer is a multi-layered block with fully connected and \\nbatch normalization layers. The Attentive Transformer and masking \\nprocedure is formulated by \\n\\na[i \\u2212 1] : M[i] = sparsemax(P[i \\u2212 1].hi([a \\u2212 1])) (1)  \\n\\nwhere a[i \\u2212 1] is the previous step, P[i] is the priori scale and hi some \\ntrainable function. Two key elements of the Attentive Transformer are \\nthe sparsemax activation function and the prior. Sparsemax reduces \\ndimensionality by introducing sparsity into feature vectors; and then \\nprojecting these features onto a probability map in Euclidean space. \\nEach projected feature vector now has an associated probability, \\nassisting in model interpretability. The prior scale term, P[i], denotes the \\nsaliency of a feature throughout the previous steps and is defined as \\n\\nP[i] = \\u03a0i\\nj=1(\\u03b3 \\u2212 M[j]) (2)  \\n\\nwhere \\u03b3 defines the relationship between enforcement of a feature at one \\ndecision step or multiple steps. When \\u03b3 = 1 the feature is enforced at the \\ngiven step and multiple steps when \\u03b3 = 0. The Attentive Transformer \\nselects the most salient features to form the transformed feature vector \\nand passes these features to the learnable Mask, M[j]. The Mask enables \\ninterpretability and further improves upon feature selection from the \\nAttentive Transformer. Mbj[i] defines the jth feature of the bth sample; \\nwhen Mbj[i] = 0, there is no contribution from the feature at that step. \\nAggregating these Masks at each step creates a coefficient that weights \\nthe importance of each step in a final decision. \\n\\nTabNet can provide both local and global model interpretability, \\nwith local interpretability an intrinsic element in TabNet\\u2019s design. \\nGlobal interpretability is obtained through the Python library Scikit- \\nlearn (Pedregosa et al., 2011), while local interpretability is obtained \\nby accessing TabNet\\u2019s decision masks. Each mask scores features, which \\ncontributed to the model decision at that step, and each step produces a \\nmask. TabNet is available through PyTorch version 3.1.1 (Pytorch- \\nTabnet, 2021). \\n\\n3.2. XGBoost \\n\\nExtreme Gradient Boosting (XGBoost) is an ensemble boosting tree \\nalgorithm. This fast and efficient ML algorithm can outperform other ML \\nmodels in accuracy, speed, and efficiency (Chen & Guestrin, 2016). \\nBoosting is an inherent feature of XGBoost, where previous weak \\nlearners are boosted by creating new models. These models are com-\\nbined to make a final prediction. Gradient descent is used during the \\nnew model creation process to minimize the loss. XGBoost deviates from \\nboost or gradient boosting through the incorporation of regularization \\n(Lasso & Ridge Regression), tree creation parallelization, and tree \\npruning (after the tree has grown to max depth, start from the bottom \\nand traverse up pruning invalid decisions). This approach uses featur-\\ne_importances to return global model interpretability in XGBoost. \\n\\n3.3. GLm \\n\\nThe GLM model is a generic form of the linear model. Unlike the \\nLinear Regression model, GLM does not make assumptions on the dis-\\ntribution of the trainable data. For example, a normal distribution does \\nnot accurately represent sparsity in claims data. The correct choice of \\ndistribution and link-function is necessary to provide accurate pre-\\ndictions of risk. The GLM model can be formally defined as follows \\n\\ng(EY(y \\u2228 x)) = \\u03b20 + \\u03b21x1 +\\u22ef+ \\u03b2pxp (3) \\n\\nTable 2 \\nSummary of the evaluation methods used in this study. Model \\nevaluation is divided into three categories, Scoring, Interpret-\\nability and Pre-processing. Scoring refers to model performance \\nmetrics such as F1-score or accuracy. Using the pre-processing \\nmethods listed, a high-scoring model with minimal user involve-\\nment indicates a good choice for an insurer. A model is highly \\ninterpretable if it can provide global and local interpretability and \\ninsights into telematics data using the interpretability methods.  \\n\\nCategory Method \\n\\nScoring F1-Score  \\n\\nPrecision \\nRecall \\nAccuracy \\nAUC \\nROC \\n\\nInterpretability Feature Importance  \\n\\nExplain Matrix \\nPre-Processing Data Normalization \\n\\nData Standardization  \\n\\nHyper-parameter tuning \\nFeature Engineering  \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n5\\n\\nwhere g defines the link function and EY the probability distribution. The \\nchoice of GLM for this study is the Logistic Regression model. Scikit- \\nlearn\\u2019s implementation of Logistic Regression does not contain the \\nfeature_importances attribute; instead, the regression coefficients were \\nused which reflect whether a feature contributed to the negative case (e. \\ng., \\u2018ClaimYN = 0\\u2032, if coefficient < 0); conversely, positive values indicate \\nthe positive case (e.g., \\u2018ClaimYN = 1\\u2032, if coefficient > 0). \\n\\n3.4. Pre-processing level 1\\u20133 \\n\\nTo demonstrate how using a DL model such as TabNet reduces the \\nneed for involved model building and feature engineering, TabNet is \\ncompared against XGBoost and GLM testing various degrees of pre- \\nprocessing. The initial test restricts the capabilities of the GLM, \\nXGBoost, and TabNet models by passing raw data to each model and \\nrunning with the default hyperparameters. The only pre-processing that \\noccurs in this step is simply encoding categorical columns. The purpose \\nof this restricted test run is to document each model\\u2019s performance with \\nlimited effort in pre-processing. Subsequent levels of testing require \\nmore involved pre-processing, feature engineering, and model building \\nsteps. The second level of pre-processing involves scaling and data \\nnormalization, along with minor model hyperparameter tuning. Data \\nnormalization for this step is simply StandardScaler and MinMaxScaler. \\n\\nThe final level requires more involved feature engineering and model \\nbuilding steps. Standardization and normalization steps continue from \\nthe previous level. The features Accel.xxmiles, Brake.xxmiles, Left.turn. \\nintensityxx and Right.turn.intensityxx, signifies harsh driving events. \\nThese values are highly correlated and will benefit from being aggre-\\ngated. Therefore, aggregating related harsh driving events to assist in \\nthis step\\u2019s feature engineering requirement. The optimal hyper-\\nparameters for each model were extracted using RandomizedSearchCV \\nwith 10-fold-cross validation. \\n\\nThis study introduces a state-of-the-art model, LightGBM, and a \\nNeural Network (NN) in a final test to determine the robustness of \\nTabNet\\u2019s ability to predict claims. The LightGBM and NN undergo the \\nsame training and testing processes described in 3.4. In addition, the \\nLightGBM model requires a similar setup to the XGBoost in hyper-\\nparameter tuning. The NN, however, requires more involved tuning due \\n\\nto configuration requirements for hidden and dropout layers and nodes. \\nThis final test for completeness provides an additional endorsement for \\ndetermining TabNet\\u2019s suitability for real-life insurance uses. \\n\\n4. Results \\n\\nThe following section describes the performance of TabNet \\ncompared with GLMs and XGBoost for both Classification and Regres-\\nsion tasks. For each round of model fitting and evaluation, an 80/20 split \\nof training and test dataset combined with 10-fold cross-validation \\nensure the integrity of each model\\u2019s performance metrics. \\n\\nTable 3 illustrates each model\\u2019s returned accuracy per level. Each \\nmodel scores high accuracy for each level; however, due to the sparsity \\nof driver claims, i.e., relatively few claims in the data, this metric can be \\n\\nFig. 1. Architecture of TabNet. Each step contains an attentive transformer, mask, feature transformer, split node and ReLu activation. Steps are sequential, \\nincreasing up to N steps before connecting to a fully connected layer and the output. Attentive Transformer contains a fully connected layer, batch normalization, \\nprior scale and sparsemax dimensionality reduction. The mask function outputs significant feature contributions for aggregation. When Mb,j[i] = 0, there is no feature \\ncontribution. \\n\\nTable 3 \\nReturned results for each model per level of preprocessing. Compared to \\nXGBoost and Logistic Regression, TabNet scores highest in F1-Score in three out \\nof two levels. Additionally, the model returns the highest Recall values overall. \\nXGBoost scores highest in precision and AUC in all three rounds of testing. Lo-\\ngistic Regression is the worst performing model of the three. Each model returns \\na high accuracy value. However, high accuracy does not sufficiently represent \\nthe performance of each model in predicting claims, as demonstrated by the \\nvarying F1, Precision, Recall and AUC values. Therefore, Matthews Correlation \\nCoefficient can assist in determining model performance on an unbalanced \\ndataset. XGBoost and TabNet score relatively closely using this metric, although \\nXGBoost edges TabNet in two out of three rounds.  \\n\\nModel Performance \\n\\nLevel Model Precision Recall F1- \\nScore \\n\\nAUC Accuracy M \\nCorr \\n\\n1 TabNet  0.55  0.20  0.30  0.86  0.97  0.32 \\nLR  0.11  0.00  0.00  0.73  0.97  0.01 \\nXGB  0.85  0.19  0.31  0.90  0.98  0.34 \\n\\n2 TabNet  0.66  0.53  0.59  0.88  0.98  0.58 \\nLR  0.25  0.00  0.00  0.81  0.97  0.01 \\nXGB  0.85  0.37  0.51  0.91  0.98  0.54 \\n\\n3 TabNet  0.66  0.55  0.60  0.87  0.98  0.59 \\nLR  0.33  0.00  0.01  0.80  0.97  0.03 \\nXGB  0.88  0.42  0.57  0.91  0.98  0.6 \\n\\nM Corr = Matthews Correlation, LR = Logistic Regression, XGB = XGBoost. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n6\\n\\nmisleading if a simple model only predicts no crash events. For this \\nreason, f1-score, precision, recall, AUC, ROC and Matthews Correlation \\nCoefficient are considered valuable metrics for model assessment. When \\ncomparing the three models\\u2019 scores, TabNet returns the highest F1-Score \\nfor all three levels of testing, also having the highest recall scores for two \\nout of three levels. Additionally, TabNet provides the most balanced set \\nof results compared to the two other models. In contrast, XGBoost has \\nreturned the highest Precision and AUC score. Both TabNet and XGBoost \\nhave comparable performance with Matthews Correlation, with \\nXGBoost scoring higher in the first round. Logistic Regression performs \\npoorly throughout the testing, failing to predict potential claims or ac-\\ncidents accurately. Fig. 2 summarizes each model\\u2019s performance for \\nAUC and ROC. \\n\\nAs per the methodology, each round of testing requires minimal to \\ninvolved preprocessing steps. For the second round of testing, XGBoost \\nrequired only two changes to its hyperparameters to improve its per-\\nformance, while TabNet required three, including an increase in epochs. \\nAs a result, the running time for TabNet doubled. Tuning the hyper-\\nparameters of Logistic Regression had little impact on the model per-\\nformance, with a marginal increase in precision recorded for the model. \\nFinally, RandomizedSearchCV was used to improve each model\\u2019s score \\nby selecting hyperparameters randomly in a given range, and the best \\nscore for a set of hyperparameters was retained. The optimal parameter \\nselection had minimal impact on TabNet\\u2019s and Logistic Regression\\u2019s \\nmodel performance, although XGBoost improved from the parameter \\ntuning. Tuning TabNet\\u2019s scores via RandomizedSearchCV was difficult \\n\\ndue to a substantial increase in model running time, and the scope of the \\nrandom search was severely limited. Despite the attempts to improve the \\nLogistic Regression score, the model still fails to identify driver risk from \\nthe dataset. In a final test for completeness, TabNet underwent addi-\\ntional analysis against a LightGBM and NN. The LightGBM and NN \\nprovided disappointing results despite the increased efforts required for \\ntraining. The LightGBM and NN failed to score higher than 0.2 in f1- \\nscore and Matthew\\u2019s Correlation coefficient, respectively. \\n\\nModel interpretability is a core component in analyzing and evalu-\\nating each model\\u2019s performance in this study. Comparing each model\\u2019s \\nfeature importance and model coefficients gives insight into model de-\\ncisions. Table 4 contains a detailed breakdown of each model\\u2019s returned \\nfeature importances. The NN and LightGBM tests did not introduce \\nsignificant insights into model decisions not already captured by Tab-\\nNet, XGBoost or Logistic Regression. As expected, extracting informa-\\ntion from the NN, in particular, proved a difficult challenge. \\n\\nTabNet can return the decision mask used internally for decision- \\nmaking, enabling further insight into local model interpretability. For \\nexample, the first mask returned from the model shows that both \\ntraditional and telematics variables contribute to model decisions at a \\nlocal level, with Right.turn.intensity11 scoring highly. Subsequent \\nmasks signify that Total.miles.driven, Accel.09miles and Duration have \\ncontributed to the model decision at a particular step. The internal mask \\nis an inherent property of TabNet; therefore, accessing and using this \\nproperty is easy. Comparing similar functionality with XGBoost and \\nother ML models, TabNet excels at providing in-depth model analytics \\n\\nFig. 2. AUC and ROC curves for each model per level of testing. XGBoost consistently returns the highest AUC values. However, as per the Precision-Recall Curve, \\nTabNet returns the most balanced recall/precision values, while XGBoost scores low in recall and high in precision consistently. Additionally, TabNet scores highest \\nin f1-score for levels two and three despite decreasing precision. Logistic Regression performs slightly better than no skill for Precision and Recall but still maintains a \\nhigh AUC score. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n7\\n\\nwithout additional software. In this study, only Logistic Regression\\u2019s \\nmodel coefficients match the ease of providing these interpretable re-\\nsults. Fig. 3 presents each mask per level of testing. \\n\\nTable 5 contains a summation of each model\\u2019s key attributes and \\nfeature interpretability capabilities. \\n\\n5. Discussion \\n\\nAs per the results presented in Section 4 TabNet provides high levels \\nof model interpretability and accuracy. TabNet was able to detect and \\nclassify driver risk using a combination of both traditional and tele-\\nmatics variables. When compared to XGBoost, TabNet can outperform \\nthis model on some classification metrics. However, XGBoost requires \\nless intensive processing and hyperparameter tuning to achieve high \\nlevels of accuracy. When comparing each model\\u2019s ability to provide \\ninterpretable results, TabNet exceeds XGBoost and GLM by returning \\nboth global and local interpretability. \\n\\n5.1. Model performance \\n\\nTabNet is a robust DL algorithm that has shown promising results for \\nthe task of Risk classification. However, training the TabNet model \\nposed some challenges, which prevented the model from demonstrating \\nthe same learning capabilities as other DL models. The TabNet model \\ntends to overfit the data and despite adjusting the available regulari-\\nzation parameters (the decision prediction and attention embedding \\nlayers); this had a marginal effect on the model performance. This form \\nof regularization is not as sophisticated as DL equivalents such as \\ndropout or weight constraint (Goodfellow et al., 2016). Additionally, \\ncriticisms of DL being over-parameterized and difficult to train also \\napply to TabNet. With limited hardware resources, training TabNet can \\ntake a considerable amount of time. XGBoost in comparison excels in \\nmost fields, with less extensive model building or effort required for \\ngood generalization. \\n\\nThe performance of Logistic Regression compared to both TabNet \\nand XGBoost demonstrates the limitations of GLM in classifying risk on a \\nhighly dimensional dataset, including both traditional and telematics \\nvariables. Logistic Regression performed poorly on the f1-score in \\nparticular and could not provide accurate estimates of precision and \\nrecall. PCA was used to reduce the dimensionality and complexity of the \\n\\ndataset for the final phase of testing, although the improvement to \\nmodel performance was insignificant. Logistic Regression still per-\\nformed well in AUC and ROC but never surpassed the performance of \\nTabNet or XGBoost. The poor model performance demonstrates that the \\nmodel found difficulty in correctly distinguishing between risky and \\nnon-risky drivers from the telematics data. \\n\\nDespite the aforementioned limitations of TabNet, the results are \\npromising for the usage of this model in detecting claims from telematics \\ndata. TabNet could predict higher Recall and f1-scores than XGBoost and \\nLogistic Regression on most tasks. For insurers, this is an important \\nscoring metric, as high levels of Recall infer the model\\u2019s capability in \\ndetecting true positive cases of risky driving behavior. In addition, ROC \\nand AUC metrics do not fully represent the sparsity of claims in the \\ndataset, high values of this score are misleading. As a result, the high f1- \\nscore and Matthew\\u2019s Correlation Coefficient from TabNet signify that \\nthe model captures the sparsity in claims data, outperforming or \\nequaling XGBoost. The addition of the final test for robustness also \\ndemonstrates TabNet\\u2019s potential for usage in insurance. The LightGBM \\nand NN models did not achieve any notable improvements in f1-score, or \\nMatthew\\u2019s Correlation Coefficient even when compared against the \\nLogistic Regression model. In addition, the LightGBM and NN required \\nextensive effort to achieve their training score, while TabNet and \\nXGBoost required less training for better performance. Since TabNet is a \\nDL model, access to larger datasets could drastically improve predictive \\nperformance. Model performance may also improve if trained on a real \\ndataset instead of a synthetic dataset, as this data may not fully represent \\nthe chosen target variable. \\n\\nThe final test conducted compared an additional two models against \\nTabNet. These models did not achieve any notable improvements in f1- \\nscore, or Matthew\\u2019s Correlation Coefficient even when compared \\nagainst the Logistic Regression model. In addition, the LightGBM and \\nNN required extensive effort to achieve their training score, while \\nTabNet and XGBoost required less training for better performance. \\n\\n5.2. Model interpretability \\n\\nEach model tested in this paper provided a set of features\\u2019 impor-\\ntances or model coefficients; however, the clarity of the decisions made \\nand the significance of these features were sometimes not as apparent. \\nFor instance, these features may be weighted differently, with some \\nvariation from the initial run. However, ranking these features and \\ndefining commonality between each returned feature for a model is \\nbeneficial, as repeated instances of the same features used may indicate \\na contributor to some risk cases. Once an insurer selects a production \\nmodel, these features will remain constant. However, for a model to be \\nfully interpretable, there needs to be a repeatable and easily definable \\nmethod to return model decisions to provide model decision clarity for \\nregulatory or auditing purposes (Actuarial Standards Board, 2020; \\nCouncil of the European Union, 2016; Institute and Faculty of Actuaries, \\n2015). For example, using p-values or model coefficients, insurers or \\nauditors can easily access model decisions from a Logistic Regression \\nmodel, negating the risk of being in breach of regulation. In contrast, the \\nfeatures\\u2019 importances returned by XGBoost score each feature uniformly \\nbefore choosing the most relevant set of features. The scoring behavior \\nof the XGBoost model is due to the ensemble decision function, where \\ndecision nodes split based on weak classifiers. These weak classifiers \\ncontribute to features\\u2019 importance until a \\u2018champion\\u2019 set of features \\nbecomes part of the final solution. Additionally, the NN used in the study \\nproved challenging to extract meaningful interior model decisions, a \\nknown disadvantage of using these models (Baecke & Bocca, 2017; \\nPaefgen et al., 2013). The internal decision process is hidden from the \\nuser unless specialist software is used (Gramegna & Giudici, 2020). \\nThus, explaining model decisions and interpreting results becomes a \\ndifficult task. \\n\\nTransitioning away from a GLM is difficult for insurers due to the \\nneed for model clarity and interpretability. Therefore, the black-box \\n\\nTable 4 \\nThe top four feature importances\\u2019 for each model tested per level. Bolded values \\nare traditional or classical risk pricing variables; all other values are telematics \\nvariables. Each model used in this study has favored telematics variables over \\ntraditional or classical variables when making risk predictions. TabNet, in \\nparticular, does not use any traditional variables when making predictions. \\nUnderlined features represent commonality between each model.  \\n\\nFeature Importance \\n\\nLevel TabNet XGBoost Logistic Regression \\n\\nFeature \\n\\n1 Annual.miles.drive \\nPct.drive.wkday \\nRight.turn.intensity11 \\nAnnual.pct.driven \\n\\nRegion \\nAnnual.miles.drive \\nAccel.12miles \\nAccel.11miles \\n\\nCar.age* \\nDuration* \\nLeft.turn.intensity12** \\nAnnual.miles.drive** \\n\\n2 Pct.drive.rush am \\nBrake.14miles \\nRight.turn.intensity08 \\nPct.drive.tue \\n\\nAnnual.miles.drive \\nCredit.score \\nLeft.turn.intensity08 \\nPct.drive.tue \\n\\nAnnual.pct.driven* \\nRight.turn.intensity10* \\nPct.drive.rush pm** \\nPct.drive.rush am** \\n\\n3 Agg_Acc \\nAnnual.pct.driven \\nAnnual.miles.drive \\nPct.drive.rush am \\n\\nCar.age \\nAnnual.miles.drive \\nPct.drive.tue \\nBrake.14miles \\n\\nAnnual.pct.driven* \\nTerritory*  \\n\\nPct.drive.tue** \\nCredit.score** \\n\\n*Denotes coeff values that contributed to drivers identified as not a risk or \\n\\u2018ClaimsYN\\u2019=0. \\n**Denotes drivers identified as a risk or \\u2018ClaimsYN\\u2019=1. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n8\\n\\nstyle of model predictions found in XGB or traditional DL models be-\\ncomes unattractive. However, TabNet provides both features\\u2019 impor-\\ntance and interior decision masks. The returned feature scores from \\nTabNet indicate a clearly chosen feature as significant to model de-\\ncisions, leaving no ambiguity in model choice. Additional features that \\nscore highly are also distinct from low-scoring features. The addition of \\nthe decision mask enables further insight into the model decision pro-\\ncess. The Attentive Transformer does not retain features that do not \\ncontribute to model decisions, and the output from the decision mask \\ncaptures this process. Gaining access to these decisions is simple and \\ndoes not require additional software packages. TabNet\\u2019s ability to easily \\nprovide model interpretability can bridge this gap in using DL in in-\\nsurance as these properties will enable insurers to provide auditors or \\nregulatory bodies with sufficient model information to be regulatory \\ncompliant. \\n\\n5.3. Data trends \\n\\nThe returned features\\u2019 importance for each model assists in discov-\\nering trends in the telematics or policyholder data. An important \\nconsideration for insurers should be the value of investing in bespoke \\ninsurance products and whether these additional features contribute to \\nmodel decisions. The returned features\\u2019 importances for each model \\nvary in their assigned importances to traditional or telematics data. \\n\\nThese decisions from the model help insurers target certain behaviors or \\ncharacteristics and offer specific and competitive bespoke insurance \\nproducts. The chosen model must identify realistic and accessible fea-\\ntures with relative accuracy to achieve this. For instance, Logistic \\nRegression and XGBoost both identified Car.age and Credit.Score as a \\nsignificant contributor to model decisions. These features are likely to \\ninfer a driver\\u2019s risk; however, traditional risk metrics such as Annual. \\nmiles.drive have historically contributed to risk (Bian, Yang, Zhao, & \\nLiang, 2018; Boucher et al., 2017) and thus should have been rated \\nhigher. \\n\\nTelematics data offers significant insights into driver behavior and, \\ntherefore, should be an indicator of risk. However, out of the three \\nmodels tested, TabNet was the only model that consistently identified \\ntelematics variables as significant contributors to driver risk. Compared \\nto TabNet, the Logistic Regression model sporadically identified fea-\\ntures, indicating poor model performance. The high f1 and recall scores \\nreturned by TabNet also reflect TabNet\\u2019s ability to identify these risk \\nindicators over the other models. Additionally, TabNet\\u2019s ability to \\nidentify these risk indicators accurately will provide insurers with \\ngreater insights into their telematics data. \\n\\n6. Conclusion \\n\\nThis paper provides a comprehensive overview of TabNet\\u2019s \\n\\nFig. 3. Feature masks for TabNet. The highlighted features in each graph display the output from each feature mask at a given step. Each row indicates the levels of \\npre-processing. Additionally, color gradients signify the importance of a feature at that stage of testing, with yellow features indicating a significant contribution and \\npurple the lowest. The x-axis refers to rows of test data, and the y-axis refers to the index of feature values. The final row has only two masks due to the optimal steps \\nchosen as two, as each step outputs a corresponding mask. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n9\\n\\nperformance compared against traditional insurance risk classification \\nmethods in GLM and XGBoost. When compared against these models, \\nTabNet surpasses the performance of XGBoost and Logistic Regression. \\nTabNet is a highly performant DL architecture for insurers, capable of \\nidentifying driver risk from telematics data. This model also provides \\nhighly interpretable results and identifies valuable data trends, another \\nimportant consideration for insurance risk pricing. \\n\\nThe usage of DL models in insurance risk pricing is underutilized due \\nto their low model interpretability and poor generalization on tabular \\ndatasets. Additionally, GLM models and XGBoost require extensive \\nmodel building processes or return poor model interpretability. This \\nnovel approach introduces TabNet for driver risk identification. TabNet \\nprovides high accuracy and model interpretability and can identify risky \\ndrivers from telematics and policyholder data. \\n\\nComparing the performance of each model, TabNet was best suited \\nto capture the sparsity of claims within the dataset, returning the highest \\nf1-scores in two out three rounds, scoring 0.59 & 0.6, respectively. \\nAdditionally, no other model scored higher than TabNet in Recall. The \\nperformance of XGBoost was also comparable to TabNet. XGBoost \\nconsistently returned high precision, accuracy, and AUC values and, in \\nthe first round of testing, returned the highest f1-score. However, Lo-\\ngistic Regression could not generalize on the dataset and could never \\naccurately capture the sparsity in claims. Thus, model performance \\nnever improved despite efforts to optimize the model. Additionally, the \\nfinal set of tests conducted using LightGBM and NN could not accurately \\npredict claims. As a result, neither model could surpass TabNet\\u2019s or \\nXGBoost\\u2019s scores. \\n\\nThis study identifies model interpretability as TabNet\\u2019s key contri-\\nbution for usage in insurance risk pricing. Each model could identify a \\nsignificant feature that contributed to model decisions; however, \\nXGBoost, in particular, could not provide clarity over the decisions \\nmade. On the other hand, TabNet excelled in this field, returning chosen \\nfeatures of significance with clarity while also providing local model \\ninterpretability. Furthermore, obtaining the decision masks from Tab-\\nNet is a simple process, and each mask displays the decisions made by \\nthe model at that particular step. Finally, the coefficients returned from \\nLogistic Regression provide interpretable results; however, clarity was \\ndifficult to obtain due to poor model performance. This problem per-\\nsisted with the LightGBM and NN models, as both models performed \\n\\npoorly on the claims prediction task. The NN, in particular, demon-\\nstrated a significant challenge in obtaining model decisions, further \\nendorsing TabNet\\u2019s interpretable qualities. \\n\\nAnother important consideration for this study was evaluating each \\nmodel\\u2019s ability to identify telematics and policyholder data trends. \\nIdentifying specific trends in the data is invaluable to insurers, as they \\ncan offer tailored bespoke insurance products for their policyholders. \\nBoth XGBoost and Logistic Regression failed in this aspect, returning \\ninsights that would not benefit the insurer. Conversely, TabNet offered \\nsignificant insights into data trends, identifying traditionally significant \\nfeatures such as annual mileage and telematics features as contributors \\nto risk. \\n\\nTabNet tended to overfit the data despite these aforementioned \\nbenefits and required extensive effort to train and tune the model \\ncorrectly. Additionally, training the model was a time-consuming pro-\\ncess with sometimes minimal reward. XGBoost, in comparison, could \\nachieve comparable performance with minimal effort. \\n\\nCRediT authorship contribution statement \\n\\nKevin McDonnell: Conceptualization, Methodology, Software, \\nFormal analysis, Writing \\u2013 original draft, Writing \\u2013 review & editing. \\nFinbarr Murphy: Funding acquisition, Supervision, Writing \\u2013 review & \\nediting. Barry Sheehan: Supervision, Writing \\u2013 review & editing. \\nLeandro Masello: Resources, Writing \\u2013 review & editing. German \\nCastignani: Writing \\u2013 review & editing. \\n\\nDeclaration of Competing Interest \\n\\nThe authors declare that they have no known competing financial \\ninterests or personal relationships that could have appeared to influence \\nthe work reported in this paper. \\n\\nData availability \\n\\nThe dataset used in this study is a synthetic telematics dataset pro-\\nvided by So et al. (2021) \\n\\nAcknowledgements/Funding \\n\\nThis project was supported by the Science Foundation Ireland (SFI), \\nand by Lero, the SFI Research Center for Software, [grant Blended \\nAutonomous Vehicles, BAV]. The authors would also like to acknowl-\\nedge Greenval Insurance for their support in this research. \\n\\nReferences \\n\\n. Actuarial Standards Board. http://www.actuarialstandardsboard.org/wp-content/uplo \\nads/2020/01/asop056_195-1.pdf. \\n\\nArik, S.O\\u0308., & Pfister, T. (2021). TabNet: Attentive Interpretable Tabular Learning. \\nProceedings of the AAAI Conference on Artificial Intelligence, 35(8), 6679\\u20136687. \\n\\nAyuso, M., Guillen, M., & Nielsen, J. P. (2019). Improving automobile insurance \\nratemaking using telematics: Incorporating mileage and driver behaviour data. \\nTransportation, 46(3), 735\\u2013752. https://doi.org/10.1007/s11116-018-9890-7 \\n\\nBaecke, P., & Bocca, L. (2017). The value of vehicle telematics data in insurance risk \\nselection processes. Decision Support Systems, 98, 69\\u201379. https://doi.org/10.1016/j. \\ndss.2017.04.009 \\n\\nBian, Y., Yang, C., Zhao, J. L., & Liang, L. (2018). Good drivers pay less: A study of usage- \\nbased vehicle insurance models. Transportation Research Part A: Policy and Practice, \\n107, 20\\u201334. https://doi.org/10.1016/j.tra.2017.10.018 \\n\\nBibal, A., Lognoul, M., de Streel, A., & Fre\\u0301nay, B. (2021). Legal requirements on \\nexplainability in machine learning. Artificial Intelligence and Law, 29(2), 149\\u2013169. \\nhttps://doi.org/10.1007/s10506-020-09270-4 \\n\\nChen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In Proceedings \\nof the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data \\nMining (pp. 785\\u2013794). https://doi.org/10.1145/2939672.2939785 \\n\\nCouncil of the European Union. (2016). Regulation (EU) 2016/679 of the European \\nParliament and of the Council of 27 April 2016 on the protection of natural persons \\nwith regard to the processing of personal data and on the free movement of such \\ndata, and repealing Directive 95/46/EC (General Data Protection Regulation) (Text \\nwith EEA relevance). https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/? \\nuri=OJ:L:2016:119:FULL&from=EN. \\n\\nTable 5 \\nSummation of Results. Key points summarize each model\\u2019s performance \\nthroughout each round of testing. These include performance metrics, model \\ncomplexity and model interpretability characteristics. For interpretability, ease \\nof access to model decisions indicates good model interpretability.  \\n\\nSummary of Results \\n\\nModel Key Points Interpretability \\n\\nTabNet  \\u2022 Highest F1-Score  \\n\\u2022 Recall highest in 2/3 rounds  \\n\\u2022 Near equal Matthew\\u2019s \\n\\nCorrelation performance \\ncompared to XGB  \\n\\n\\u2022 Scores balanced across all tests  \\n\\u2022 Longest running time  \\n\\u2022 Model building is more \\n\\ncomplex than XGB for similar \\nperformance  \\n\\n\\u2022 Identifies Telematics as \\nsignificant to model decisions in \\nall rounds  \\n\\n\\u2022 Internal model decisions are \\neasily accessible.  \\n\\n\\u2022 Both TabNet and LR have equal \\nlevels of model interpretability \\n\\nXGB  \\u2022 Highest AUC and Precision  \\n\\u2022 Comparable Matthew\\u2019s \\n\\nCorrelation to TabNet  \\n\\u2022 Minimal effort in feature \\n\\nprocessing for good results.  \\n\\u2022 Shortest runtime  \\n\\n\\u2022 Identifies Telematics as \\nsignificant to model decisions in \\nall rounds  \\n\\n\\u2022 Poor interpretability without the \\nusing specialist software \\n\\nLR  \\u2022 Lowest scores in all three \\nrounds  \\n\\n\\u2022 Identifies Telematics variables as \\nmain contributors to risk  \\n\\n\\u2022 Coefficients easily obtained  \\n\\u2022 Both TabNet and GLM have equal \\n\\nlevels of model interpretablility  \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\nhttp://www.actuarialstandardsboard.org/wp-content/uploads/2020/01/asop056_195-1.pdf\\nhttp://www.actuarialstandardsboard.org/wp-content/uploads/2020/01/asop056_195-1.pdf\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0010\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0010\\nhttps://doi.org/10.1007/s11116-018-9890-7\\nhttps://doi.org/10.1016/j.dss.2017.04.009\\nhttps://doi.org/10.1016/j.dss.2017.04.009\\nhttps://doi.org/10.1016/j.tra.2017.10.018\\nhttps://doi.org/10.1007/s10506-020-09270-4\\nhttps://doi.org/10.1145/2939672.2939785\\nhttps://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ%3aL%3a2016%3a119%3aFULL%26from=EN\\nhttps://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ%3aL%3a2016%3a119%3aFULL%26from=EN\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n10\\n\\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.  \\nGramegna, A., & Giudici, P. (2020). Why to Buy Insurance? An Explainable Artificial \\n\\nIntelligence Approach. Risks, 8(4), 137. https://doi.org/10.3390/risks8040137 \\nGuelman, L. (2012). Gradient boosting trees for auto insurance loss cost modeling and \\n\\nprediction. Expert Systems with Applications, 39(3), 3659\\u20133667. https://doi.org/ \\n10.1016/j.eswa.2011.09.058 \\n\\nHenckaerts, R., Antonio, K., Clijsters, M., & Verbelen, R. (2018). A data driven binning \\nstrategy for the construction of insurance tariff classes. Scandinavian Actuarial \\nJournal, 2018(8), 681\\u2013705. https://doi.org/10.1080/03461238.2018.1429300 \\n\\nHenckaerts, R., Co\\u0302te\\u0301, M.-P., Antonio, K., & Verbelen, R. (2021). Boosting Insights in \\nInsurance Tariff Plans with Tree-Based Machine Learning Methods. North American \\nActuarial Journal, 25(2), 255\\u2013285. https://doi.org/10.1080/ \\n10920277.2020.1745656 \\n\\nKlein, N., Denuit, M., Lang, S., & Kneib, T. (2014). Nonlife ratemaking and risk \\nmanagement with Bayesian generalized additive models for location, scale, and \\nshape. Insurance: Mathematics and Economics, 55, 225\\u2013249. https://doi.org/10.1016/ \\nj.insmatheco.2014.02.001 \\n\\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436\\u2013444. \\nhttps://doi.org/10.1038/nature14539 \\n\\nMa, Y.-L., Zhu, X., Hu, X., & Chiu, Y.-C. (2018). The use of context-sensitive insurance \\ntelematics data in auto insurance rate making. Transportation Research Part A: Policy \\nand Practice, 113, 243\\u2013258. https://doi.org/10.1016/j.tra.2018.04.013 \\n\\nMaillart, A. (2021). Toward an explainable machine learning model for claim frequency: \\nA use case in car insurance pricing with telematics data. European Actuarial Journal. \\nhttps://doi.org/10.1007/s13385-021-00270-5 \\n\\nMasello, L., Sheehan, B., Murphy, F., Castignani, G., McDonnell, K., & Ryan, C. (2022). \\nFrom Traditional to Autonomous Vehicles: A Systematic Review of Data Availability. \\nTransportation Research Record, 2676(4), 161\\u2013193. https://doi.org/10.1177/ \\n03611981211057532 \\n\\nMcCullagh, P., & Nelder, J. A. (2019). In Generalized Linear Models (2nd ed.). Routledge. \\nhttps://doi.org/10.1201/9780203753736.  \\n\\nMcDonnell, K., Murphy, F., Sheehan, B., Masello, L., Castignani, G., & Ryan, C. (2021). \\nRegulatory and Technical Constraints: An Overview of the Technical Possibilities \\nand Regulatory Limitations of Vehicle Telematic Data. Sensors, 21(10), 3517. \\nhttps://doi.org/10.3390/s21103517 \\n\\nMolnar, C. (2020). Interpretable Machine Learning. \\nNoll, A., Salzmann, R., & Wuthrich, M. V. (2018). Case Study: French Motor Third-Party \\n\\nLiability Claims. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3164764 \\nPaefgen, J., Staake, T., & Thiesse, F. (2013). Evaluation and aggregation of pay-as-you- \\n\\ndrive insurance rate factors: A classification analysis approach. Decision Support \\nSystems, 56, 192\\u2013201. https://doi.org/10.1016/j.dss.2013.06.001 \\n\\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., \\u2026 \\nDuchesnay, E\\u0301. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine \\nLearning Research, 12(85), 2825\\u20132830. \\n\\nPesantez-Narvaez, J., Guillen, M., & Alcan\\u0303iz, M. (2019). Predicting Motor Insurance \\nClaims Using Telematics Data\\u2014XGBoost versus Logistic Regression. Risks, 7(2), 70. \\nhttps://doi.org/10.3390/risks7020070 \\n\\npytorch-tabnet: PyTorch implementation of TabNet (3.1.1). (2021). [Python]. DreamQuark. \\nhttps://github.com/dreamquark-ai/tabnet. \\n\\nQuan, Z., & Valdez, E. A. (2018). Predictive analytics of insurance claims using \\nmultivariate decision trees. Dependence Modeling, 6(1), 377\\u2013407. https://doi.org/ \\n10.1515/demo-2018-0022 \\n\\nRenshaw, A. E. (1994). Modelling the claims process in the presence of covariates. ASTIN \\nBulletin, 24(2), 265\\u2013285. Scopus. doi:10.2143/AST.24.2.2005070. \\n\\nShannon, D., Murphy, F., Mullins, M., & Eggert, J. (2018). Applying crash data to injury \\nclaims\\u2014An investigation of determinant factors in severe motor vehicle accidents. \\nAccident; Analysis and Prevention, 113, 244\\u2013256. https://doi.org/10.1016/j. \\naap.2018.01.037 \\n\\nShavitt, I., & Segal, E. (2018). Regularization Learning Networks: Deep Learning for \\nTabular Datasets. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa- \\nBianchi, & R. Garnett (Eds.), Advances in Neural Information Processing Systems (Vol. \\n31). Curran Associates, Inc. https://proceedings.neurips.cc/paper/2018/file/500 \\ne75a036dc2d7d2fec5da1b71d36cc-Paper.pdf. \\n\\nSheehan, B., Murphy, F., Ryan, C., Mullins, M., & Liu, H. Y. (2017). Semi-autonomous \\nvehicle motor insurance: A Bayesian Network risk transfer approach. Transportation \\nResearch Part C: Emerging Technologies, 82, 124\\u2013137. https://doi.org/10.1016/j. \\ntrc.2017.06.015 \\n\\nSiami, M., Naderpour, M., & Lu, J. (2021). A Mobile Telematics Pattern Recognition \\nFramework for Driving Behavior Extraction. IEEE Transactions on Intelligent \\nTransportation Systems, 22(3), 1459\\u20131472. https://doi.org/10.1109/ \\nTITS.2020.2971214 \\n\\n[dataset] So, B., Boucher, J.-P., & Valdez, E. A. (2021). Synthetic Dataset Generation of \\nDriver Telematics. Risks, 9(4), 58. doi:10.3390/risks9040058. \\n\\nThe Regulation Board, I. and F. of A. (2015, July). APS X2: Review of Actuarial Work. \\nInstitute and Faculty of Actuaries. https://www.actuaries.org.uk/system/files \\n/documents/pdf/20150122-aps-x2-final-version.pdf. \\n\\nVerbelen, R., Antonio, K., & Claeskens, G. (2018). Unravelling the predictive power of \\ntelematics data in car insurance pricing. Journal of the Royal Statistical Society. Series \\nC: Applied Statistics, 67(5), 1275\\u20131304. Scopus. doi:10.1111/rssc.12283. \\n\\nWang, W., & Xi, J. (2016). A rapid pattern-recognition method for driving styles using \\nclustering-based support vector machines. American Control Conference (ACC), 2016, \\n5270\\u20135275. https://doi.org/10.1109/ACC.2016.7526495 \\n\\nWu, M., Zhang, S., & Dong, Y. (2016). A Novel Model-Based Driving Behavior \\nRecognition System Using Motion Sensors. Sensors, 16(10), 1746. https://doi.org/ \\n10.3390/s16101746 \\n\\nW\\u00fcthrich, M. V. (2020). Bias regularization in neural network models for general \\ninsurance pricing. European Actuarial Journal, 10(1), 179\\u2013202. https://doi.org/ \\n10.1007/s13385-019-00215-z \\n\\nXu, L., Skoularidou, M., Cuesta-Infante, A., & Veeramachaneni, K. (2019). Modeling \\nTabular data using Conditional GAN. In H. Wallach, H. Larochelle, A. Beygelzimer, \\nF. d\\u2019Alche\\u0301-Buc, E. Fox, & R. Garnett (Eds.), Advances in Neural Information Processing \\nSystems (Vol. 32). Curran Associates, Inc. https://proceedings.neurips.cc/paper/201 \\n9/file/254ed7d2de3b23ab10936522dd547b78-Paper.pdf. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0045\\nhttps://doi.org/10.3390/risks8040137\\nhttps://doi.org/10.1016/j.eswa.2011.09.058\\nhttps://doi.org/10.1016/j.eswa.2011.09.058\\nhttps://doi.org/10.1080/03461238.2018.1429300\\nhttps://doi.org/10.1080/10920277.2020.1745656\\nhttps://doi.org/10.1080/10920277.2020.1745656\\nhttps://doi.org/10.1016/j.insmatheco.2014.02.001\\nhttps://doi.org/10.1016/j.insmatheco.2014.02.001\\nhttps://doi.org/10.1038/nature14539\\nhttps://doi.org/10.1016/j.tra.2018.04.013\\nhttps://doi.org/10.1007/s13385-021-00270-5\\nhttps://doi.org/10.1177/03611981211057532\\nhttps://doi.org/10.1177/03611981211057532\\nhttps://doi.org/10.1201/9780203753736\\nhttps://doi.org/10.3390/s21103517\\nhttps://doi.org/10.2139/ssrn.3164764\\nhttps://doi.org/10.1016/j.dss.2013.06.001\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0120\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0120\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0120\\nhttps://doi.org/10.3390/risks7020070\\nhttps://github.com/dreamquark-ai/tabnet\\nhttps://doi.org/10.1515/demo-2018-0022\\nhttps://doi.org/10.1515/demo-2018-0022\\nhttps://doi.org/10.1016/j.aap.2018.01.037\\nhttps://doi.org/10.1016/j.aap.2018.01.037\\nhttps://proceedings.neurips.cc/paper/2018/file/500e75a036dc2d7d2fec5da1b71d36cc-Paper.pdf\\nhttps://proceedings.neurips.cc/paper/2018/file/500e75a036dc2d7d2fec5da1b71d36cc-Paper.pdf\\nhttps://doi.org/10.1016/j.trc.2017.06.015\\nhttps://doi.org/10.1016/j.trc.2017.06.015\\nhttps://doi.org/10.1109/TITS.2020.2971214\\nhttps://doi.org/10.1109/TITS.2020.2971214\\nhttps://www.actuaries.org.uk/system/files/documents/pdf/20150122-aps-x2-final-version.pdf\\nhttps://www.actuaries.org.uk/system/files/documents/pdf/20150122-aps-x2-final-version.pdf\\nhttps://doi.org/10.1109/ACC.2016.7526495\\nhttps://doi.org/10.3390/s16101746\\nhttps://doi.org/10.3390/s16101746\\nhttps://doi.org/10.1007/s13385-019-00215-z\\nhttps://doi.org/10.1007/s13385-019-00215-z\\nhttps://proceedings.neurips.cc/paper/2019/file/254ed7d2de3b23ab10936522dd547b78-Paper.pdf\\nhttps://proceedings.neurips.cc/paper/2019/file/254ed7d2de3b23ab10936522dd547b78-Paper.pdf\\n\\n\\tDeep learning in insurance: Accuracy and model interpretability using TabNet\\n\\t1 Introduction\\n\\t2 Data\\n\\t3 Methodology\\n\\t3.1 TabNet\\n\\t3.2 XGBoost\\n\\t3.3 GLm\\n\\t3.4 Pre-processing level 1\\u20133\\n\\n\\t4 Results\\n\\t5 Discussion\\n\\t5.1 Model performance\\n\\t5.2 Model interpretability\\n\\t5.3 Data trends\\n\\n\\t6 Conclusion\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgements/Funding\\n\\tReferences\\n\\n\\n\",\n",
      "  \"language\": \"en\",\n",
      "  \"metadata_cid\": \"QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\",\n",
      "  \"modified\": \"2023-02-07t17:36:19z\",\n",
      "  \"project_id\": \"77323@test\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"subject\": \"deep learning,telematics,connected vehicles,insurance,general linear model,xgboost,machine learning,explainable ai, expert systems with applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543\",\n",
      "  \"title\": \"deep learning in insurance: accuracy and model interpretability using tabnet\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 2: {\n",
      "  \"metadata_cid\": \"QmQvGdmxoDtMFN3ciARqKANbJ6EGsXowfncs59LKb356s4\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 3: {\n",
      "  \"metadata_cid\": \"QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 4: {\n",
      "  \"metadata_cid\": \"QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 5: {\n",
      "  \"metadata_cid\": \"Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"77323@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 6: {\n",
      "  \"metadata_cid\": \"QmNf9v11kNmrrrFw58VdMnS7GAjdfss6aiBaVkKq4ghdn7\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 7: {\n",
      "  \"metadata_cid\": \"QmedM2sDbqRi5VmoWAUvwbuPrtSkLjHzYqor4FWK4223FV\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 8: {\n",
      "  \"metadata_cid\": \"QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 9: {\n",
      "  \"metadata_cid\": \"QmTDECsHqEHEthrKVChmpeo1VXS1fpptph3EhLCMKZNxCy\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 10: {\n",
      "  \"metadata_cid\": \"QmcEd1CvbCB98BjtV48ufLfJXH6nkRkfhySonJddo4kXub\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 11: {\n",
      "  \"metadata_cid\": \"Qmda3UGvN1Ywmc2FkxuKSEHK8iy5vW5YrRFE9sqKKxdUVw\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 12: {\n",
      "  \"metadata_cid\": \"QmNjaCTeNdmrJfLYUpD8qhpjndXXX7QrWagRMhNSAtQkC6\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"73243@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 13: {\n",
      "  \"metadata_cid\": \"QmdyAE132FSeSQaqUHzE5GtMrEwy821ScAYKEXsxpWSnV5\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"73243@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 14: {\n",
      "  \"metadata_cid\": \"QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"73243@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 15: {\n",
      "  \"metadata_cid\": \"QmWcdZFjgVaocJrPvDqKzf5KSFDcxypn5Ffyq9SNxQM1dN\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - Result 16: {\n",
      "  \"metadata_cid\": \"QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"date\": \"\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\"\n",
      "}\n",
      "\u001b[32m2025-01-13 23:09:14.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Keyword Search\n",
      "\u001b[32m2025-01-13 23:09:14.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Search Results\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 77323@test\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 77323@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\", \"file_2\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\", \"linked_user\" : \"romantic_johnson@test\", \"project_metadata_cid\" : \"QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q found under file_2.\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 77323@test: {'is_valid': True, 'project_metadata_cid': 'QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7', 'linked_user': 'romantic_johnson@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how gene therapy influences energy storage, providing insights into how to maximize its personalized medicine.', 'schema:endDate': '2028-06-19', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'National Geographic Society'}, 'schema:keywords': ['gene therapy', 'energy storage', 'personalized medicine'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Accra, Ghana'}, 'schema:name': 'Analyzing the Influence of gene therapy on energy storage', 'schema:startDate': '2018-10-29'}\n",
      "\u001b[32m2025-01-13 23:09:14.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:14.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'romantic_johnson@test', 'schema:publicKey': '6cc2015624b935cd3c7aed3b6848528bc4b841ad196c0dc0abdf0e8c84032626', 'schema:roleName': 'author'}, 'foaf:mbox': 'romantic_johnson@email.com', 'foaf:name': 'Romantic Johnson', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Paktia University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '1027-3561-0949-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:14.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/77323@test\n",
      "\u001b[32m2025-01-13 23:09:14.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/77323@test/Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 77323@test\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmQvGdmxoDtMFN3ciARqKANbJ6EGsXowfncs59LKb356s4\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 77323@test\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 77323@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, Qme5cwgyMn5R2LRqT6jvrg4GfjuauPKwGR4m6njHpzhAtR\", \"file_2\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmWa6PngcSfzdn677h7j8fqQyk7xFp2PVpJzj8whpJUUw9\", \"linked_user\" : \"romantic_johnson@test\", \"project_metadata_cid\" : \"QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 77323@test: {'is_valid': True, 'project_metadata_cid': 'QmaWfoLPTka6WB8qTFiJ7YhZs2k3XPkdDDocEmTS5L7ZF7', 'linked_user': 'romantic_johnson@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how gene therapy influences energy storage, providing insights into how to maximize its personalized medicine.', 'schema:endDate': '2028-06-19', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'National Geographic Society'}, 'schema:keywords': ['gene therapy', 'energy storage', 'personalized medicine'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Accra, Ghana'}, 'schema:name': 'Analyzing the Influence of gene therapy on energy storage', 'schema:startDate': '2018-10-29'}\n",
      "\u001b[32m2025-01-13 23:09:14.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:14.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'romantic_johnson@test', 'schema:publicKey': '6cc2015624b935cd3c7aed3b6848528bc4b841ad196c0dc0abdf0e8c84032626', 'schema:roleName': 'author'}, 'foaf:mbox': 'romantic_johnson@email.com', 'foaf:name': 'Romantic Johnson', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Paktia University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '1027-3561-0949-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: romantic_johnson@test\n",
      "\u001b[32m2025-01-13 23:09:14.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/77323@test\n",
      "\u001b[32m2025-01-13 23:09:14.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/77323@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 77323@test\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmNf9v11kNmrrrFw58VdMnS7GAjdfss6aiBaVkKq4ghdn7\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmedM2sDbqRi5VmoWAUvwbuPrtSkLjHzYqor4FWK4223FV\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmTDECsHqEHEthrKVChmpeo1VXS1fpptph3EhLCMKZNxCy\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmcEd1CvbCB98BjtV48ufLfJXH6nkRkfhySonJddo4kXub\n",
      "\u001b[32m2025-01-13 23:09:14.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: Qmda3UGvN1Ywmc2FkxuKSEHK8iy5vW5YrRFE9sqKKxdUVw\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:14.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:14.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmNjaCTeNdmrJfLYUpD8qhpjndXXX7QrWagRMhNSAtQkC6\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 73243@test: {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 23:09:14.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:14.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:14.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 23:09:14.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:14.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmdyAE132FSeSQaqUHzE5GtMrEwy821ScAYKEXsxpWSnV5\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:14.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:15.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 73243@test: {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}\n",
      "\u001b[32m2025-01-13 23:09:15.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:15.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:15.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 23:09:15.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:15.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:15.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 23:09:15.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:15.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:15.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:15.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 23:09:15.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:15.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 73243@test: {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:15.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 23:09:15.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:15.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:15.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 23:09:15.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 23:09:15.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:15.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:15.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 23:09:15.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmWcdZFjgVaocJrPvDqKzf5KSFDcxypn5Ffyq9SNxQM1dN\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:15.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:15.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:15.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:15.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:15.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:15.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:15.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:15.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:15.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:15.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m70\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m79\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m288\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m296\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 23:09:15.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m92\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 23:09:15.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 23:09:15.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:15.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m104\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 23:09:15.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 23:09:15.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:15.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m119\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 23:09:15.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 23:09:15.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:15.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 23:09:15.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m51\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:15.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m56\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 23:09:15.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m60\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 23:09:15.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m128\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 23:09:15.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 23:09:15.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 23:09:15.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 23:09:15.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Search Results\n",
      "\u001b[32m2025-01-13 23:09:15.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def with_logging_block(block_name, logger):\n",
    "    \"\"\"\n",
    "    A reusable context manager for logging structured execution blocks.\n",
    "\n",
    "    Args:\n",
    "        block_name (str): The name of the block being executed.\n",
    "        logger (Logger): The logger instance.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"\\n\" + \"=\" * 50)\n",
    "        logger.info(f\"STARTING BLOCK: {block_name}\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        yield  # Code within the `with` block will execute here\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in block '{block_name}': {e}. Exiting.\")\n",
    "        sys.exit(1)  # Graceful exit on error\n",
    "    finally:\n",
    "        logger.info(f\"COMPLETED BLOCK: {block_name}\")\n",
    "        logger.info(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# Main Code Logic\n",
    "\n",
    "# with with_logging_block(\"Keyword Search\", logger):\n",
    "#     if not search_results:\n",
    "#         logger.warning(f\"No search results found for keyword: '{keyword}'. Exiting the script.\")\n",
    "#         sys.exit(1)\n",
    "#     logger.info(f\"Search results for keyword '{keyword}':\")\n",
    "#     for idx, result in enumerate(search_results, 1):\n",
    "#         logger.info(f\"Result {idx}: {json.dumps(result, indent=2)}\")\n",
    "\n",
    "with with_logging_block(\"Keyword Search\", logger):\n",
    "    if not search_results:\n",
    "        logger.warning(f\"No search results found for keyword: '{keyword}'. Exiting the script.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Log the total number of search results\n",
    "    total_results = len(search_results)\n",
    "    logger.info(f\"Total search results found for keyword '{keyword}': {total_results}\")\n",
    "    \n",
    "    # List the `project_id` and `file_cid` for each search result\n",
    "    logger.info(\"Listing all search results:\")\n",
    "    for idx, result in enumerate(search_results, 1):\n",
    "        project_id = result.get('project_id', 'N/A')\n",
    "        file_cid = result.get('file_cid', 'N/A')\n",
    "        logger.info(f\"Result {idx}: Project ID: {project_id}, File CID: {file_cid}\")\n",
    "    \n",
    "    # Log the full details of search results\n",
    "    logger.info(f\"Full search results for keyword '{keyword}':\")\n",
    "    for idx, result in enumerate(search_results, 1):\n",
    "        logger.info(f\"Result {idx}: {json.dumps(result, indent=2)}\")\n",
    "\n",
    "with with_logging_block(\"Processing Search Results\", logger):\n",
    "    for result_dict in search_results:\n",
    "        project_id = result_dict.get('project_id')\n",
    "        file_cid = result_dict.get('file_cid')\n",
    "        metadata_cid = result_dict.get('metadata_cid')\n",
    "\n",
    "        with with_logging_block(f\"Processing Result for Project ID: {project_id or 'Unknown'}\", logger):\n",
    "            if not project_id or not file_cid or not metadata_cid:\n",
    "                logger.error(f\"Missing required data in result: {result_dict}\")\n",
    "                continue\n",
    "\n",
    "            logger.info(f\"File CID: {file_cid}\")\n",
    "            logger.info(f\"Metadata CID: {metadata_cid}\")\n",
    "\n",
    "            # Fetch project details\n",
    "            with with_logging_block(\"Fetching Project Details\", logger):\n",
    "                project_details = get_account_detail(project_id)\n",
    "                if not project_details:\n",
    "                    logger.error(f\"No project details found for Project ID: {project_id}.\")\n",
    "                    continue\n",
    "                logger.info(f\"Fetched project details for {project_id}: {project_details}\")\n",
    "\n",
    "            # Parse blockchain data\n",
    "            with with_logging_block(\"Parsing Blockchain Data\", logger):\n",
    "                try:\n",
    "                    blockchain_data = json.loads(project_details)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(f\"Error decoding project details JSON for {project_id}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Validate file CID\n",
    "            with with_logging_block(\"Validating File CID\", logger):\n",
    "                validation_result = fetch_project_details(file_cid, blockchain_data)\n",
    "                logger.info(f\"Validation Result for {project_id}: {validation_result}\")\n",
    "                if not validation_result[\"is_valid\"]:\n",
    "                    logger.warning(f\"Invalid File CID for Project ID: {project_id}. Skipping metadata processing.\")\n",
    "                    continue\n",
    "\n",
    "            project_metadata_cid = validation_result.get(\"project_metadata_cid\")\n",
    "            linked_user = validation_result.get(\"linked_user\")\n",
    "\n",
    "            # Process project metadata\n",
    "            if project_metadata_cid:\n",
    "                with with_logging_block(\"Processing Project Metadata\", logger):\n",
    "                    project_metadata = download_json_from_ipfs(project_metadata_cid)\n",
    "                    logger.info(f\"Downloaded project metadata: {project_metadata}\")\n",
    "\n",
    "            # Process linked user details\n",
    "            if linked_user:\n",
    "                with with_logging_block(f\"Processing Linked User: {linked_user}\", logger):\n",
    "                    user_details = get_account_detail(linked_user)\n",
    "                    try:\n",
    "                        user_details = json.loads(user_details)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        logger.error(f\"Error decoding user details JSON for {linked_user}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    user_json_ld_cid = user_details.get(\"admin@test\", {}).get(\"user_json_ld_cid\")\n",
    "                    if user_json_ld_cid:\n",
    "                        user_metadata = download_json_from_ipfs(user_json_ld_cid)\n",
    "                        logger.info(f\"Downloaded user metadata: {user_metadata}\")\n",
    "                    else:\n",
    "                        logger.warning(f\"User JSON-LD CID not found for linked user {linked_user}.\")\n",
    "\n",
    "            # Process metadata CID\n",
    "            if metadata_cid:\n",
    "                with with_logging_block(\"Processing Metadata CID\", logger):\n",
    "                    file_metadata = download_json_from_ipfs(metadata_cid)\n",
    "                    file_metadata_json = download_file(file_metadata, download_path, project_id, file_cid)\n",
    "                    logger.info(f\"Downloaded file metadata: {file_metadata_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9596fe-6623-48ab-85f4-2de7974801ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
