{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759b5251-2d99-444d-890b-0272c036750d",
   "metadata": {},
   "source": [
    "**IMPORTANT** \n",
    "\n",
    "- For requirements and initial setup go to https://github.com/OliveiraEdu/OpenScience/Readme.md;\n",
    "- To execute the notebook run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8923b08-9526-4300-a2ad-3c943be049ba",
   "metadata": {},
   "source": [
    " # Cross Linking Account and Project accounts, IPFS Search Engine implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11965914-6a6a-43b4-a793-01a3eda28617",
   "metadata": {},
   "source": [
    "# Part - 1 Cross Linking Account and Project accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab571c6-459e-4d8c-a14f-8ea40c12fdbe",
   "metadata": {},
   "source": [
    "## Activities\n",
    "\n",
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;\n",
    "\n",
    "2 - User and Project id extraction from CSVs;\n",
    "\n",
    "3 - Queries Iroha 1 for User and Project accounts and checks the present values;\n",
    "\n",
    "4 - Sets details for both User and Project accounts in Iroha 1 providing a logical link between them for later references;\n",
    "\n",
    "5 - Queries the User and Project accounts again and checks the proper setting of details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79226aee-cfb3-4a03-b85a-18468e43a9aa",
   "metadata": {},
   "source": [
    "## Sequence Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aad64b-9986-49bf-bf43-1039243c4dd3",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'base',\n",
    "    'themeVariables': {\n",
    "      'primaryColor': '#ffffff',\n",
    "      'primaryTextColor': '#000000',\n",
    "      'primaryBorderColor': '#000000',\n",
    "      'lineColor': '#000000',\n",
    "      'secondaryColor': '#f4f4f4',\n",
    "      'secondaryTextColor': '#000000',\n",
    "      'tertiaryColor': '#d3d3d3',\n",
    "      'tertiaryTextColor': '#000000',\n",
    "      'background': '#ffffff',\n",
    "      'actorBkg': '#B4B4B4',\n",
    "      'actorTextColor': '#000000',\n",
    "      'actorBorder': '#000000',\n",
    "      'actorLineColor': '#000000',\n",
    "      'signalColor': '#000000',\n",
    "      'signalTextColor': '#000000',\n",
    "      'activationBorderColor': '#000000',\n",
    "      'activationBkgColor': '#d3d3d3',\n",
    "      'sequenceNumberColor': '#000000',\n",
    "      'noteBkgColor': '#F0F0F0',\n",
    "      'noteTextColor': '#000000',\n",
    "      'noteBorderColor': '#000000'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant self as \"self\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    \n",
    "\n",
    "    Note over Platform, Blockchain: Deploy smart contract for details setting\n",
    "    Platform->>Blockchain: Deploy Smart Contract\n",
    "    Blockchain-->>Platform: Smart Contract Deployed Successfully\n",
    "\n",
    "    Note over Platform, Blockchain: Extract user and project IDs from CSVs\n",
    "    Platform->>self: User ID Extraction\n",
    "    Platform->>self: Project ID Extraction\n",
    "\n",
    "    Note over Platform, Blockchain: Queries the blockchain for <br/>User and Project accounts details\n",
    "    Platform->>Blockchain: Get User Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "    Platform->>Blockchain: Get Project Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "    \n",
    "    Note over Platform, Blockchain: Set details for User and Project accounts\n",
    "    Platform->>Blockchain: Set User Details in Blockchain\n",
    "    Blockchain-->>Platform: User Details Set Successfully\n",
    "    Platform->>Blockchain: Set Project Details in Blockchain\n",
    "    Blockchain-->>Platform: Project Details Set Successfully\n",
    "    \n",
    "    Note over Platform, Blockchain: Queries the blockchain to <br/>confirm proper setting of details\n",
    "    Platform->>Blockchain: Get User Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "    Platform->>Blockchain: Get Project Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a043d51-4a22-4186-975e-7e3e8a4b54ef",
   "metadata": {},
   "source": [
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a1c5a2-75c3-482e-999c-70eb25226078",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntering \"create_contract\"\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "\tLeaving \"create_contract\"\n",
      "\tEntering \"get_engine_receipts_result\"\n",
      "\n",
      "\tLeaving \"get_engine_receipts_result\"\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from Crypto.Hash import keccak\n",
    "import os\n",
    "import binascii\n",
    "from iroha import IrohaCrypto\n",
    "from iroha import Iroha, IrohaGrpc\n",
    "from iroha.ed25519 import H\n",
    "import integration_helpers\n",
    "from iroha.primitive_pb2 import can_set_my_account_detail\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import icecream as ic\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Python 3 or a more recent version is required.\")\n",
    "\n",
    "# Load configuration from config.json file\n",
    "config_path = \"config.json\"  # Update this path as needed\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IROHA_HOST_ADDR = config[\"IROHA_HOST_ADDR\"]\n",
    "IROHA_PORT = config[\"IROHA_PORT\"]\n",
    "ADMIN_ACCOUNT_ID = config[\"ADMIN_ACCOUNT_ID\"]\n",
    "ADMIN_PRIVATE_KEY = config[\"ADMIN_PRIVATE_KEY\"]\n",
    "\n",
    "iroha = Iroha(ADMIN_ACCOUNT_ID)\n",
    "net = IrohaGrpc(\"{}:{}\".format(IROHA_HOST_ADDR, IROHA_PORT))\n",
    "\n",
    "\n",
    "@integration_helpers.trace\n",
    "def create_contract():\n",
    "    bytecode = \"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\"\n",
    "    \"\"\"Bytecode was generated using remix editor  https://remix.ethereum.org/ from file detail.sol. \"\"\"\n",
    "    tx = iroha.transaction(\n",
    "        [iroha.command(\"CallEngine\", caller=ADMIN_ACCOUNT_ID, input=bytecode)]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    net.send_tx(tx)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    return hex_hash\n",
    "\n",
    "hash = create_contract()\n",
    "integration_helpers.get_engine_receipts_result(hash)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea1051-cb1c-4c29-97e5-38ba90248081",
   "metadata": {},
   "source": [
    "2 - Data extraction from JSON-LD.\n",
    "\n",
    "Extracts account ids from `datasets/accounts.json` and `datasets/projects.json`.\n",
    "\n",
    "Must update `json_ld_index` with a line number related to an existing object in `datasets/accounts.json` and `datasets/projects.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8384a9-49db-44a2-b222-f3657a3bc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for objects in both user account and project account JSON-LDs.\n",
    "json_ld_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e068d0-2247-4fd3-827f-4144b66965e1",
   "metadata": {},
   "source": [
    "4 - Sets details for both User and Project accounts providing a logical link between them for later references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126df4cd-d358-43cc-997f-e17453a5b8dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntering \"get_engine_receipts_address\"\n",
      "\tLeaving \"get_engine_receipts_address\"\n",
      "User Account ID: hardcore_northcutt@test\n",
      "Project Account ID: 33829@test\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "User account hardcore_northcutt@test linked to project 33829@test\n",
      "Project account 33829@test linked to user hardcore_northcutt@test\n"
     ]
    }
   ],
   "source": [
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "\n",
    "\n",
    "# Function to link details using blockchain\n",
    "def set_account_detail(address, account, key, value):\n",
    "    params = integration_helpers.get_first_four_bytes_of_keccak(\n",
    "        b\"setAccountDetail(string,string,string)\"\n",
    "    )\n",
    "    no_of_param = 3\n",
    "    for x in range(no_of_param):\n",
    "        params = params + integration_helpers.left_padded_address_of_param(\n",
    "            x, no_of_param\n",
    "        )\n",
    "    params = params + integration_helpers.argument_encoding(account)  # account id\n",
    "    params = params + integration_helpers.argument_encoding(key)  # key\n",
    "    params = params + integration_helpers.argument_encoding(value)  # value\n",
    "    tx = iroha.transaction(\n",
    "        [\n",
    "            iroha.command(\n",
    "                \"CallEngine\", caller=ADMIN_ACCOUNT_ID, callee=address, input=params\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    response = net.send_tx(tx)\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    return hex_hash\n",
    "\n",
    "# Function to read user accounts from JSON-LD\n",
    "def read_user_accounts_from_jsonld(file_path):\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        user_accounts = []\n",
    "        for entry in data[\"@graph\"]:\n",
    "            if entry[\"@type\"] == \"foaf:Person\":\n",
    "                account_id = entry.get(\"foaf:holdsAccount\", {}).get(\"schema:identifier\")\n",
    "                if account_id:\n",
    "                    user_accounts.append({\n",
    "                        'account_id': account_id\n",
    "                    })\n",
    "        return user_accounts\n",
    "\n",
    "# Function to read project accounts from JSON-LD\n",
    "def read_project_accounts_from_jsonld(file_path):\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        project_accounts = []\n",
    "        for entry in data[\"@graph\"]:\n",
    "            if entry[\"@type\"] == \"schema:ResearchProject\":\n",
    "                project_id = entry.get(\"schema:identifier\")\n",
    "                if project_id:\n",
    "                    project_accounts.append({\n",
    "                        'account_id': project_id\n",
    "                    })\n",
    "        return project_accounts\n",
    "\n",
    "# Paths to the JSON-LD files\n",
    "user_accounts_jsonld_file_path = 'datasets/accounts.json'\n",
    "project_accounts_jsonld_file_path = 'datasets/projects.json'\n",
    "\n",
    "# Read accounts from JSON-LD\n",
    "user_accounts = read_user_accounts_from_jsonld(user_accounts_jsonld_file_path)\n",
    "project_accounts = read_project_accounts_from_jsonld(project_accounts_jsonld_file_path)\n",
    "\n",
    "# Example to use the [n] row from the JSON-LD for the operation\n",
    "# csv_index = 0  # Assuming an index\n",
    "user_account = user_accounts[json_ld_index]\n",
    "project_account = project_accounts[json_ld_index]\n",
    "\n",
    "print(f\"User Account ID: {user_account['account_id']}\")\n",
    "print(f\"Project Account ID: {project_account['account_id']}\")\n",
    "\n",
    "# Set project_id as a detail for the user account\n",
    "hash_user_to_project = set_account_detail(\n",
    "    address, \n",
    "    user_account['account_id'], \n",
    "    \"linked_project\", \n",
    "    project_account['account_id']\n",
    ")\n",
    "\n",
    "# Set user_account_id as a detail for the project account\n",
    "hash_project_to_user = set_account_detail(\n",
    "    address, \n",
    "    project_account['account_id'], \n",
    "    \"linked_user\", \n",
    "    user_account['account_id']\n",
    ")\n",
    "\n",
    "# Confirming the operation\n",
    "print(f\"User account {user_account['account_id']} linked to project {project_account['account_id']}\")\n",
    "print(f\"Project account {project_account['account_id']} linked to user {user_account['account_id']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562857c-d86d-42cf-a24b-23a5c3f5cb4e",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for User account and checks its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52e47a4-b1c5-4ebe-a2d8-8edae10063d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Account id = {'account_id': 'hardcore_northcutt@test'}, { \"admin@test\" : { \"linked_project\" : \"33829@test\", \"user_json_ld_cid\" : \"QmSMLJZBvLTLP1YcKtgp8tE4oyT35DuthMWE1AeVJy2j6g\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=user_account['account_id'])\n",
    "# print(query)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "\n",
    "user_data = response.account_detail_response\n",
    "user_details = user_data.detail\n",
    "\n",
    "print(f'User Account id = {user_account}, {user_details}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a556f-b657-4a6a-8c9f-b18aac8f8375",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for Project account and checks its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d39cb27c-4f7d-48dd-a137-6bceb294c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '33829@test'}, { \"admin@test\" : { \"linked_user\" : \"hardcore_northcutt@test\", \"project_metadata_cid\" : \"QmW8fa17i54v8wKLJwYZ7REqZPpMvphHPYnYKqj2jSEPrh\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=project_account['account_id'])\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f660b-56d6-4ea0-bd2b-e3bb54ecd05b",
   "metadata": {},
   "source": [
    "# Part2 - Querying Project Metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986de21a-9ddc-4aea-b63d-47a6a0323871",
   "metadata": {},
   "source": [
    "## Activities\n",
    "\n",
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0445f-998d-4470-9dfa-252caf810921",
   "metadata": {},
   "source": [
    "## Sequence Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e812f7b-8439-4e65-883c-de57b8e81097",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'base',\n",
    "    'themeVariables': {\n",
    "      'primaryColor': '#ffffff',\n",
    "      'primaryTextColor': '#000000',\n",
    "      'primaryBorderColor': '#000000',\n",
    "      'lineColor': '#000000',\n",
    "      'secondaryColor': '#f4f4f4',\n",
    "      'secondaryTextColor': '#000000',\n",
    "      'tertiaryColor': '#d3d3d3',\n",
    "      'tertiaryTextColor': '#000000',\n",
    "      'background': '#ffffff',\n",
    "      'actorBkg': '#B4B4B4',\n",
    "      'actorTextColor': '#000000',\n",
    "      'actorBorder': '#000000',\n",
    "      'actorLineColor': '#000000',\n",
    "      'signalColor': '#000000',\n",
    "      'signalTextColor': '#000000',\n",
    "      'activationBorderColor': '#000000',\n",
    "      'activationBkgColor': '#d3d3d3',\n",
    "      'sequenceNumberColor': '#000000',\n",
    "      'noteBkgColor': '#F0F0F0',\n",
    "      'noteTextColor': '#000000',\n",
    "      'noteBorderColor': '#000000'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "    participant FrontEnd as \"Front End\"\n",
    "\n",
    "    Note over Platform, Blockchain: Queries the user account <br/> and get the project id \n",
    "    Platform->>Blockchain: Query User Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "        \n",
    "    Note over Platform, Blockchain: Queries the Project Account details <br/> and get the project metadata CID \n",
    "    Platform->>Blockchain: Query Project Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "\n",
    "    Note over Platform, IPFS: Process and displays the metadata CID \n",
    "    Platform->>IPFS: Sends the project metadata CID\n",
    "    IPFS-->>Platform: Sends back the project metadata JSON\n",
    "    Platform->>FrontEnd: Displays the project metadata JSON   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f33098-43df-47f3-8708-f3212dec1c0f",
   "metadata": {},
   "source": [
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "374843b3-6862-4a93-b298-1bdd0320c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admin@test': {'linked_project': '33829@test', 'user_json_ld_cid': 'QmSMLJZBvLTLP1YcKtgp8tE4oyT35DuthMWE1AeVJy2j6g'}}\n",
      "33829@test\n"
     ]
    }
   ],
   "source": [
    "from ipfs_functions import *\n",
    "\n",
    "# Process the account details response\n",
    "user_details_dict = json.loads(user_details)  # Convert the string to a JSON object\n",
    "print(user_details_dict)\n",
    "\n",
    "# Now you can access the specific key like this\n",
    "linked_project = user_details_dict[\"admin@test\"][\"linked_project\"]\n",
    "print(linked_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66b2f2c1-00b1-4b1b-8951-196af1f25208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '33829@test'}, { \"admin@test\" : { \"linked_user\" : \"hardcore_northcutt@test\", \"project_metadata_cid\" : \"QmW8fa17i54v8wKLJwYZ7REqZPpMvphHPYnYKqj2jSEPrh\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail', account_id=linked_project)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e7130f8-ad7d-4d0b-a521-ba0de69e9271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QmW8fa17i54v8wKLJwYZ7REqZPpMvphHPYnYKqj2jSEPrh\n",
      "{'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This study explores the impact of blockchain in urban development, focusing on public health.', 'schema:endDate': '2028-05-02', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'National Science Foundation'}, 'schema:keywords': ['blockchain', 'urban development', 'public health'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Phuket, Thailand'}, 'schema:name': 'Investigating the Role of blockchain in urban development', 'schema:startDate': '2018-11-27'}\n"
     ]
    }
   ],
   "source": [
    "# Convert the JSON string to a Python dictionary\n",
    "project_details_dict = json.loads(project_details)\n",
    "\n",
    "# Now you can access the specific key like this\n",
    "project_metadata_cid = project_details_dict[\"admin@test\"][\"project_metadata_cid\"]\n",
    "print(project_metadata_cid)\n",
    "\n",
    "\n",
    "project_metadata = download_json_from_ipfs(project_metadata_cid)\n",
    "\n",
    "# print(20*\"-\")\n",
    "\n",
    "print(project_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31163ee6-8c5a-4cd3-8951-9190665abd5a",
   "metadata": {},
   "source": [
    "# Part 3 - File Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d265a-50e1-423d-9e53-26226afe7756",
   "metadata": {},
   "source": [
    "7 -  Sends every file in the `upload` directory to IPFS, extracts theirs respective metadata with Apache Tika and sends it to IPFS, get the CIDs back and store in Iroha as details of the project account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419c69e-9fbb-474b-ab9b-4ffdc38403ee",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'base',\n",
    "    'themeVariables': {\n",
    "      'primaryColor': '#ffffff',\n",
    "      'primaryTextColor': '#000000',\n",
    "      'primaryBorderColor': '#000000',\n",
    "      'lineColor': '#000000',\n",
    "      'secondaryColor': '#f4f4f4',\n",
    "      'secondaryTextColor': '#000000',\n",
    "      'tertiaryColor': '#d3d3d3',\n",
    "      'tertiaryTextColor': '#000000',\n",
    "      'background': '#ffffff',\n",
    "      'actorBkg': '#B4B4B4',\n",
    "      'actorTextColor': '#000000',\n",
    "      'actorBorder': '#000000',\n",
    "      'actorLineColor': '#000000',\n",
    "      'signalColor': '#000000',\n",
    "      'signalTextColor': '#000000',\n",
    "      'activationBorderColor': '#000000',\n",
    "      'activationBkgColor': '#d3d3d3',\n",
    "      'sequenceNumberColor': '#000000',\n",
    "      'noteBkgColor': '#F0F0F0',\n",
    "      'noteTextColor': '#000000',\n",
    "      'noteBorderColor': '#000000'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant Metadata Extractor\n",
    "    participant Indexer\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "\n",
    "    Note over Platform, IPFS: File Operations \n",
    "    Platform->>IPFS: Upload local file to IPFS\n",
    "    IPFS-->>Platform: Send back file CIDs\n",
    "    Platform->>Blockchain: Set CID as Project Account Details\n",
    "    Blockchain-->>Platform:Details set successfully\n",
    "\n",
    "    Note over Platform, IPFS: File Metadata Operations\n",
    "    Platform->>Metadata Extractor: Parse file and extract metadata \n",
    "    Metadata Extractor->>Indexer: Send file metadata for indexing\n",
    "    Indexer->>IPFS: Store file metadata JSON\n",
    "    IPFS-->>Platform: Send back file metadata JSON CIDs\n",
    "    Platform->>Blockchain: Set file metadata JSON CID as Project Account Details\n",
    "    Blockchain-->>Platform:Details set successfully\n",
    "         \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8f960d3-522d-4276-a08a-423e6818f264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| linked_project: '33829@test'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editorial-Board_2023_Expert-Systems-with-Applications.pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed Editorial-Board_2023_Expert-Systems-with-Applications.pdf with CID: Qmc4d9fpDBnqfY7SNSSgV2YqEUZ41uvGUiTHMgLSJTvUwf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf with CID: QmTLp6JYFx91pfHx7azKuUm6MHRjc3647xfKZzCT7pxFts\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "Munafò et al. - 2022 - The reproducibility debate is an opportunity, not .pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed Munafò et al. - 2022 - The reproducibility debate is an opportunity, not .pdf with CID: QmdkLSqoRmNpXtkZFVgFvurSBwE8MBzADH5tCzFMz4yfB9\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "hello_world.py\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed hello_world.py with CID: QmNvfzYmDYePPKuZnJhtGKgZYQhzdF3J3vap8qFz8kKkTi\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "bitcoin.pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed bitcoin.pdf with CID: QmTfQnQkUahbEYBnbh5cEZr1WH9w71TBuxEDtCdsUi2A7R\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf with CID: QmPYqRCYvSUZLLHnjoiMNcetqNU5arEqwErJiao3FLETPb\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf with CID: QmeCSsMxyDw7qeCc5ZJ9Ys5nz7Aea5m5jJCwMFuUV6u3wC\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf with CID: QmQiW5Hxy2enzDqhMrNGP2rbxJeCViQ5qJER9eBNH8WC7q\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "Random-feature-selection-using-random-subspace-l_2023_Expert-Systems-with-Ap.pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed Random-feature-selection-using-random-subspace-l_2023_Expert-Systems-with-Ap.pdf with CID: QmZF4piTCwfAhutVGfXU8BP8kb7ftTB71PoENi8ce3X8sQ\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf with CID: QmVbveTui6awvqkHe3L6nfxX9AYXEajptWyS763xHS74gE\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "World_Energy_By_Country_And_Region_1965_to_2023.csv\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Indexed World_Energy_By_Country_And_Region_1965_to_2023.csv with CID: QmZ98TU3kN48oc7Bn4rYdS2YFnvSte497PQMtxm6Ni44vi\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "----------------------------------------\n",
      "Jean-Baptiste_Perronneau_-_Magdaleine_Pinceloup_de_la_Grange,_née_de_Parseval.jpg\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Error with file 'Jean-Baptiste_Perronneau_-_Magdaleine_Pinceloup_de_la_Grange,_née_de_Parseval.jpg': 'NoneType' object has no attribute 'strip'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "from tika import parser  # Apache Tika for metadata extraction\n",
    "from whoosh.index import create_in, LockError\n",
    "from whoosh.fields import Schema, TEXT, ID, NUMERIC  # <-- Add this line\n",
    "import mimetypes\n",
    "\n",
    "ic(linked_project)\n",
    "\n",
    "def reset_index_writer():\n",
    "    \"\"\"Manually remove the lock file if it exists.\"\"\"\n",
    "    lock_file = \"indexdir/WRITELOCK\"\n",
    "    if os.path.exists(lock_file):\n",
    "        os.remove(lock_file)\n",
    "        print(\"Lock file removed. Writer reset.\")\n",
    "\n",
    "def recreate_index(schema):\n",
    "    \"\"\"Recreate the index directory and start fresh.\"\"\"\n",
    "    if os.path.exists(\"indexdir\"):\n",
    "        shutil.rmtree(\"indexdir\")  # Remove the entire index directory\n",
    "    os.mkdir(\"indexdir\")\n",
    "    ix = create_in(\"indexdir\", schema)  # Recreate index\n",
    "    print(\"Index recreated.\")\n",
    "    return ix\n",
    "\n",
    "def get_writer_with_retry(ix, retries=5, delay=1):\n",
    "    \"\"\"Retry acquiring the writer with a delay, and reset lock if retries exhausted.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return ix.writer()\n",
    "        except LockError:\n",
    "            print(f\"Writer is locked, retrying in {delay} seconds... (Attempt {attempt + 1})\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "    # If retries are exhausted, remove the lock file\n",
    "    reset_index_writer()\n",
    "    raise Exception(\"Failed to acquire writer lock after several attempts.\")\n",
    "\n",
    "def parse_documents_in_directory(directory_path, schema, recreate=False):\n",
    "    \"\"\"Parses documents in a directory and indexes them, with reset logic.\"\"\"\n",
    "    if recreate:\n",
    "        ix = recreate_index(schema)  # Reset the index if needed\n",
    "    else:\n",
    "        ix = create_in(\"indexdir\", schema)  # Use the existing index\n",
    "\n",
    "    index = 1\n",
    "    writer = get_writer_with_retry(ix)  # Retry logic for writer\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        print(filename)\n",
    "\n",
    "        if not os.path.basename(filename).startswith('.'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            file_cid = upload_file_to_ipfs(file_path)\n",
    "\n",
    "            variable_1 = f\"file_{index}_CID\"\n",
    "            variable_2 = file_cid\n",
    "\n",
    "            hash = set_account_detail(address, linked_project, variable_1, variable_2)\n",
    "\n",
    "            try:\n",
    "                parsed_document = parser.from_file(file_path)\n",
    "\n",
    "                if parsed_document:  # Check if parsing was successful\n",
    "                    metadata = parsed_document.get('metadata', {})\n",
    "                    full_text = parsed_document.get(\"content\", \"\").strip()\n",
    "\n",
    "                    title = metadata.get(\"title\", \"Unknown\")\n",
    "                    author = metadata.get(\"Author\", \"Unknown\")\n",
    "                    keywords = metadata.get(\"Keywords\", \"\")\n",
    "\n",
    "                    metadata_cid = upload_json_to_ipfs(metadata)\n",
    "\n",
    "                    # Fetch file stats from IPFS\n",
    "                    stats = client.object.stat(metadata_cid)\n",
    "                    file_size = stats['CumulativeSize']\n",
    "\n",
    "                    # Use mimetypes to get the file type\n",
    "                    filetype = mimetypes.guess_type(filename)[0] or \"unknown\"\n",
    "\n",
    "                    # Index the document\n",
    "                    writer.add_document(\n",
    "                        cid=metadata_cid,\n",
    "                        name=filename,\n",
    "                        size=file_size,\n",
    "                        filetype=filetype,\n",
    "                        title=title,\n",
    "                        author=author,\n",
    "                        keywords=keywords,\n",
    "                        full_text=full_text,  # Index full text for searching\n",
    "                    )\n",
    "                    print(f\"Indexed {filename} with CID: {metadata_cid}\")\n",
    "\n",
    "                    variable_3 = f\"file_{index}_metadata_CID\"\n",
    "                    variable_4 = metadata_cid\n",
    "\n",
    "                    hash = set_account_detail(address, linked_project, variable_3, variable_4)\n",
    "\n",
    "                else:\n",
    "                    print(f\"Parsing failed for '{filename}'.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error with file '{filename}': {e}\")\n",
    "                continue\n",
    "\n",
    "        print(\"-\" * 40)\n",
    "        index += 1\n",
    "\n",
    "    writer.commit()  # Commit changes once after all files are processed\n",
    "\n",
    "# Example usage\n",
    "schema = Schema(\n",
    "    cid=ID(stored=True),\n",
    "    name=TEXT(stored=True),\n",
    "    size=NUMERIC(stored=True),\n",
    "    filetype=TEXT(stored=True),\n",
    "    title=TEXT(stored=True),\n",
    "    author=TEXT(stored=True),\n",
    "    keywords=TEXT(stored=True),\n",
    "    full_text=TEXT(stored=False)\n",
    ")\n",
    "\n",
    "# Parse documents in the directory \"upload\", and optionally reset the index\n",
    "parse_documents_in_directory(\"upload\", schema, recreate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6ffff1e-3f02-4294-b9dd-c70e9e60d797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CID: QmTfQnQkUahbEYBnbh5cEZr1WH9w71TBuxEDtCdsUi2A7R, Name: bitcoin.pdf, Title: Unknown, Author: Unknown, Size: 1569 bytes\n",
      "CID: QmPYqRCYvSUZLLHnjoiMNcetqNU5arEqwErJiao3FLETPb, Name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf, Title: Unknown, Author: Unknown, Size: 3852 bytes\n"
     ]
    }
   ],
   "source": [
    "from whoosh.index import open_dir, create_in\n",
    "from whoosh.fields import Schema, TEXT, ID, NUMERIC\n",
    "from whoosh.qparser import QueryParser\n",
    "import os\n",
    "\n",
    "# Define the schema\n",
    "schema = Schema(\n",
    "    cid=ID(stored=True),\n",
    "    name=TEXT(stored=True),\n",
    "    size=NUMERIC(stored=True),\n",
    "    filetype=TEXT(stored=True),\n",
    "    title=TEXT(stored=True),\n",
    "    author=TEXT(stored=True),\n",
    "    keywords=TEXT(stored=True),\n",
    "    full_text=TEXT(stored=False)\n",
    ")\n",
    "\n",
    "# Ensure the index directory exists\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "    ix = create_in(\"indexdir\", schema)  # Create index if it doesn't exist\n",
    "else:\n",
    "    ix = open_dir(\"indexdir\")  # Open existing index\n",
    "\n",
    "def search_ipfs(keyword, ix):\n",
    "    \"\"\"Search for a keyword in the indexed documents.\"\"\"\n",
    "    try:\n",
    "        with ix.searcher() as searcher:\n",
    "            query = QueryParser(\"full_text\", ix.schema).parse(keyword)\n",
    "            results = searcher.search(query)\n",
    "\n",
    "            if results:\n",
    "                for result in results:\n",
    "                    print(f\"CID: {result['cid']}, Name: {result['name']}, Title: {result['title']}, \"\n",
    "                          f\"Author: {result['author']}, Size: {result['size']} bytes\")\n",
    "            else:\n",
    "                print(f\"No results found for '{keyword}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during search: {e}\")\n",
    "\n",
    "# Example search usage\n",
    "search_ipfs(\"longer\", ix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e6b78-9d2c-4543-b88c-ba216b3ed596",
   "metadata": {},
   "source": [
    "8 - Query the project account to verify the details update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66cfac8c-5f92-487a-87fd-067df3e26299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '33829@test'}, { \"admin@test\" : { \"file_10_CID\" : \"QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4\", \"file_10_metadata_CID\" : \"QmVbveTui6awvqkHe3L6nfxX9AYXEajptWyS763xHS74gE\", \"file_11_CID\" : \"QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ\", \"file_11_metadata_CID\" : \"QmZ98TU3kN48oc7Bn4rYdS2YFnvSte497PQMtxm6Ni44vi\", \"file_12_CID\" : \"QmVTTcqbGvYRn7n7uPYwk4vi8NdbeYvnZkX9MVT3byrAx2\", \"file_1_CID\" : \"QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg\", \"file_1_metadata_CID\" : \"Qmc4d9fpDBnqfY7SNSSgV2YqEUZ41uvGUiTHMgLSJTvUwf\", \"file_2_CID\" : \"QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs\", \"file_2_metadata_CID\" : \"QmTLp6JYFx91pfHx7azKuUm6MHRjc3647xfKZzCT7pxFts\", \"file_3_CID\" : \"QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW\", \"file_3_metadata_CID\" : \"QmdkLSqoRmNpXtkZFVgFvurSBwE8MBzADH5tCzFMz4yfB9\", \"file_4_CID\" : \"QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv\", \"file_4_metadata_CID\" : \"QmNvfzYmDYePPKuZnJhtGKgZYQhzdF3J3vap8qFz8kKkTi\", \"file_5_CID\" : \"QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj\", \"file_5_metadata_CID\" : \"QmTfQnQkUahbEYBnbh5cEZr1WH9w71TBuxEDtCdsUi2A7R\", \"file_6_CID\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\", \"file_6_metadata_CID\" : \"QmPYqRCYvSUZLLHnjoiMNcetqNU5arEqwErJiao3FLETPb\", \"file_7_CID\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q\", \"file_7_metadata_CID\" : \"QmeCSsMxyDw7qeCc5ZJ9Ys5nz7Aea5m5jJCwMFuUV6u3wC\", \"file_8_CID\" : \"QmXquoApMLCcauNkz4tYw1Sp2tsqZ4edv1YtnQi5pmbw6C\", \"file_8_metadata_CID\" : \"QmQiW5Hxy2enzDqhMrNGP2rbxJeCViQ5qJER9eBNH8WC7q\", \"file_9_CID\" : \"QmTLZSqzPexwEdniZXLPN6fUfmEXX6MXS3b4QjKURgxc9y\", \"file_9_metadata_CID\" : \"QmZF4piTCwfAhutVGfXU8BP8kb7ftTB71PoENi8ce3X8sQ\", \"linked_user\" : \"hardcore_northcutt@test\", \"project_metadata_cid\" : \"QmW8fa17i54v8wKLJwYZ7REqZPpMvphHPYnYKqj2jSEPrh\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail', account_id=linked_project)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6ee05-f89d-44ce-aab8-e57b2acff3a4",
   "metadata": {},
   "source": [
    "9 - Read CIDs from Iroha and download file metadata and files from IPFS to the project home directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbac27b-655e-47e9-859a-b88629f5af14",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'base',\n",
    "    'themeVariables': {\n",
    "      'primaryColor': '#ffffff',\n",
    "      'primaryTextColor': '#000000',\n",
    "      'primaryBorderColor': '#000000',\n",
    "      'lineColor': '#000000',\n",
    "      'secondaryColor': '#f4f4f4',\n",
    "      'secondaryTextColor': '#000000',\n",
    "      'tertiaryColor': '#d3d3d3',\n",
    "      'tertiaryTextColor': '#000000',\n",
    "      'background': '#ffffff',\n",
    "      'actorBkg': '#B4B4B4',\n",
    "      'actorTextColor': '#000000',\n",
    "      'actorBorder': '#000000',\n",
    "      'actorLineColor': '#000000',\n",
    "      'signalColor': '#000000',\n",
    "      'signalTextColor': '#000000',\n",
    "      'activationBorderColor': '#000000',\n",
    "      'activationBkgColor': '#d3d3d3',\n",
    "      'sequenceNumberColor': '#000000',\n",
    "      'noteBkgColor': '#F0F0F0',\n",
    "      'noteTextColor': '#000000',\n",
    "      'noteBorderColor': '#000000'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant self as \"self\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "    participant FrontEnd as \"Front End\"\n",
    "    \n",
    "       \n",
    "    Note over Platform, Blockchain: Queries the Project Account details and get details\n",
    "    Platform->>Blockchain: Query Project Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "\n",
    "    Note over Platform, IPFS: Process project account metadata\n",
    "    Platform->>self: Parse Project Details JSON and retrieve file CIDs\n",
    "\n",
    "    Note over Platform, IPFS: Download file from IPFS \n",
    "    Platform->>IPFS: Sends the file CID\n",
    "    IPFS->>Platform: Sends back the file\n",
    "    Platform->>FrontEnd:    Saves the file locally and display info and status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6ca74-7343-4109-b774-0582cb9bab9b",
   "metadata": {},
   "source": [
    "10 - Read details from the project account retrieve the CID of every file, download the it file from IPFS and store locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ae73161-a508-408c-81fb-3bb08b13fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| files_metadata: {'file_10_CID': 'QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4',\n",
      "                     'file_10_metadata_CID': 'QmVbveTui6awvqkHe3L6nfxX9AYXEajptWyS763xHS74gE',\n",
      "                     'file_11_CID': 'QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ',\n",
      "                     'file_11_metadata_CID': 'QmZ98TU3kN48oc7Bn4rYdS2YFnvSte497PQMtxm6Ni44vi',\n",
      "                     'file_12_CID': 'QmVTTcqbGvYRn7n7uPYwk4vi8NdbeYvnZkX9MVT3byrAx2',\n",
      "                     'file_1_CID': 'QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg',\n",
      "                     'file_1_metadata_CID': 'Qmc4d9fpDBnqfY7SNSSgV2YqEUZ41uvGUiTHMgLSJTvUwf',\n",
      "                     'file_2_CID': 'QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs',\n",
      "                     'file_2_metadata_CID': 'QmTLp6JYFx91pfHx7azKuUm6MHRjc3647xfKZzCT7pxFts',\n",
      "                     'file_3_CID': 'QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW',\n",
      "                     'file_3_metadata_CID': 'QmdkLSqoRmNpXtkZFVgFvurSBwE8MBzADH5tCzFMz4yfB9',\n",
      "                     'file_4_CID': 'QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv',\n",
      "                     'file_4_metadata_CID': 'QmNvfzYmDYePPKuZnJhtGKgZYQhzdF3J3vap8qFz8kKkTi',\n",
      "                     'file_5_CID': 'QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj',\n",
      "                     'file_5_metadata_CID': 'QmTfQnQkUahbEYBnbh5cEZr1WH9w71TBuxEDtCdsUi2A7R',\n",
      "                     'file_6_CID': 'QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW',\n",
      "                     'file_6_metadata_CID': 'QmPYqRCYvSUZLLHnjoiMNcetqNU5arEqwErJiao3FLETPb',\n",
      "                     'file_7_CID': 'QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q',\n",
      "                     'file_7_metadata_CID': 'QmeCSsMxyDw7qeCc5ZJ9Ys5nz7Aea5m5jJCwMFuUV6u3wC',\n",
      "                     'file_8_CID': 'QmXquoApMLCcauNkz4tYw1Sp2tsqZ4edv1YtnQi5pmbw6C',\n",
      "                     'file_8_metadata_CID': 'QmQiW5Hxy2enzDqhMrNGP2rbxJeCViQ5qJER9eBNH8WC7q',\n",
      "                     'file_9_CID': 'QmTLZSqzPexwEdniZXLPN6fUfmEXX6MXS3b4QjKURgxc9y',\n",
      "                     'file_9_metadata_CID': 'QmZF4piTCwfAhutVGfXU8BP8kb7ftTB71PoENi8ce3X8sQ',\n",
      "                     'linked_user': 'hardcore_northcutt@test',\n",
      "                     'project_metadata_cid': 'QmW8fa17i54v8wKLJwYZ7REqZPpMvphHPYnYKqj2jSEPrh'}\n",
      "ic| file_metadata_key: 'file_10'\n",
      "ic| file_metadata_CID: 'QmVbveTui6awvqkHe3L6nfxX9AYXEajptWyS763xHS74gE'\n",
      "ic| raw_original_file_name: \"b'Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf'\"\n",
      "ic| clean_original_file_name: 'Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf'\n",
      "ic| file_metadata_key: 'file_11'\n",
      "ic| file_metadata_CID: 'QmZ98TU3kN48oc7Bn4rYdS2YFnvSte497PQMtxm6Ni44vi'\n",
      "ic| raw_original_file_name: \"b'World_Energy_By_Country_And_Region_1965_to_2023.csv'\"\n",
      "ic| clean_original_file_name: 'World_Energy_By_Country_And_Region_1965_to_2023.csv'\n",
      "ic| file_metadata_key: 'file_1'\n",
      "ic| file_metadata_CID: 'Qmc4d9fpDBnqfY7SNSSgV2YqEUZ41uvGUiTHMgLSJTvUwf'\n",
      "ic| raw_original_file_name: \"b'Editorial-Board_2023_Expert-Systems-with-Applications.pdf'\"\n",
      "ic| clean_original_file_name: 'Editorial-Board_2023_Expert-Systems-with-Applications.pdf'\n",
      "ic| file_metadata_key: 'file_2'\n",
      "ic| file_metadata_CID: 'QmTLp6JYFx91pfHx7azKuUm6MHRjc3647xfKZzCT7pxFts'\n",
      "ic| raw_original_file_name: \"b'Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf'\"\n",
      "ic| clean_original_file_name: 'Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf'\n",
      "ic| file_metadata_key: 'file_3'\n",
      "ic| file_metadata_CID: 'QmdkLSqoRmNpXtkZFVgFvurSBwE8MBzADH5tCzFMz4yfB9'\n",
      "ic| raw_original_file_name: (\"b'Munaf\\\\xc3\\\\xb2 et al. - 2022 - The reproducibility debate is an \"\n",
      "                             \"opportunity, not .pdf'\")\n",
      "ic| clean_original_file_name: 'Munafò et al. - 2022 - The reproducibility debate is an opportunity, not .pdf'\n",
      "ic| file_metadata_key: 'file_4'\n",
      "ic| file_metadata_CID: 'QmNvfzYmDYePPKuZnJhtGKgZYQhzdF3J3vap8qFz8kKkTi'\n",
      "ic| raw_original_file_name: \"b'hello_world.py'\"\n",
      "ic| clean_original_file_name: 'hello_world.py'\n",
      "ic| file_metadata_key: 'file_5'\n",
      "ic| file_metadata_CID: 'QmTfQnQkUahbEYBnbh5cEZr1WH9w71TBuxEDtCdsUi2A7R'\n",
      "ic| raw_original_file_name: \"b'bitcoin.pdf'\"\n",
      "ic| clean_original_file_name: 'bitcoin.pdf'\n",
      "ic| file_metadata_key: 'file_6'\n",
      "ic| file_metadata_CID: 'QmPYqRCYvSUZLLHnjoiMNcetqNU5arEqwErJiao3FLETPb'\n",
      "ic| raw_original_file_name: \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\"\n",
      "ic| clean_original_file_name: 'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\n",
      "ic| file_metadata_key: 'file_7'\n",
      "ic| file_metadata_CID: 'QmeCSsMxyDw7qeCc5ZJ9Ys5nz7Aea5m5jJCwMFuUV6u3wC'\n",
      "ic| raw_original_file_name: \"b'Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf'\"\n",
      "ic| clean_original_file_name: 'Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf'\n",
      "ic| file_metadata_key: 'file_8'\n",
      "ic| file_metadata_CID: 'QmQiW5Hxy2enzDqhMrNGP2rbxJeCViQ5qJER9eBNH8WC7q'\n",
      "ic| raw_original_file_name: \"b'Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf'\"\n",
      "ic| clean_original_file_name: 'Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf'\n",
      "ic| file_metadata_key: 'file_9'\n",
      "ic| file_metadata_CID: 'QmZF4piTCwfAhutVGfXU8BP8kb7ftTB71PoENi8ce3X8sQ'\n",
      "ic| raw_original_file_name: \"b'Random-feature-selection-using-random-subspace-l_2023_Expert-Systems-with-Ap.pdf'\"\n",
      "ic| clean_original_file_name: 'Random-feature-selection-using-random-subspace-l_2023_Expert-Systems-with-Ap.pdf'\n"
     ]
    }
   ],
   "source": [
    "# from ipfs_functions import *\n",
    "from clean_file_name import *\n",
    "\n",
    "# Convert the JSON string to a Python dictionary\n",
    "project_details_dict = json.loads(project_details)\n",
    "\n",
    "# Process the account details response\n",
    "# account_details_dict = json.loads(data.detail)  # Convert the string to a JSON object\n",
    "# ic(project_details_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Get the value of the dictionary (the actual file metadata)\n",
    "files_metadata = project_details_dict['admin@test']\n",
    "ic(files_metadata)\n",
    "\n",
    "for key, value in files_metadata.items():\n",
    "    if 'metadata_CID' not in key:  # Check if this is a file CID\n",
    "        key = '_'.join(key.split('_')[:-1])+\"_CID\"    \n",
    "        # ic(key)\n",
    "        file_CID = value\n",
    "        # ic(value)\n",
    "        \n",
    "    else:\n",
    "        file_metadata_key = '_'.join(key.split('_')[:-2])  # Extract the actual filename from the key\n",
    "        ic(file_metadata_key)\n",
    "        file_metadata_CID = value  # Get the corresponding metadata CID\n",
    "        ic(file_metadata_CID)\n",
    "        # print(f\"Downloading {file_metadata_CID} metadata...\")\n",
    "        file_metadata_json = download_json_from_ipfs(file_metadata_CID)\n",
    "        # ic(file_metadata_json)\n",
    "        if 'resourceName' in file_metadata_json:  # check if key exists in the dictionary\n",
    "            raw_original_file_name = file_metadata_json['resourceName']\n",
    "            ic(raw_original_file_name)\n",
    "            clean_original_file_name = clean_file_name(raw_original_file_name)  # Remove the 'b' prefix and quotes\n",
    "            ic(clean_original_file_name)\n",
    "\n",
    "            # Create a home directory for the user with the account ID as the username under /download/\n",
    "            user_id = project_account['account_id']\n",
    "            download_directory = os.path.join(\"download\", user_id)\n",
    "            if not os.path.exists(download_directory):\n",
    "                os.makedirs(download_directory)  # Create the directory if it doesn't exist\n",
    "\n",
    "            file_path = os.path.join(download_directory, clean_original_file_name)\n",
    "            download_file_from_ipfs(file_CID, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704db6c7-13c4-463a-b329-ce5078c46bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
