{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759b5251-2d99-444d-890b-0272c036750d",
   "metadata": {},
   "source": [
    "**IMPORTANT** \n",
    "\n",
    "- For requirements and initial setup go to https://github.com/OliveiraEdu/OpenScience/Readme.md;\n",
    "- To execute the notebook run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8923b08-9526-4300-a2ad-3c943be049ba",
   "metadata": {},
   "source": [
    " # Cross Linking Account and Project accounts, IPFS Search Engine implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11965914-6a6a-43b4-a793-01a3eda28617",
   "metadata": {},
   "source": [
    "# Part - 1 Cross Linking Account and Project accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab571c6-459e-4d8c-a14f-8ea40c12fdbe",
   "metadata": {},
   "source": [
    "## Activities\n",
    "\n",
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;\n",
    "\n",
    "2 - User and Project id extraction from JSON-LD files;\n",
    "\n",
    "3 - Queries Iroha 1 for User and Project accounts and checks the present values;\n",
    "\n",
    "4 - Sets details for both User and Project accounts in Iroha 1 providing a logical link between them for later references;\n",
    "\n",
    "5 - Queries the User and Project accounts again and checks the proper setting of details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79226aee-cfb3-4a03-b85a-18468e43a9aa",
   "metadata": {},
   "source": [
    "## Sequence Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aad64b-9986-49bf-bf43-1039243c4dd3",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'base',\n",
    "    'themeVariables': {\n",
    "      'primaryColor': '#ffffff',\n",
    "      'primaryTextColor': '#000000',\n",
    "      'primaryBorderColor': '#000000',\n",
    "      'lineColor': '#000000',\n",
    "      'secondaryColor': '#f4f4f4',\n",
    "      'secondaryTextColor': '#000000',\n",
    "      'tertiaryColor': '#d3d3d3',\n",
    "      'tertiaryTextColor': '#000000',\n",
    "      'background': '#ffffff',\n",
    "      'actorBkg': '#B4B4B4',\n",
    "      'actorTextColor': '#000000',\n",
    "      'actorBorder': '#000000',\n",
    "      'actorLineColor': '#000000',\n",
    "      'signalColor': '#000000',\n",
    "      'signalTextColor': '#000000',\n",
    "      'activationBorderColor': '#000000',\n",
    "      'activationBkgColor': '#d3d3d3',\n",
    "      'sequenceNumberColor': '#000000',\n",
    "      'noteBkgColor': '#F0F0F0',\n",
    "      'noteTextColor': '#000000',\n",
    "      'noteBorderColor': '#000000'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant self as \"self\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    \n",
    "\n",
    "    Note over Platform, Blockchain: Deploy smart contract for details setting\n",
    "    Platform->>Blockchain: Deploy Smart Contract\n",
    "    Blockchain-->>Platform: Smart Contract Deployed Successfully\n",
    "\n",
    "    Note over Platform, Blockchain: Extract user and project IDs from JSONs\n",
    "    Platform->>self: User ID Extraction\n",
    "    Platform->>self: Project ID Extraction\n",
    "\n",
    "    Note over Platform, Blockchain: Queries the blockchain for <br/>User and Project accounts details\n",
    "    Platform->>Blockchain: Get User Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "    Platform->>Blockchain: Get Project Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "    \n",
    "    Note over Platform, Blockchain: Set details for User and Project accounts\n",
    "    Platform->>Blockchain: Set User Details in Blockchain\n",
    "    Blockchain-->>Platform: User Details Set Successfully\n",
    "    Platform->>Blockchain: Set Project Details in Blockchain\n",
    "    Blockchain-->>Platform: Project Details Set Successfully\n",
    "    \n",
    "    Note over Platform, Blockchain: Queries the blockchain to <br/>confirm proper setting of details\n",
    "    Platform->>Blockchain: Get User Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "    Platform->>Blockchain: Get Project Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a043d51-4a22-4186-975e-7e3e8a4b54ef",
   "metadata": {},
   "source": [
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4a1c5a2-75c3-482e-999c-70eb25226078",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntering \"create_contract\"\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "\tLeaving \"create_contract\"\n",
      "\tEntering \"get_engine_receipts_result\"\n",
      "\n",
      "\tLeaving \"get_engine_receipts_result\"\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from Crypto.Hash import keccak\n",
    "import os\n",
    "import binascii\n",
    "from iroha import IrohaCrypto\n",
    "from iroha import Iroha, IrohaGrpc\n",
    "from iroha.ed25519 import H\n",
    "import integration_helpers\n",
    "from iroha.primitive_pb2 import can_set_my_account_detail\n",
    "import sys\n",
    "# import csv\n",
    "import json\n",
    "import icecream as ic\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Python 3 or a more recent version is required.\")\n",
    "\n",
    "# Load configuration from config.json file\n",
    "config_path = \"config.json\"  # Update this path as needed\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IROHA_HOST_ADDR = config[\"IROHA_HOST_ADDR\"]\n",
    "IROHA_PORT = config[\"IROHA_PORT\"]\n",
    "ADMIN_ACCOUNT_ID = config[\"ADMIN_ACCOUNT_ID\"]\n",
    "ADMIN_PRIVATE_KEY = config[\"ADMIN_PRIVATE_KEY\"]\n",
    "\n",
    "iroha = Iroha(ADMIN_ACCOUNT_ID)\n",
    "net = IrohaGrpc(\"{}:{}\".format(IROHA_HOST_ADDR, IROHA_PORT))\n",
    "\n",
    "\n",
    "@integration_helpers.trace\n",
    "def create_contract():\n",
    "    bytecode = \"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\"\n",
    "    \"\"\"Bytecode was generated using remix editor  https://remix.ethereum.org/ from file detail.sol. \"\"\"\n",
    "    tx = iroha.transaction(\n",
    "        [iroha.command(\"CallEngine\", caller=ADMIN_ACCOUNT_ID, input=bytecode)]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    net.send_tx(tx)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    return hex_hash\n",
    "\n",
    "hash = create_contract()\n",
    "integration_helpers.get_engine_receipts_result(hash)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea1051-cb1c-4c29-97e5-38ba90248081",
   "metadata": {},
   "source": [
    "2 - Data extraction from JSON-LD.\n",
    "\n",
    "Extracts account ids from `datasets/accounts.json` and `datasets/projects.json`.\n",
    "\n",
    "Must update `json_ld_index` with a entry number related to an existing object in `datasets/accounts.json` and `datasets/projects.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f8384a9-49db-44a2-b222-f3657a3bc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for objects in both user account and project account JSON-LDs.\n",
    "json_ld_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e068d0-2247-4fd3-827f-4144b66965e1",
   "metadata": {},
   "source": [
    "4 - Sets details for both User and Project accounts providing a logical link between them for later references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "126df4cd-d358-43cc-997f-e17453a5b8dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntering \"get_engine_receipts_address\"\n",
      "\tLeaving \"get_engine_receipts_address\"\n",
      "\tEntering \"get_engine_receipts_address\"\n",
      "\tLeaving \"get_engine_receipts_address\"\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Updated user account elastic_nash@test with linked project 74289@test\n",
      "Updated project account 74289@test with linked user elastic_nash@test\n",
      "User account elastic_nash@test linked to project 74289@test\n",
      "Project account 74289@test linked to user elastic_nash@test\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import binascii\n",
    "\n",
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "\n",
    "\n",
    "# Function to link details using blockchain\n",
    "def set_account_detail(address, account, key, value):\n",
    "    params = integration_helpers.get_first_four_bytes_of_keccak(\n",
    "        b\"setAccountDetail(string,string,string)\"\n",
    "    )\n",
    "    no_of_param = 3\n",
    "    for x in range(no_of_param):\n",
    "        params = params + integration_helpers.left_padded_address_of_param(\n",
    "            x, no_of_param\n",
    "        )\n",
    "    params = params + integration_helpers.argument_encoding(account)  # account id\n",
    "    params = params + integration_helpers.argument_encoding(key)  # key\n",
    "    params = params + integration_helpers.argument_encoding(value)  # value\n",
    "    tx = iroha.transaction(\n",
    "        [\n",
    "            iroha.command(\n",
    "                \"CallEngine\", caller=ADMIN_ACCOUNT_ID, callee=address, input=params\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    response = net.send_tx(tx)\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    return hex_hash\n",
    "\n",
    "# Function to update user account with linked project\n",
    "def update_user_account_link(user_account_id, linked_project_id, accounts_filename=\"datasets/accounts.json\"):\n",
    "    try:\n",
    "        if os.path.exists(accounts_filename):\n",
    "            with open(accounts_filename, mode='r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "        else:\n",
    "            print(f\"{accounts_filename} does not exist.\")\n",
    "            return\n",
    "\n",
    "        user_found = False\n",
    "\n",
    "        # Look for the user account and update it\n",
    "        for entry in data[\"@graph\"]:\n",
    "            if entry[\"@type\"] == \"foaf:Person\" and entry.get(\"foaf:holdsAccount\", {}).get(\"schema:identifier\") == user_account_id:\n",
    "                entry[\"schema:linked_project\"] = linked_project_id\n",
    "                user_found = True\n",
    "                print(f\"Updated user account {user_account_id} with linked project {linked_project_id}\")\n",
    "                break\n",
    "\n",
    "        if not user_found:\n",
    "            print(f\"User account {user_account_id} not found.\")\n",
    "\n",
    "        # Write back the updated data\n",
    "        with open(accounts_filename, mode='w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating user account in JSON-LD: {str(e)}\")\n",
    "\n",
    "\n",
    "# Function to update project account with linked user\n",
    "def update_project_account_link(project_account_id, linked_user_id, projects_filename=\"datasets/projects.json\"):\n",
    "    try:\n",
    "        if os.path.exists(projects_filename):\n",
    "            with open(projects_filename, mode='r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "        else:\n",
    "            print(f\"{projects_filename} does not exist.\")\n",
    "            return\n",
    "\n",
    "        project_found = False\n",
    "\n",
    "        # Look for the project account and update it\n",
    "        for entry in data[\"@graph\"]:\n",
    "            if entry[\"@type\"] == \"schema:ResearchProject\" and entry.get(\"schema:identifier\") == project_account_id:\n",
    "                entry[\"schema:linked_user\"] = linked_user_id\n",
    "                project_found = True\n",
    "                print(f\"Updated project account {project_account_id} with linked user {linked_user_id}\")\n",
    "                break\n",
    "\n",
    "        if not project_found:\n",
    "            print(f\"Project account {project_account_id} not found.\")\n",
    "\n",
    "        # Write back the updated data\n",
    "        with open(projects_filename, mode='w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating project account in JSON-LD: {str(e)}\")\n",
    "\n",
    "\n",
    "# Function to read accounts from JSON-LD\n",
    "def read_user_accounts_from_jsonld(file_path):\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        user_accounts = []\n",
    "        for entry in data[\"@graph\"]:\n",
    "            if entry[\"@type\"] == \"foaf:Person\":\n",
    "                account_id = entry.get(\"foaf:holdsAccount\", {}).get(\"schema:identifier\")\n",
    "                if account_id:\n",
    "                    user_accounts.append({'account_id': account_id})\n",
    "        return user_accounts\n",
    "\n",
    "\n",
    "def read_project_accounts_from_jsonld(file_path):\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        project_accounts = []\n",
    "        for entry in data[\"@graph\"]:\n",
    "            if entry[\"@type\"] == \"schema:ResearchProject\":\n",
    "                project_id = entry.get(\"schema:identifier\")\n",
    "                if project_id:\n",
    "                    project_accounts.append({'account_id': project_id})\n",
    "        return project_accounts\n",
    "\n",
    "\n",
    "# Example execution of the previous snippet\n",
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "\n",
    "# Read accounts from JSON-LD\n",
    "user_accounts = read_user_accounts_from_jsonld('datasets/accounts.json')\n",
    "project_accounts = read_project_accounts_from_jsonld('datasets/projects.json')\n",
    "\n",
    "# Assuming json_ld_index is defined\n",
    "user_account = user_accounts[json_ld_index]\n",
    "project_account = project_accounts[json_ld_index]\n",
    "\n",
    "# Set project_id as a detail for the user account\n",
    "hash_user_to_project = set_account_detail(\n",
    "    address, \n",
    "    user_account['account_id'], \n",
    "    \"linked_project\", \n",
    "    project_account['account_id']\n",
    ")\n",
    "\n",
    "# Set user_account_id as a detail for the project account\n",
    "hash_project_to_user = set_account_detail(\n",
    "    address, \n",
    "    project_account['account_id'], \n",
    "    \"linked_user\", \n",
    "    user_account['account_id']\n",
    ")\n",
    "\n",
    "# Update the JSON-LD files with the linked details\n",
    "update_user_account_link(user_account['account_id'], project_account['account_id'])\n",
    "update_project_account_link(project_account['account_id'], user_account['account_id'])\n",
    "\n",
    "# Confirming the operation\n",
    "print(f\"User account {user_account['account_id']} linked to project {project_account['account_id']}\")\n",
    "print(f\"Project account {project_account['account_id']} linked to user {user_account['account_id']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562857c-d86d-42cf-a24b-23a5c3f5cb4e",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for User account and checks its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b52e47a4-b1c5-4ebe-a2d8-8edae10063d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Account id = {'account_id': 'elastic_nash@test'}, { \"admin@test\" : { \"linked_project\" : \"74289@test\", \"user_json_ld_cid\" : \"QmaDL95RhUXrndqguiDw4raBZG11opEuwx3BgCW9VhVKc6\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=user_account['account_id'])\n",
    "# print(query)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "\n",
    "user_data = response.account_detail_response\n",
    "user_details = user_data.detail\n",
    "\n",
    "\n",
    "print(f'User Account id = {user_account}, {user_details}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a556f-b657-4a6a-8c9f-b18aac8f8375",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for Project account and checks its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d39cb27c-4f7d-48dd-a137-6bceb294c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '74289@test'}, { \"admin@test\" : { \"file_1_CID\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\", \"linked_user\" : \"elastic_nash@test\", \"project_metadata_cid\" : \"QmYLGs2hzebM56odvitzKoW4SDyAStJsAHYmLeUD8SERHR\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=project_account['account_id'])\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f660b-56d6-4ea0-bd2b-e3bb54ecd05b",
   "metadata": {},
   "source": [
    "# Part2 - Querying Project Metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986de21a-9ddc-4aea-b63d-47a6a0323871",
   "metadata": {},
   "source": [
    "## Activities\n",
    "\n",
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0445f-998d-4470-9dfa-252caf810921",
   "metadata": {},
   "source": [
    "## Sequence Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e812f7b-8439-4e65-883c-de57b8e81097",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'base',\n",
    "    'themeVariables': {\n",
    "      'primaryColor': '#ffffff',\n",
    "      'primaryTextColor': '#000000',\n",
    "      'primaryBorderColor': '#000000',\n",
    "      'lineColor': '#000000',\n",
    "      'secondaryColor': '#f4f4f4',\n",
    "      'secondaryTextColor': '#000000',\n",
    "      'tertiaryColor': '#d3d3d3',\n",
    "      'tertiaryTextColor': '#000000',\n",
    "      'background': '#ffffff',\n",
    "      'actorBkg': '#B4B4B4',\n",
    "      'actorTextColor': '#000000',\n",
    "      'actorBorder': '#000000',\n",
    "      'actorLineColor': '#000000',\n",
    "      'signalColor': '#000000',\n",
    "      'signalTextColor': '#000000',\n",
    "      'activationBorderColor': '#000000',\n",
    "      'activationBkgColor': '#d3d3d3',\n",
    "      'sequenceNumberColor': '#000000',\n",
    "      'noteBkgColor': '#F0F0F0',\n",
    "      'noteTextColor': '#000000',\n",
    "      'noteBorderColor': '#000000'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "    participant FrontEnd as \"Front End\"\n",
    "\n",
    "    Note over Platform, Blockchain: Queries the user account <br/> and get the project id \n",
    "    Platform->>Blockchain: Query User Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "        \n",
    "    Note over Platform, Blockchain: Queries the Project Account details <br/> and get the project metadata CID \n",
    "    Platform->>Blockchain: Query Project Account Details\n",
    "    Blockchain-->>Platform: Query Response\n",
    "\n",
    "    Note over Platform, IPFS: Process and displays the metadata CID \n",
    "    Platform->>IPFS: Sends the project metadata CID\n",
    "    IPFS-->>Platform: Sends back the project metadata JSON\n",
    "    Platform->>FrontEnd: Displays the project metadata JSON   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f33098-43df-47f3-8708-f3212dec1c0f",
   "metadata": {},
   "source": [
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "374843b3-6862-4a93-b298-1bdd0320c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"admin@test\" : { \"linked_project\" : \"74289@test\", \"user_json_ld_cid\" : \"QmaDL95RhUXrndqguiDw4raBZG11opEuwx3BgCW9VhVKc6\" } }\n",
      "{'admin@test': {'linked_project': '74289@test', 'user_json_ld_cid': 'QmaDL95RhUXrndqguiDw4raBZG11opEuwx3BgCW9VhVKc6'}}\n",
      "74289@test\n"
     ]
    }
   ],
   "source": [
    "from ipfs_functions import *\n",
    "\n",
    "print(user_details)\n",
    "\n",
    "# Process the account details response\n",
    "user_details_dict = json.loads(user_details)  # Convert the string to a JSON object\n",
    "print(user_details_dict)\n",
    "\n",
    "# Now you can access the specific key like this\n",
    "linked_project = user_details_dict[\"admin@test\"][\"linked_project\"]\n",
    "print(linked_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66b2f2c1-00b1-4b1b-8951-196af1f25208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '74289@test'}, { \"admin@test\" : { \"file_1_CID\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\", \"linked_user\" : \"elastic_nash@test\", \"project_metadata_cid\" : \"QmYLGs2hzebM56odvitzKoW4SDyAStJsAHYmLeUD8SERHR\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail', account_id=linked_project)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e7130f8-ad7d-4d0b-a521-ba0de69e9271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QmYLGs2hzebM56odvitzKoW4SDyAStJsAHYmLeUD8SERHR\n",
      "{'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how hydrogen energy influences space exploration, providing insights into how to maximize its resilience building.', 'schema:endDate': '2027-09-26', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'National Science Foundation'}, 'schema:keywords': ['hydrogen energy', 'space exploration', 'resilience building'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Accra, Ghana'}, 'schema:name': 'Analyzing the Influence of hydrogen energy on space exploration', 'schema:startDate': '2024-09-24'}\n"
     ]
    }
   ],
   "source": [
    "# Convert the JSON string to a Python dictionary\n",
    "project_details_dict = json.loads(project_details)\n",
    "\n",
    "# Now you can access the specific key like this\n",
    "project_metadata_cid = project_details_dict[\"admin@test\"][\"project_metadata_cid\"]\n",
    "print(project_metadata_cid)\n",
    "\n",
    "\n",
    "project_metadata = download_json_from_ipfs(project_metadata_cid)\n",
    "\n",
    "# print(20*\"-\")\n",
    "\n",
    "print(project_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31163ee6-8c5a-4cd3-8951-9190665abd5a",
   "metadata": {},
   "source": [
    "# Part 3 - File Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d265a-50e1-423d-9e53-26226afe7756",
   "metadata": {},
   "source": [
    "7 -  Sends every file in the `upload` directory to IPFS, extracts theirs respective metadata with Apache Tika and sends it to IPFS, get the CIDs back and store in Iroha as details of the project account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419c69e-9fbb-474b-ab9b-4ffdc38403ee",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'base',\n",
    "    'themeVariables': {\n",
    "      'primaryColor': '#ffffff',\n",
    "      'primaryTextColor': '#000000',\n",
    "      'primaryBorderColor': '#000000',\n",
    "      'lineColor': '#000000',\n",
    "      'secondaryColor': '#f4f4f4',\n",
    "      'secondaryTextColor': '#000000',\n",
    "      'tertiaryColor': '#d3d3d3',\n",
    "      'tertiaryTextColor': '#000000',\n",
    "      'background': '#ffffff',\n",
    "      'actorBkg': '#B4B4B4',\n",
    "      'actorTextColor': '#000000',\n",
    "      'actorBorder': '#000000',\n",
    "      'actorLineColor': '#000000',\n",
    "      'signalColor': '#000000',\n",
    "      'signalTextColor': '#000000',\n",
    "      'activationBorderColor': '#000000',\n",
    "      'activationBkgColor': '#d3d3d3',\n",
    "      'sequenceNumberColor': '#000000',\n",
    "      'noteBkgColor': '#F0F0F0',\n",
    "      'noteTextColor': '#000000',\n",
    "      'noteBorderColor': '#000000'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant Metadata Extractor\n",
    "    participant Indexer\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "\n",
    "    Note over Platform, IPFS: File Operations \n",
    "    Platform->>IPFS: Upload local file to IPFS\n",
    "    IPFS-->>Platform: Send back file CIDs\n",
    "    Platform->>Blockchain: Set CID as Project Account Details\n",
    "    Blockchain-->>Platform:Details set successfully\n",
    "\n",
    "    Note over Platform, IPFS: File Metadata Operations\n",
    "    Platform->>Metadata Extractor: Parse file and extract metadata \n",
    "    Metadata Extractor->>Indexer: Send file metadata for indexing\n",
    "    Indexer->>IPFS: Store file metadata JSON\n",
    "    IPFS-->>Platform: Send back file metadata JSON CIDs\n",
    "    Platform->>Blockchain: Set file metadata JSON CID as Project Account Details\n",
    "    Blockchain-->>Platform:Details set successfully\n",
    "         \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Opened existing index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Index recreated.\n",
      "INFO:root:Processing file: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "INFO:root:File COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf uploaded to IPFS with CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74289@test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Indexed COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf with CID: QmbvhUdVof8L8o3zoGQuXkXQYnUwpHG1fxK3ZhtqkAD7b8\n",
      "INFO:root:Document COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf indexed successfully.\n",
      "INFO:root:updated project entry\n",
      "INFO:root:File COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf uploaded to IPFS with CID: QmbvhUdVof8L8o3zoGQuXkXQYnUwpHG1fxK3ZhtqkAD7b8\n",
      "INFO:root:----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:containsNonEmbeddedFont': 'false', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:hasMarkedContent': 'false', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119549', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'dc:language': 'en-US', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '16', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'X-TIKA:parse_time_millis': '434', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'CrossmarkMajorVersionDate': '2010-04-23'}, 'content': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,∗\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors’ apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; Štifanić et al., 2020). Based on this, we conducted\\n\\n∗ Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors’ investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/© 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (Štifanić et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market’s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu’s index, and the media informa-\\ntion statistics all reflect COVID-19’s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task’s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n• A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n• Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n• Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN’s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\nŠtifanić et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China’s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers’ evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays’ data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix 𝛽 of the market sentiment index (where\\n𝑋, 𝑌 ... 𝑍 represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n𝛽 =\\n\\n⎡\\n\\n⎢\\n\\n⎢\\n\\n⎢\\n\\n⎢\\n\\nX1 Y1 Z1\\nX2 Y2 ⋯ Z2\\n\\n⋮ ⋱ ⋮\\n\\n⎤\\n\\n⎥\\n\\n⎥\\n\\n⎥\\n\\n⎥\\n\\n(1)\\n5\\n\\n⎣\\n\\nX𝑚 Y𝑚 ⋯ Z𝑚 ⎦\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix 𝛽 is normalized using Eq. (2) to obtain the\\nnormalization matrix 𝑆.\\n\\n𝑆𝑖𝑗 =\\n𝑥𝑖𝑗 − �̄�𝑗\\n\\n𝜎𝑗\\n, 𝑖 = 1, 2,… , 𝑚; 𝑗 = 1, 2,… , 𝑝 (2)\\n\\nwhere 𝑝 denotes the number of columns, 𝑥𝑖𝑗 denotes the data matrix\\n𝛽 values, and �̄�𝑗 , 𝜎𝑗 denote the mean and standard deviation of each\\ncomponent 𝑗.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n𝑅 − 𝜆𝑗𝐼\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere 𝑅 denotes the correlation coefficient matrix of matrix 𝑆, and 𝑝\\neigenvalues 𝜆𝑗 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A𝑔𝑗 (𝑔\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value 𝑌𝑔 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) 𝑀𝑚 is\\ncalculated.\\n\\nA𝑔𝑗 = U𝑔 ∗\\n√\\n\\n𝑌𝑔 (4)\\n\\n𝑌𝑔 =\\n∑\\n\\n(\\n\\nA𝑔𝑗 ∗ 𝛽\\n)\\n\\n(5)\\n\\n𝑀𝑚 =\\n∑\\n\\n(\\n\\n𝑌𝑔 ∗ 𝜆𝑔\\n)\\n\\n(6)\\n\\nwhere U𝑔 is the loading of the principal component, 𝑌𝑔 represents\\nthe eigenvalue corresponding to each principal component, 𝑌𝑔 repre-\\nsents the 𝑔th principal component, and 𝜆𝑔 represents the eigenvalue\\ncorresponding to the 𝑔th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April–July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n𝑟 =\\n∑𝑚\\n\\n𝑖=1\\n(\\n\\n𝑋𝑖 − �̄�\\n) (\\n\\n𝑌𝑖 − 𝑌\\n)\\n\\n√\\n\\n∑𝑚\\n𝑖=1\\n\\n(\\n\\n𝑋𝑖 − �̄�\\n)2\\n√\\n\\n∑𝑚\\n𝑖=1\\n\\n(\\n\\n𝑌𝑖 − 𝑌\\n)2\\n\\n(7)\\n\\nwhere 𝑋 and 𝑌 denote the series values of NMSI and CSI 300, �̄�, 𝑌\\nenote the mean values of NMSI and CSI 300 series data, and 𝑚 is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords ‘‘epidemic’’ in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf ‘‘COVID-19’’ in online information increases, investors’ investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of ‘‘COVID-19’’ decreases and the number of cured cases\\nncreases, investors’ investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the ‘‘Omicron’’ COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany’s DAX closing down\\n.15%, the largest one-day drop since 2021, and France’s CAC 40 and\\nhe UK’s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019–2021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February–March\\n020, February 2021 and July–August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence 𝐶𝑚 of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 −0.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index’s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence 𝑋(𝑚) =\\n\\n[\\n\\n𝑥1, 𝑥2, 𝑥3 … 𝑥𝑚\\n]\\n\\n.\\n\\nmin\\n𝜔𝑘 ,𝑉𝑘)\\n\\n{ 𝑛\\n∑\\n\\n𝑘=1\\n\\n‖\\n\\n‖\\n\\n‖\\n\\n𝜕𝑚\\n[\\n\\n(𝛿(𝑚) + 𝑗∕𝜋𝑚) ∗ 𝑉𝑘(𝑚)\\n]\\n\\n𝑒−𝑗𝜔𝑖𝑚‖\\n‖\\n\\n‖\\n\\n2\\n\\n2\\n\\n}\\n\\n𝑛\\n∑\\n\\n𝑘=1\\n𝑉𝑘 = 𝑋(𝑚)\\n\\n(8)\\n\\nwhere 𝑚 denotes each moment of the sequence, 𝑋(𝑚) is the original\\nequence of stock prices, 𝑘 is the number of modes, 𝛿(𝑚) is the Dirichlet\\nunction, ∗ denotes the convolution, 𝑗 =\\n\\n√\\n\\n−1, and 𝜕𝑚 is the partial\\nderivative. After decomposition, 𝑘 discrete modes are obtained, and\\nthe component of each mode 𝑘 is 𝑉𝑘, and each 𝑉𝑘 is concentrated\\naround the center frequency 𝜔𝑘 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as 𝑉𝑘=1 =\\n\\n[\\n\\n𝐿1, 𝐿2, 𝐿3 …𝐿𝑚\\n]\\n\\n. To better illustrate this,\\nthe first three values 𝑋1, 𝑋2, 𝑋3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series 𝑉 1\\n\\n𝑘=1 =\\n[\\n\\n𝐿1\\n1, 𝐿\\n\\n1\\n2, 𝐿\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of 𝑉𝑘=1 and 𝑉 1\\n\\n𝑘=1 are not equal,\\nindicating that 𝑉𝑘=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of 𝑋. The local values of 𝑉𝑘=1 still\\ncontain some information of the whole sequence. Therefore, using 𝑉𝑘=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019–2021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series 𝑉𝑚1, 𝑉𝑚2, 𝑉𝑚3,… , 𝑉𝑚𝑘 is obtained after decomposing the\\ndata in each window of 𝑋(𝑚) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 – –\\nMACD 0.11 1 –\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n𝑇𝑚 =\\n\\n⎡\\n\\n⎢\\n\\n⎢\\n\\n⎢\\n\\n⎢\\n\\n⎣\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 ⋯ RSI 2\\n\\n⋮ ⋱ ⋮\\n𝑀𝐴5𝑚 MA15 𝑚 ⋯ RSI 𝑚\\n\\n⎤\\n\\n⎥\\n\\n⎥\\n\\n⎥\\n\\n⎥\\n\\n⎦\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n𝑉𝑚1, 𝑉𝑚2, 𝑉𝑚3,… , 𝑉𝑚𝑘 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence 𝑀𝑚, the COVID-19 Index 𝐶𝑚 and\\nhe stock price technical indicator sequence 𝑇𝑚, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence 𝑉𝑚1, the\\nmarket sentiment indicator sequence 𝑀𝑚 and the stock price technical\\nindicator sequence 𝑇𝑚 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix 𝐻\\n\\n[\\n\\n𝑉𝑚1,𝑀𝑚, 𝑇𝑚\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in 𝐻 all reflect the long-term trend\\nof stock prices, 𝐻 can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix 𝐻 is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. 𝐻 with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n𝐻1 = Attention (𝑄,𝐾, 𝑉 ) = sof tmax\\n\\n(\\n\\n𝑄𝐾𝑇\\n√\\n\\n𝑑\\n\\n)\\n\\n𝑉 (10)\\n\\nWhere 𝑄, 𝐾, 𝑉 are the same tensor as 𝐻 as shown in Eq. (11), 𝑑\\ndenotes the feature dimension of 𝑄, and 𝑠𝑜𝑓𝑡𝑚𝑎𝑥 denotes the activation\\nfunction.\\n𝑄 = 𝑾 𝑞𝐻\\n\\n𝐾 = 𝑾 𝑘𝐻\\n\\n𝑉 = 𝑾 𝑣𝐻\\n\\n(11)\\n\\nWhere 𝑾 𝑞 ,𝑾 𝑘,𝑾 𝑣 denote the parameter matrix. Then the obtained\\n𝐻1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (𝑡) =\\n𝑘\\n∑\\n\\n𝑓𝑖𝐻\\n1\\n𝑡−𝑑⋅𝑖 (12)\\n9\\n\\n𝑖=1\\nwhere 𝑓 =\\n(\\n\\n𝑓1, 𝑓2,… , 𝑓𝑘\\n)\\n\\ndenotes the convolutional kernel, 𝑘 is the\\nsize of convolutional kernels, 𝑑 is the expansion coefficient, and 𝐻1\\n\\n𝑡−𝑑⋅𝑖\\nrepresents the feature matrix before moment 𝑡. Where each residual\\nmodule is subjected to two \\ue232 (⋅) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n𝐻1 + \\ue232\\n(\\n\\n𝐻1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n𝐺𝑙 =\\n𝑙\\n\\n∑\\n\\n𝑡=1\\n\\nexp\\n(\\n\\n𝛽T tanh\\n(\\n\\n𝜔𝑟\\ue232 (𝑡) + 𝑏𝑟\\n))\\n\\n∑𝑛\\n𝑡=1 exp\\n\\n(\\n\\n𝛽T tanh\\n(\\n\\n𝜔𝑟\\ue232 (𝑡) + 𝑏𝑟\\n))\\ue232 (𝑡) (14)\\n\\nWhere 𝛽T, 𝜔𝑟 are the parameter matrices, 𝑏𝑟 denotes the bias vector,\\n𝑡𝑎𝑛ℎ is the activation function, and 𝑙 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n𝐺𝑙\\n\\n[\\n\\n𝐺1, 𝐺2 …𝐺𝑙\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences 𝑉 , 𝑉 ,… , 𝑉 in\\n𝑚2 𝑚3 𝑚𝑘\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n𝑆1\\n[\\n\\n𝑉𝑚2, 𝐶𝑚\\n]\\n\\n, 𝑆2\\n[\\n\\n𝑉𝑚3, 𝐶𝑚\\n]\\n\\n,… , of number 𝑘 − 1 and length 𝑚 The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix 𝑆 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)–(21).\\n\\n𝑖𝑡 = 𝜎\\n(\\n\\n𝑊𝑖\\n[\\n\\nℎ𝑡−1, 𝑥𝑡\\n]\\n\\n+ 𝑏𝑖\\n)\\n\\n(15)\\n\\n𝑓𝑡 = 𝜎\\n(\\n\\n𝑊𝑓\\n[\\n\\nℎ𝑡−1, 𝑥𝑡\\n]\\n\\n+ 𝑏𝑓\\n)\\n\\n(16)\\n\\n�̃�𝑡 = tanh\\n(\\n\\n𝑊𝐶\\n[\\n\\nℎ𝑡−1, 𝑥𝑡\\n]\\n\\n+ 𝑏𝐶\\n)\\n\\n(17)\\n\\n𝑜𝑡 = 𝜎\\n(\\n\\n𝑊𝑜\\n[\\n\\nℎ𝑡−1, 𝑥𝑡\\n]\\n\\n+ 𝑏𝑜\\n)\\n\\n(18)\\n\\n𝐶𝑡 = 𝑓𝑡◦𝐶𝑡−1 + 𝑖𝑡◦�̃�𝑡 (19)\\n\\nℎ𝑡 = 𝑜𝑡◦ tanh\\n(\\n\\n𝐶𝑡\\n)\\n\\n(20)\\n\\n𝐵 = ⃖⃖⃖⃖⃖⃗[\\n\\nℎ , ⃖⃖ ⃖ℎ\\n]\\n\\n(21)\\n10\\n\\n𝑡 𝑡 𝑡\\nWhere Eq. (15)–Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. 𝜎, 𝑡𝑎𝑛ℎ denote the activation function, 𝑊𝑖,𝑊𝐶 ,𝑊𝑓 ,𝑊𝑜\\ndenote the parameter matrix, 𝑏𝑖, 𝑏𝑐 , 𝑏𝑓 , 𝑏𝑜 denote the bias vectors, where\\n◦ denotes the Hadamard product (element-wise multiplication), ℎ𝑡−1\\ndenotes the hidden state value at the previous moment, 𝑥𝑡 denotes the\\ninput at the current moment, �̃�𝑡 denotes the temporary hidden variable\\nat the current moment, ℎ⃗𝑡 denotes the cell forward structural state, ⃖⃖ ⃖ℎ𝑡\\ndenotes the cell backward structural state, and 𝐵𝑡 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n𝜁𝑡 = 𝑎T tanh\\n(\\n\\n𝜔𝐵𝑡 + 𝑏𝑣\\n)\\n\\n(22)\\n\\n𝑃𝑡 =\\nexp\\n\\n(\\n\\n𝜁𝑡\\n)\\n\\n∑𝑛\\n𝑡=1 exp\\n\\n(\\n\\n𝜁𝑡\\n) (23)\\n\\n𝐷𝑡 =\\n𝑛\\n∑\\n\\n𝑡=1\\n𝑃𝑡𝐵𝑡 (24)\\n\\nwhere 𝑎, 𝜔 denote the parameter matrix, 𝜁 calculates the attention\\nweights for 𝐵𝑡. Finally, after calculating the probability 𝑃𝑡 of the\\nattention weight, perform a weighted summation,calculate output 𝐷𝑡\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted 𝑘−1 local\\nfeatures 𝐷𝑙\\n\\n[\\n\\n𝐷1, 𝐷2,… , 𝐷𝑙\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model’s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n𝑑\\n(\\n\\n𝑥𝑗 , 𝑥𝑖\\n)\\n\\n= 1\\n√\\n\\n∑𝑛\\n𝑝=1\\n\\n(\\n\\n𝑥∗𝑝 − 𝑥𝑝\\n)2\\n\\n, 𝑝 = 1, 2,… , 𝑙 (25)\\n\\nwhere 𝑥∗𝑗 (𝑗 = 1, 2,… , 𝑛) is the data to be classified in the test set and\\n𝑥𝑖(𝑖 = 1, 2,… , 𝑙) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series 𝑋𝑙 and the global features 𝐺𝑙 (feature 1)\\nand local features 𝐷𝑙 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix 𝑊𝑙 =\\n\\n[\\n\\n𝑋𝑙 , 𝐺𝑙 , 𝐷𝑙\\n]\\n\\n, and set the stock price series 𝑋𝑡 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n𝑋𝑡 =\\n\\n{\\n\\n1 𝑋𝑡+1 ≥ 𝑋𝑡\\n\\n0 𝑋𝑡+1 < 𝑋𝑡\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n�̂�(𝑡+1) = 𝐹\\n(\\n\\n𝑊 𝑡−𝜕\\n𝑙 ,𝑊 𝑡−𝜕+1\\n\\n𝑙 ,… ,𝑊 𝑡\\n𝑙\\n)\\n\\n(27)\\n\\nwhere �̂�(𝑡+1) is the prediction result, 𝐹 (⋅) is the set KNN classification\\nmodel, and 𝜕 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n𝑙\\n\\n𝑙\\n∑\\n\\n𝑖=1\\n\\n(\\n\\n�̂�𝑖 − 𝑦𝑖\\n)2 (28)\\n\\nwhere �̂�𝑖 denotes the predicted value of the network, 𝑦𝑖 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n𝑥∗ =\\n𝑥 − 𝑥min\\n\\n𝑥max − 𝑥min\\n(29)\\n\\nAmong of them, 𝑥 is the original data, 𝑥 is the normalized data.\\n11\\n\\n∗\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = 𝑇𝑃 + 𝑇𝑁\\n𝑇𝑃 + 𝐹𝑃 + 𝑇𝑁 + 𝐹𝑁\\n\\n(30)\\n\\n𝑀𝐶𝐶 = 𝑇𝑃 × 𝑇𝑁 − 𝐹𝑃 × 𝐹𝑁\\n√\\n\\n(𝑇𝑃 + 𝐹𝑃 ) × (𝑇𝑃 + 𝐹𝑁) × (𝑇𝑁 + 𝐹𝑃 ) × (𝑇𝑁 + 𝐹𝑁)\\n(31)\\n\\n𝐹 − score = 2 ⋅ Precision ⋅ Recall\\nPrecision + Recall (32)\\n\\nwhere 𝑇𝑃 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, 𝐹𝑃 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, 𝐹𝑁 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, 𝑇𝑁 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. 𝑃𝑡 is the net value of the product in a certain day,\\nand 𝑃𝑦 is the net value of the product in a certain day after 𝑡, 𝑘 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n𝑃𝑡\\n𝑃𝑡−𝑘\\n\\n− 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n𝑃𝑥 − 𝑃𝑦\\n)\\n\\n𝑃𝑥\\n(34)\\n\\nwhere 𝑅𝑒𝑐𝑎𝑙𝑙 denotes the recall rate, 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = 𝑇𝑃\\n𝑇𝑃 + 𝐹𝑁\\n\\n(35)\\n\\nPrecision = 𝑇𝑃\\n𝑇𝑃 + 𝐹𝑃\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% −7.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% −10.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% −7.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% −2.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% −6.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% −2.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% −3.76% 10.86%\\nNaive 43.23% −13.58% 44.10% −16.75% 18.59%\\nBuy and Hold – – – −14.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today’s up and down as tomorrow’s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% −6.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% −5.97% 10.67%\\nKNN 50.52% 1.38% 43.11% −5.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days 𝜕, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days 𝜕 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days 𝜕.\\n\\nEnter days 𝜕=15 𝜕=20 𝜕=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing – original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing – review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357–386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151–156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645–1680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129–152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340–355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381–402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160–167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965–2969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177–1183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383–417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324–328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\nŠ\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833–2854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440–1448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965–989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China’s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735–1780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261–269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104–109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23–27.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268–273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141–1151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64–82.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483–497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1–8). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239–255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078–0086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Naïve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670–680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381–392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285–3292). IEEE.\\n\\ntifanić, D., Musulin, J., Miočević, A., Baressi Šegota, S., Šubić, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China’s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18–25.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174–184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221–228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710–2719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n', 'status': 200}\n",
      "Dublin Core Metadata:\n",
      "{\n",
      "    \"dc:format\": \"application/pdf; version=1.7\",\n",
      "    \"dc:title\": \"COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\",\n",
      "    \"dc:description\": \"Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "    \"dc:creator\": [\n",
      "        \"Chenxun Yuan\",\n",
      "        \"Xiang Ma\",\n",
      "        \"Hua Wang\",\n",
      "        \"Caiming Zhang\",\n",
      "        \"Xuemei Li\"\n",
      "    ],\n",
      "    \"dcterms:created\": \"2023-02-04T09:40:15Z\",\n",
      "    \"dcterms:modified\": \"2023-02-07T16:52:03Z\",\n",
      "    \"dc:language\": \"en-US\",\n",
      "    \"dc:subject\": [\n",
      "        \"Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier\",\n",
      "        \"Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\"\n",
      "    ]\n",
      "}\n",
      "Loaded project data successfully.\n",
      "Current project_data: {\n",
      "    \"@context\": {\n",
      "        \"schema\": \"http://schema.org/\",\n",
      "        \"dc\": \"http://purl.org/dc/terms/\"\n",
      "    },\n",
      "    \"@graph\": [\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"74289@test\",\n",
      "            \"schema:publicKey\": \"57bee5e0e23f723760b8e1b21a3a9afa61acece6c3b18f5eca3ee88eaee99ff8\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of hydrogen energy on space exploration\",\n",
      "                \"dc:abstract\": \"This paper analyzes how hydrogen energy influences space exploration, providing insights into how to maximize its resilience building.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"hydrogen energy\",\n",
      "                    \"space exploration\",\n",
      "                    \"resilience building\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2024-09-24\",\n",
      "                \"schema:endDate\": \"2027-09-26\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Accra, Ghana\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmYLGs2hzebM56odvitzKoW4SDyAStJsAHYmLeUD8SERHR\",\n",
      "            \"schema:linked_user\": \"elastic_nash@test\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Checking project with ID: '74289@test' against '74289@test'\n",
      "Match found for project ID: 74289@test\n",
      "Updated project 74289@test with new file entry: {'file_index': 1, 'file_cid': 'QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW', 'metadata_cid': 'QmbvhUdVof8L8o3zoGQuXkXQYnUwpHG1fxK3ZhtqkAD7b8', 'metadata': {'dc:format': 'application/pdf; version=1.7', 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549']}}\n",
      "Successfully wrote updated data to datasets/projects.json\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:All documents processed and index committed.\n"
     ]
    }
   ],
   "source": [
    "### New version\n",
    "\n",
    "from whoosh.index import create_in, open_dir, EmptyIndexError  # Import EmptyIndexError\n",
    "from metadata_helper import *\n",
    "import os\n",
    "import logging\n",
    "import mimetypes\n",
    "from tika import parser  # Import Apache Tika\n",
    "\n",
    "print(project_account['account_id'])\n",
    "\n",
    "# Function to extract only Dublin Core related metadata\n",
    "def extract_dublin_core(metadata):\n",
    "    \"\"\"Extracts only Dublin Core related metadata.\"\"\"\n",
    "    return {k: v for k, v in metadata.items() if k.startswith('dc:') or k.startswith('dcterms:')}\n",
    "\n",
    "\n",
    "# Function to parse and index documents from a directory\n",
    "def parse_documents_in_directory(directory_path, schema, linked_project, recreate=True):\n",
    "    \"\"\"Parses documents in a directory and indexes them.\"\"\"\n",
    "    ix = recreate_index(schema) if recreate else create_in(\"indexdir\", schema)\n",
    "    writer = get_writer_with_retry(ix)\n",
    "    index = 1\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        logging.info(f\"Processing file: {filename}\")\n",
    "\n",
    "        if not os.path.basename(filename).startswith('.'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            try:\n",
    "                # Upload the file to IPFS and get its CID\n",
    "                file_cid = upload_file_to_ipfs(file_path)\n",
    "                logging.info(f\"File {filename} uploaded to IPFS with CID: {file_cid}\")\n",
    "\n",
    "                \n",
    "                # Update the project details in the Iroha 1 blockchain\n",
    "                hash = set_account_detail(address, project_account['account_id'], f\"file_{index}_CID\", file_cid)\n",
    "\n",
    "\n",
    "                # Parse the document using Apache Tika\n",
    "\n",
    "                try:\n",
    "                    parsed_document = parser.from_file(file_path)\n",
    "                    print(parsed_document)\n",
    "                except Exception as e:\n",
    "                        logging.error(f\"Error parsing file with Tika: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if parsed_document:\n",
    "                    metadata = parsed_document.get('metadata', {})\n",
    "                    full_text = parsed_document.get(\"content\", \"\").strip() or \"No content extracted\"\n",
    "\n",
    "                    # Extract Dublin Core related metadata\n",
    "                    dublin_core_metadata = extract_dublin_core(metadata)\n",
    "                    \n",
    "                    # Normalize and upload JSON metadata to IPFS\n",
    "                    normalized_metadata = {\n",
    "                        'project_id': linked_project,\n",
    "                        'cid': upload_json_to_ipfs(metadata),  # Upload the full metadata\n",
    "                        'name': filename,\n",
    "                        'size': os.path.getsize(file_path),\n",
    "                        'filetype': mimetypes.guess_type(filename)[0] or \"unknown\",\n",
    "                        'title': normalize_metadata_value(metadata.get(\"dc:title\", f\"Document {index}\")),\n",
    "                        'creator': normalize_metadata_value(metadata.get(\"dc:creator\", \"Unknown\")),\n",
    "                        'language': normalize_metadata_value(metadata.get(\"dc:language\", \"en\")),\n",
    "                        'subject': normalize_metadata_value(metadata.get(\"dc:subject\", \"\")),\n",
    "                        'description': normalize_metadata_value(metadata.get(\"dc:description\", \"\")),\n",
    "                        'publisher': normalize_metadata_value(metadata.get(\"dc:publisher\", \"Unknown\")),\n",
    "                        'date': normalize_metadata_value(metadata.get(\"dc:date\", \"\")),\n",
    "                        'abstract': normalize_metadata_value(metadata.get(\"dc:abstract\", \"\")),\n",
    "                        'format': normalize_metadata_value(metadata.get(\"dc:format\", \"\")),\n",
    "                        'created': normalize_metadata_value(metadata.get(\"dcterms:created\", \"\")),\n",
    "                        'modified': normalize_metadata_value(metadata.get(\"dcterms:modified\", \"\"))\n",
    "                    }\n",
    "                    \n",
    "                    logging.info(f\"Indexed {filename} with CID: {normalized_metadata['cid']}\")\n",
    "\n",
    "                    # Add document to the Whoosh index\n",
    "                    add_document(writer, normalized_metadata, full_text)\n",
    "\n",
    "                    # Print extracted Dublin Core metadata\n",
    "                    print(\"Dublin Core Metadata:\")\n",
    "                    print(json.dumps(dublin_core_metadata, indent=4))\n",
    "\n",
    "                    # Update project entry with file data and Dublin Core metadata\n",
    "                    update_project_entry_with_file_data(\n",
    "                        linked_project, file_cid, normalized_metadata['cid'], dublin_core_metadata\n",
    "                    )\n",
    "                    logging.info(\"updated project entry\")\n",
    "                    \n",
    "                    # Upload the metadata to IPFS and get its CID\n",
    "                    print(40*\"-\")\n",
    "                    metadata_cid = upload_json_to_ipfs(metadata)\n",
    "                    logging.info(f\"File {filename} uploaded to IPFS with CID: {metadata_cid}\")\n",
    "                                        \n",
    "                    #Sets the project account detail with the file metadata\n",
    "                    print(40*\"-\")\n",
    "\n",
    "                    # print(project_account['account_id'])\n",
    "                    # print(index)\n",
    "                    # hash = set_account_detail(\n",
    "                    #     address, project_account['account_id'], f\"file_{index}_metadata_CID\", metadata_cid\n",
    "                    #     )\n",
    "\n",
    "                    print(40*\"-\")\n",
    "                    \n",
    "                    #-\n",
    "                    \n",
    "                else:\n",
    "                    logging.error(f\"Parsing failed for '{filename}'.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing file '{filename}': {e}\")\n",
    "                continue\n",
    "\n",
    "        logging.info(\"-\" * 40)\n",
    "        index += 1\n",
    "\n",
    "    writer.commit()  # Commit changes once all files are processed\n",
    "    logging.info(\"All documents processed and index committed.\")\n",
    "\n",
    "\n",
    "# Function to set up the Whoosh index directory\n",
    "def setup_index(schema):\n",
    "    \"\"\"Sets up the Whoosh index directory and returns the index object.\"\"\"\n",
    "    index_dir = \"indexdir\"\n",
    "    if not os.path.exists(index_dir):\n",
    "        os.mkdir(index_dir)\n",
    "        logging.info(\"Index directory created.\")\n",
    "        ix = create_in(index_dir, schema)\n",
    "    else:\n",
    "        try:\n",
    "            ix = open_dir(index_dir)\n",
    "            logging.info(\"Opened existing index.\")\n",
    "        except EmptyIndexError:\n",
    "            logging.warning(\"Index is empty. Creating a new index.\")\n",
    "            ix = create_in(index_dir, schema)\n",
    "    return ix\n",
    "\n",
    "# ic(linked_project)\n",
    "\n",
    "# Define the schema (including Dublin Core fields)\n",
    "schema = Schema(\n",
    "    project_id=TEXT(stored=True),\n",
    "    cid=ID(stored=True),\n",
    "    name=TEXT(stored=True),\n",
    "    size=NUMERIC(stored=True),\n",
    "    filetype=TEXT(stored=True),\n",
    "    title=TEXT(stored=True),\n",
    "    creator=TEXT(stored=True),\n",
    "    language=TEXT(stored=True),\n",
    "    subject=TEXT(stored=True),\n",
    "    description=TEXT(stored=True),\n",
    "    publisher=TEXT(stored=True),\n",
    "    date=TEXT(stored=True),\n",
    "    abstract=TEXT(stored=True),\n",
    "    format=TEXT(stored=True),\n",
    "    created=TEXT(stored=True),  # Store as string (e.g., ISO format 'YYYY-MM-DD')\n",
    "    modified=TEXT(stored=True),  # Store as string (e.g., ISO format 'YYYY-MM-DD')\n",
    "    full_text=TEXT(stored=False)\n",
    ")\n",
    "\n",
    "# Setup index directory\n",
    "ix = setup_index(schema)\n",
    "\n",
    "# Example document parsing and indexing execution\n",
    "directory_path = \"upload\"\n",
    "\n",
    "linked_project = project_account['account_id']  # Example placeholder, adjust as needed\n",
    "\n",
    "# Parse documents in the specified directory\n",
    "parse_documents_in_directory(directory_path, schema, linked_project, recreate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74689d5",
   "metadata": {},
   "source": [
    "8 -  Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79938646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No results found for 'feature'\n",
      "ERROR:root:Error occurred during search: local variable 'project_ids' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "# Example search usage\n",
    "keyword = \"feature\"\n",
    "search_index(keyword, ix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a509be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No results found for 'feature'\n",
      "ERROR:root:Error occurred during search: local variable 'project_ids' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "project_ids = search_index(keyword, ix)\n",
    "print(project_ids)  # prints the list of project ids found in thvc e results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6348ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = \"example_keyword\"\n",
    "\n",
    "# Initialize objects and variables\n",
    "\n",
    "\n",
    "# project_ids = search_index(keyword, ix)\n",
    "if project_ids:\n",
    "    get_project_details(project_ids, net, iroha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e6b78-9d2c-4543-b88c-ba216b3ed596",
   "metadata": {},
   "source": [
    "9 - Query the project account to verify the details update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfac8c-5f92-487a-87fd-067df3e26299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '74289@test'}, { \"admin@test\" : { \"file_1_CID\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\", \"linked_user\" : \"elastic_nash@test\", \"project_metadata_cid\" : \"QmYLGs2hzebM56odvitzKoW4SDyAStJsAHYmLeUD8SERHR\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail', account_id=linked_project)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6ee05-f89d-44ce-aab8-e57b2acff3a4",
   "metadata": {},
   "source": [
    "10 - Read CIDs from Iroha and download file metadata and files from IPFS to the project home directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbac27b-655e-47e9-859a-b88629f5af14",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'base',\n",
    "    'themeVariables': {\n",
    "      'primaryColor': '#ffffff',\n",
    "      'primaryTextColor': '#000000',\n",
    "      'primaryBorderColor': '#000000',\n",
    "      'lineColor': '#000000',\n",
    "      'secondaryColor': '#f4f4f4',\n",
    "      'secondaryTextColor': '#000000',\n",
    "      'tertiaryColor': '#d3d3d3',\n",
    "      'tertiaryTextColor': '#000000',\n",
    "      'background': '#ffffff',\n",
    "      'actorBkg': '#B4B4B4',\n",
    "      'actorTextColor': '#000000',\n",
    "      'actorBorder': '#000000',\n",
    "      'actorLineColor': '#000000',\n",
    "      'signalColor': '#000000',\n",
    "      'signalTextColor': '#000000',\n",
    "      'activationBorderColor': '#000000',\n",
    "      'activationBkgColor': '#d3d3d3',\n",
    "      'sequenceNumberColor': '#000000',\n",
    "      'noteBkgColor': '#F0F0F0',\n",
    "      'noteTextColor': '#000000',\n",
    "      'noteBorderColor': '#000000'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant self as \"self\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "    participant FrontEnd as \"Front End\"\n",
    "    \n",
    "       \n",
    "    Note over Platform, Blockchain: Queries the Project Account details and get details\n",
    "    Platform->>Blockchain: Query Project Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "\n",
    "    Note over Platform, IPFS: Process project account metadata\n",
    "    Platform->>self: Parse Project Details JSON and retrieve file CIDs\n",
    "\n",
    "    Note over Platform, IPFS: Download file from IPFS \n",
    "    Platform->>IPFS: Sends the file CID\n",
    "    IPFS->>Platform: Sends back the file\n",
    "    Platform->>FrontEnd:    Saves the file locally and display info and status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6ca74-7343-4109-b774-0582cb9bab9b",
   "metadata": {},
   "source": [
    "11 - Read details from the project account retrieve the CID of every file, download the it file from IPFS and store locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae73161-a508-408c-81fb-3bb08b13fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing project account: 74289@test\n",
      "Processing file CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW for key: file_1_CID\n",
      "Skipping key: linked_user\n",
      "Skipping key: project_metadata_cid\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from clean_file_name import clean_file_name as clean_name\n",
    "from ipfs_functions import download_file_from_ipfs, download_json_from_ipfs\n",
    "\n",
    "# Convert the JSON string to a Python dictionary\n",
    "project_details_dict = json.loads(project_details)\n",
    "project_account_id = project_account['account_id']\n",
    "\n",
    "print(f\"Processing project account: {project_account_id}\")\n",
    "\n",
    "# Get the value of the dictionary (actual file metadata)\n",
    "files_metadata = project_details_dict['admin@test']\n",
    "# print(files_metadata)\n",
    "\n",
    "# Iterate through files metadata, skip unneeded keys, and process files and metadata CIDs\n",
    "for key, value in files_metadata.items():\n",
    "    if key in ['linked_user', 'project_metadata_cid']:\n",
    "        print(f\"Skipping key: {key}\")\n",
    "        continue\n",
    "\n",
    "    # Distinguish between file CID and metadata CID\n",
    "    if 'metadata_CID' not in key:\n",
    "        file_CID = value\n",
    "        print(f\"Processing file CID: {file_CID} for key: {key}\")\n",
    "    else:\n",
    "        file_metadata_key = '_'.join(key.split('_')[:-2])\n",
    "        file_metadata_CID = value\n",
    "        print(f\"Processing metadata CID: {file_metadata_CID} for key: {file_metadata_key}\")\n",
    "\n",
    "        # Download and process metadata JSON\n",
    "        file_metadata_json = download_json_from_ipfs(file_metadata_CID)\n",
    "        # print(file_metadata_json)\n",
    "\n",
    "        # Ensure 'resourceName' exists in metadata and process the file download\n",
    "        if 'resourceName' in file_metadata_json:\n",
    "            raw_file_name = file_metadata_json['resourceName']\n",
    "            cleaned_file_name = clean_name(raw_file_name)  # Renamed to avoid conflict\n",
    "            print(f\"Cleaned file name: {cleaned_file_name}\")\n",
    "\n",
    "            # Create user-specific download directory if it doesn't exist\n",
    "            download_directory = os.path.join(\"download\", project_account_id)\n",
    "            os.makedirs(download_directory, exist_ok=True)\n",
    "            print(f\"Download directory ready: {download_directory}\")\n",
    "\n",
    "            # Download file using the file CID\n",
    "            file_path = os.path.join(download_directory, cleaned_file_name)\n",
    "            print(f\"Downloading file to: {file_path}\")\n",
    "            download_file_from_ipfs(file_CID, file_path)\n",
    "            print(\"-\" * 40)\n",
    "        else:\n",
    "            print(f\"No 'resourceName' found for metadata CID: {file_metadata_CID}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
