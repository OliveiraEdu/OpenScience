{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1c5a2-75c3-482e-999c-70eb25226078",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from iroha import IrohaCrypto\n",
    "from iroha.ed25519 import H\n",
    "import integration_helpers\n",
    "from iroha.primitive_pb2 import can_set_my_account_detail\n",
    "import json\n",
    "from iroha_helper import *\n",
    "from new_helper import *\n",
    "from super_helper import *\n",
    "from ipfs_functions import *\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad05321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for objects in both user account and project account JSON-LDs.\n",
    "json_ld_index = 2\n",
    "\n",
    "# Local path for file upload\n",
    "directory_path = \"upload\"\n",
    "\n",
    "# Directory for file downloads\n",
    "download_path = \"download\"\n",
    "\n",
    "# Read accounts from JSON-LD\n",
    "user_accounts = read_user_accounts_from_jsonld('datasets/accounts.json')\n",
    "project_accounts = read_project_accounts_from_jsonld('datasets/projects.json')\n",
    "\n",
    "#for the index system\n",
    "index_path = \"indexdir\"\n",
    "index = open_dir(index_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089523ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize the logger format\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sink=lambda msg: print(msg, end=\"\"),\n",
    "    format=\"<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | \"\n",
    "           \"<level>{level: <8}</level> | \"\n",
    "           \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - \"\n",
    "           \"{message}\",\n",
    "    colorize=True,  # Enable colors for supported terminals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eaf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually resets the index on execution\n",
    "# recreate_index() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a043d51-4a22-4186-975e-7e3e8a4b54ef",
   "metadata": {},
   "source": [
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6442fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash = create_detail_contract()\n",
    "integration_helpers.get_engine_receipts_result(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea1051-cb1c-4c29-97e5-38ba90248081",
   "metadata": {},
   "source": [
    "2 - Data extraction from JSON-LD.\n",
    "\n",
    "Extracts account ids from `datasets/accounts.json` and `datasets/projects.json`.\n",
    "\n",
    "Must update `json_ld_index` with a entry number related to an existing object in `datasets/accounts.json` and `datasets/projects.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e068d0-2247-4fd3-827f-4144b66965e1",
   "metadata": {},
   "source": [
    "4 - Sets details for both User and Project accounts providing a logical link between them for later references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example execution of the previous snippet\n",
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "\n",
    "# Assuming json_ld_index is defined\n",
    "user_account = user_accounts[json_ld_index]\n",
    "project_account = project_accounts[json_ld_index]\n",
    "\n",
    "# Set project_id as a detail for the user account\n",
    "hash_user_to_project = set_account_detail(\n",
    "    address, \n",
    "    user_account['account_id'], \n",
    "    \"linked_project\", \n",
    "    project_account['account_id']\n",
    ")\n",
    "\n",
    "# Set user_account_id as a detail for the project account\n",
    "hash_project_to_user = set_account_detail(\n",
    "    address, \n",
    "    project_account['account_id'], \n",
    "    \"linked_user\", \n",
    "    user_account['account_id']\n",
    ")\n",
    "\n",
    "# Update the JSON-LD files with the linked details\n",
    "update_user_account_link(user_account['account_id'], project_account['account_id'])\n",
    "update_project_account_link(project_account['account_id'], user_account['account_id'])\n",
    "\n",
    "# Confirming the operation\n",
    "logger.info(f\"User account {user_account['account_id']} linked to project {project_account['account_id']}\")\n",
    "logger.info(f\"Project account {project_account['account_id']} linked to user {user_account['account_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562857c-d86d-42cf-a24b-23a5c3f5cb4e",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for User account and checks its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e47a4-b1c5-4ebe-a2d8-8edae10063d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=user_account['account_id'])\n",
    "# logger.info(query)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# logger.info(response)\n",
    "\n",
    "user_data = response.account_detail_response\n",
    "user_details = user_data.detail\n",
    "\n",
    "logger.info(f'User Account id = {user_account}, {user_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f33098-43df-47f3-8708-f3212dec1c0f",
   "metadata": {},
   "source": [
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374843b3-6862-4a93-b298-1bdd0320c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the account details response\n",
    "user_details_dict = json.loads(user_details)  # Convert the string to a JSON object\n",
    "logger.info(user_details_dict)\n",
    "\n",
    "# Now you can access the specific key like this\n",
    "project_id = user_details_dict[\"admin@test\"][\"linked_project\"]\n",
    "logger.info(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = get_schema() #super_helper.py\n",
    "\n",
    "logger.info(schema)\n",
    "\n",
    "processed_data = process_files(directory_path, project_id, schema) #new_helper.py\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a01a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_detail = get_account_detail(project_id)\n",
    "logger.info(f\"{project_id}, {account_detail}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bca4c-e506-414d-aee5-f9a58ff3105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a keyword search\n",
    "keyword = \"paper\"\n",
    "search_results, project_ids_with_cids = search_index(index, keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a150d-7e23-4e81-9b77-fa6febdc43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are no search results\n",
    "if not search_results:\n",
    "    logger.warning(f\"No search results found for keyword: '{keyword}'. Exiting the script.\")\n",
    "else:\n",
    "    # Process each dictionary in search results\n",
    "    for result_dict in search_results:\n",
    "        project_id = result_dict.get('project_id')\n",
    "        file_cid = result_dict.get('file_cid')\n",
    "        metadata_cid = result_dict.get('metadata_cid')\n",
    "\n",
    "        if not project_id or not file_cid or not metadata_cid:\n",
    "            logger.error(f\"Missing required data in result: {result_dict}\")\n",
    "            continue\n",
    "\n",
    "        # Log the retrieved project details\n",
    "        logger.info(f\"Processing Project ID: {project_id}\")\n",
    "        logger.info(f\"File CID: {file_cid}\")\n",
    "        logger.info(f\"Metadata CID: {metadata_cid}\")\n",
    "        # file_metadata_json = download_json_from_ipfs(metadata_cid)\n",
    "        # logger.info(\"file_metadata_json:\", file_metadata_json)\n",
    "        \n",
    "\n",
    "        # Fetch project details from the blockchain\n",
    "        project_details = get_account_detail(project_id)\n",
    "        if not project_details:\n",
    "            logger.error(f\"No project details found for Project ID: {project_id}.\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Fetched project details for {project_id}: {project_details}\")\n",
    "\n",
    "        # Parse blockchain data\n",
    "        try:\n",
    "            blockchain_data = json.loads(project_details)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"Error decoding project details JSON for {project_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Validate file CID and fetch project details\n",
    "        validation_result = fetch_project_details(file_cid, blockchain_data)\n",
    "        logger.info(f\"Valid Result for {project_id} is {validation_result}.\")\n",
    "        if validation_result[\"is_valid\"]:\n",
    "            project_metadata_cid = validation_result.get(\"project_metadata_cid\")\n",
    "            linked_user = validation_result.get(\"linked_user\")\n",
    "            file_metadata_cid = validation_result.get(\"metadata_cid\")\n",
    "            \n",
    "            # download_file(file_metadata_json, download_path, project_id, file_cid)\n",
    "\n",
    "            logger.info(f\"Valid File CID for {project_id}.\")\n",
    "            logger.info(f\"Project Metadata CID: {project_metadata_cid}\")\n",
    "            logger.info(f\"Linked User: {linked_user}\")\n",
    "\n",
    "            # Fetch and process metadata and user details\n",
    "            if project_metadata_cid:\n",
    "                logger.info(f\"Processing project metadata CID: {project_metadata_cid}\")\n",
    "                project_metadata = download_json_from_ipfs(project_metadata_cid)\n",
    "                logger.info(f\"Downloaded project metadata: {project_metadata}\")\n",
    "\n",
    "            if linked_user:\n",
    "                logger.info(f\"Processing linked user: {linked_user}\")\n",
    "                user_details = get_account_detail(linked_user)\n",
    "                try:\n",
    "                    user_details = json.loads(user_details)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(f\"Error decoding user details JSON for {linked_user}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                user_json_ld_cid = user_details.get(\"admin@test\", {}).get(\"user_json_ld_cid\", None)\n",
    "                if user_json_ld_cid:\n",
    "                    logger.info(f\"User JSON-LD CID: {user_json_ld_cid}\")\n",
    "                    user_metadata = download_json_from_ipfs(user_json_ld_cid)\n",
    "                    logger.info(f\"Downloaded user metadata: {user_metadata}\")\n",
    "                else:\n",
    "                    logger.warning(f\"User JSON-LD CID not found for linked user {linked_user}.\")\n",
    "            \n",
    "            if metadata_cid:\n",
    "                logger.info(f\"Processing metadata CID: {metadata_cid}\")\n",
    "                file_metadata = download_json_from_ipfs(metadata_cid)\n",
    "                file_metadata_json = download_file(file_metadata, download_path, project_id, file_cid)\n",
    "                logger.info(f\"Downloaded file metadata: {metadata_cid}\")\n",
    "                logger.info(f\"file metadata: {file_metadata}\")\n",
    "                logger.info(f\"file metadata JSON: {file_metadata_json}\")\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            logger.warning(f\"Invalid File CID for Project ID: {project_id}. Skipping metadata processing.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce1cc47f-e840-4a18-9023-38778bf1a29d",
   "metadata": {},
   "source": [
    "With Reusable Helper Function for Block Separation and Tracing\n",
    "\n",
    "A helper function, with_logging_block, which accepts a block name, the code block to execute, and optional parameters for context-specific tracing.\n",
    "\n",
    "Cleanly separates each logical block, improving readability, modularity, and error tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9672f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "# Main Code Logic\n",
    "\n",
    "with with_logging_block(\"Keyword Search\", logger):\n",
    "    if not search_results:\n",
    "        logger.warning(f\"No search results found for keyword: '{keyword}'. Exiting the script.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "with with_logging_block(\"Processing Search Results\", logger):\n",
    "    for result_dict in search_results:\n",
    "        project_id = result_dict.get('project_id')\n",
    "        file_cid = result_dict.get('file_cid')\n",
    "        metadata_cid = result_dict.get('metadata_cid')\n",
    "\n",
    "        with with_logging_block(f\"Processing Result for Project ID: {project_id or 'Unknown'}\", logger):\n",
    "            if not project_id or not file_cid or not metadata_cid:\n",
    "                logger.error(f\"Missing required data in result: {result_dict}\")\n",
    "                continue\n",
    "\n",
    "            logger.info(f\"File CID: {file_cid}\")\n",
    "            logger.info(f\"Metadata CID: {metadata_cid}\")\n",
    "\n",
    "            # Fetch project details\n",
    "            with with_logging_block(\"Fetching Project Details\", logger):\n",
    "                project_details = get_account_detail(project_id)\n",
    "                if not project_details:\n",
    "                    logger.error(f\"No project details found for Project ID: {project_id}.\")\n",
    "                    continue\n",
    "                logger.info(f\"Fetched project details for {project_id}: {project_details}\")\n",
    "\n",
    "            # Parse blockchain data\n",
    "            with with_logging_block(\"Parsing Blockchain Data\", logger):\n",
    "                try:\n",
    "                    blockchain_data = json.loads(project_details)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(f\"Error decoding project details JSON for {project_id}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Validate file CID\n",
    "            with with_logging_block(\"Validating File CID\", logger):\n",
    "                validation_result = fetch_project_details(file_cid, blockchain_data)\n",
    "                logger.info(f\"Validation Result for {project_id}: {validation_result}\")\n",
    "                if not validation_result[\"is_valid\"]:\n",
    "                    logger.warning(f\"Invalid File CID for Project ID: {project_id}. Skipping metadata processing.\")\n",
    "                    continue\n",
    "\n",
    "            project_metadata_cid = validation_result.get(\"project_metadata_cid\")\n",
    "            linked_user = validation_result.get(\"linked_user\")\n",
    "\n",
    "            # Process project metadata\n",
    "            if project_metadata_cid:\n",
    "                with with_logging_block(\"Processing Project Metadata\", logger):\n",
    "                    project_metadata = download_json_from_ipfs(project_metadata_cid)\n",
    "                    logger.info(f\"Downloaded project metadata: {project_metadata}\")\n",
    "\n",
    "            # Process linked user details\n",
    "            if linked_user:\n",
    "                with with_logging_block(f\"Processing Linked User: {linked_user}\", logger):\n",
    "                    user_details = get_account_detail(linked_user)\n",
    "                    try:\n",
    "                        user_details = json.loads(user_details)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        logger.error(f\"Error decoding user details JSON for {linked_user}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    user_json_ld_cid = user_details.get(\"admin@test\", {}).get(\"user_json_ld_cid\")\n",
    "                    if user_json_ld_cid:\n",
    "                        user_metadata = download_json_from_ipfs(user_json_ld_cid)\n",
    "                        logger.info(f\"Downloaded user metadata: {user_metadata}\")\n",
    "                    else:\n",
    "                        logger.warning(f\"User JSON-LD CID not found for linked user {linked_user}.\")\n",
    "\n",
    "            # Process metadata CID\n",
    "            if metadata_cid:\n",
    "                with with_logging_block(\"Processing Metadata CID\", logger):\n",
    "                    file_metadata = download_json_from_ipfs(metadata_cid)\n",
    "                    file_metadata_json = download_file(file_metadata, download_path, project_id, file_cid)\n",
    "             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee93820-46b0-4202-bd71-734469df2d97",
   "metadata": {},
   "source": [
    "includes the output of the search results explicitly logged within the Keyword Search block. This will ensure all search results are printed for visibility and debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e230d1d0-2265-4b8d-a7af-9c6b0d736d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 22:51:07.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Keyword Search\n",
      "\u001b[32m2025-01-13 22:51:07.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - Search results for keyword 'paper':\n",
      "\u001b[32m2025-01-13 22:51:07.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - Result 1: {\n",
      "  \"abstract\": \"\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"date\": \"\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"metadata_cid\": \"Qmda3UGvN1Ywmc2FkxuKSEHK8iy5vW5YrRFE9sqKKxdUVw\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\"\n",
      "}\n",
      "\u001b[32m2025-01-13 22:51:07.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - Result 2: {\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"metadata_cid\": \"QmNjaCTeNdmrJfLYUpD8qhpjndXXX7QrWagRMhNSAtQkC6\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"date\": \"\",\n",
      "  \"project_id\": \"73243@test\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\"\n",
      "}\n",
      "\u001b[32m2025-01-13 22:51:07.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - Result 3: {\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"metadata_cid\": \"QmdyAE132FSeSQaqUHzE5GtMrEwy821ScAYKEXsxpWSnV5\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"date\": \"\",\n",
      "  \"project_id\": \"73243@test\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\"\n",
      "}\n",
      "\u001b[32m2025-01-13 22:51:07.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - Result 4: {\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"metadata_cid\": \"QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"date\": \"\",\n",
      "  \"project_id\": \"73243@test\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\"\n",
      "}\n",
      "\u001b[32m2025-01-13 22:51:07.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - Result 5: {\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"metadata_cid\": \"QmWcdZFjgVaocJrPvDqKzf5KSFDcxypn5Ffyq9SNxQM1dN\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"date\": \"\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\"\n",
      "}\n",
      "\u001b[32m2025-01-13 22:51:07.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - Result 6: {\n",
      "  \"abstract\": \"\",\n",
      "  \"subject\": \"stock market forecasting,covid-19 pandemic,multi-task learning,feature fusion,k-nearest neighbor classifier, expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "  \"full_text\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\u2217\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors\\u2019 apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; \\u0160tifani\\u0107 et al., 2020). Based on this, we conducted\\n\\n\\u2217 Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors\\u2019 investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/\\u00a9 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (\\u0160tifani\\u0107 et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock market\\u2019s short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidu\\u2019s index, and the media informa-\\ntion statistics all reflect COVID-19\\u2019s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain task\\u2019s predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n\\u2022 A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n\\u2022 Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n\\u2022 Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCN\\u2019s insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\n\\u0160tifani\\u0107 et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how China\\u2019s Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers\\u2019 evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays\\u2019 data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix \\ud835\\udefd of the market sentiment index (where\\n\\ud835\\udc4b, \\ud835\\udc4c ... \\ud835\\udc4d represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n\\ud835\\udefd =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\nX1 Y1 Z1\\nX2 Y2 \\u22ef Z2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n(1)\\n5\\n\\n\\u23a3\\n\\nX\\ud835\\udc5a Y\\ud835\\udc5a \\u22ef Z\\ud835\\udc5a \\u23a6\\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix \\ud835\\udefd is normalized using Eq. (2) to obtain the\\nnormalization matrix \\ud835\\udc46.\\n\\n\\ud835\\udc46\\ud835\\udc56\\ud835\\udc57 =\\n\\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 \\u2212 \\ufffd\\u0304\\ufffd\\ud835\\udc57\\n\\n\\ud835\\udf0e\\ud835\\udc57\\n, \\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc5a; \\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5d (2)\\n\\nwhere \\ud835\\udc5d denotes the number of columns, \\ud835\\udc65\\ud835\\udc56\\ud835\\udc57 denotes the data matrix\\n\\ud835\\udefd values, and \\ufffd\\u0304\\ufffd\\ud835\\udc57 , \\ud835\\udf0e\\ud835\\udc57 denote the mean and standard deviation of each\\ncomponent \\ud835\\udc57.\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n\\ud835\\udc45 \\u2212 \\ud835\\udf06\\ud835\\udc57\\ud835\\udc3c\\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere \\ud835\\udc45 denotes the correlation coefficient matrix of matrix \\ud835\\udc46, and \\ud835\\udc5d\\neigenvalues \\ud835\\udf06\\ud835\\udc57 are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A\\ud835\\udc54\\ud835\\udc57 (\\ud835\\udc54\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value \\ud835\\udc4c\\ud835\\udc54 are calculated for the original\\ndata, and then the final new market sentiment index (NMSI) \\ud835\\udc40\\ud835\\udc5a is\\ncalculated.\\n\\nA\\ud835\\udc54\\ud835\\udc57 = U\\ud835\\udc54 \\u2217\\n\\u221a\\n\\n\\ud835\\udc4c\\ud835\\udc54 (4)\\n\\n\\ud835\\udc4c\\ud835\\udc54 =\\n\\u2211\\n\\n(\\n\\nA\\ud835\\udc54\\ud835\\udc57 \\u2217 \\ud835\\udefd\\n)\\n\\n(5)\\n\\n\\ud835\\udc40\\ud835\\udc5a =\\n\\u2211\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc54 \\u2217 \\ud835\\udf06\\ud835\\udc54\\n)\\n\\n(6)\\n\\nwhere U\\ud835\\udc54 is the loading of the principal component, \\ud835\\udc4c\\ud835\\udc54 represents\\nthe eigenvalue corresponding to each principal component, \\ud835\\udc4c\\ud835\\udc54 repre-\\nsents the \\ud835\\udc54th principal component, and \\ud835\\udf06\\ud835\\udc54 represents the eigenvalue\\ncorresponding to the \\ud835\\udc54th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between April\\u2013July 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n\\ud835\\udc5f =\\n\\u2211\\ud835\\udc5a\\n\\n\\ud835\\udc56=1\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n) (\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)\\n\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4b\\ud835\\udc56 \\u2212 \\ufffd\\u0304\\ufffd\\n)2\\n\\u221a\\n\\n\\u2211\\ud835\\udc5a\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ud835\\udc4c\\ud835\\udc56 \\u2212 \\ud835\\udc4c\\n)2\\n\\n(7)\\n\\nwhere \\ud835\\udc4b and \\ud835\\udc4c denote the series values of NMSI and CSI 300, \\ufffd\\u0304\\ufffd, \\ud835\\udc4c\\nenote the mean values of NMSI and CSI 300 series data, and \\ud835\\udc5a is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords \\u2018\\u2018epidemic\\u2019\\u2019 in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf \\u2018\\u2018COVID-19\\u2019\\u2019 in online information increases, investors\\u2019 investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of \\u2018\\u2018COVID-19\\u2019\\u2019 decreases and the number of cured cases\\nncreases, investors\\u2019 investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the \\u2018\\u2018Omicron\\u2019\\u2019 COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germany\\u2019s DAX closing down\\n.15%, the largest one-day drop since 2021, and France\\u2019s CAC 40 and\\nhe UK\\u2019s FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 2019\\u20132021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between February\\u2013March\\n020, February 2021 and July\\u2013August 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence \\ud835\\udc36\\ud835\\udc5a of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 \\u22120.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Index\\u2019s valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence \\ud835\\udc4b(\\ud835\\udc5a) =\\n\\n[\\n\\n\\ud835\\udc651, \\ud835\\udc652, \\ud835\\udc653 \\u2026 \\ud835\\udc65\\ud835\\udc5a\\n]\\n\\n.\\n\\nmin\\n\\ud835\\udf14\\ud835\\udc58 ,\\ud835\\udc49\\ud835\\udc58)\\n\\n{ \\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\u2016\\n\\n\\ud835\\udf15\\ud835\\udc5a\\n[\\n\\n(\\ud835\\udeff(\\ud835\\udc5a) + \\ud835\\udc57\\u2215\\ud835\\udf0b\\ud835\\udc5a) \\u2217 \\ud835\\udc49\\ud835\\udc58(\\ud835\\udc5a)\\n]\\n\\n\\ud835\\udc52\\u2212\\ud835\\udc57\\ud835\\udf14\\ud835\\udc56\\ud835\\udc5a\\u2016\\n\\u2016\\n\\n\\u2016\\n\\n2\\n\\n2\\n\\n}\\n\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc58=1\\n\\ud835\\udc49\\ud835\\udc58 = \\ud835\\udc4b(\\ud835\\udc5a)\\n\\n(8)\\n\\nwhere \\ud835\\udc5a denotes each moment of the sequence, \\ud835\\udc4b(\\ud835\\udc5a) is the original\\nequence of stock prices, \\ud835\\udc58 is the number of modes, \\ud835\\udeff(\\ud835\\udc5a) is the Dirichlet\\nunction, \\u2217 denotes the convolution, \\ud835\\udc57 =\\n\\n\\u221a\\n\\n\\u22121, and \\ud835\\udf15\\ud835\\udc5a is the partial\\nderivative. After decomposition, \\ud835\\udc58 discrete modes are obtained, and\\nthe component of each mode \\ud835\\udc58 is \\ud835\\udc49\\ud835\\udc58, and each \\ud835\\udc49\\ud835\\udc58 is concentrated\\naround the center frequency \\ud835\\udf14\\ud835\\udc58 of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as \\ud835\\udc49\\ud835\\udc58=1 =\\n\\n[\\n\\n\\ud835\\udc3f1, \\ud835\\udc3f2, \\ud835\\udc3f3 \\u2026\\ud835\\udc3f\\ud835\\udc5a\\n]\\n\\n. To better illustrate this,\\nthe first three values \\ud835\\udc4b1, \\ud835\\udc4b2, \\ud835\\udc4b3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 =\\n[\\n\\n\\ud835\\udc3f1\\n1, \\ud835\\udc3f\\n\\n1\\n2, \\ud835\\udc3f\\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of \\ud835\\udc49\\ud835\\udc58=1 and \\ud835\\udc49 1\\n\\n\\ud835\\udc58=1 are not equal,\\nindicating that \\ud835\\udc49\\ud835\\udc58=1 This set of components is obtained based on the\\ndecomposition of the whole sequence of \\ud835\\udc4b. The local values of \\ud835\\udc49\\ud835\\udc58=1 still\\ncontain some information of the whole sequence. Therefore, using \\ud835\\udc49\\ud835\\udc58=1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 2019\\u20132021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series \\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 is obtained after decomposing the\\ndata in each window of \\ud835\\udc4b(\\ud835\\udc5a) using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1 \\u2013 \\u2013\\nMACD 0.11 1 \\u2013\\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n\\ud835\\udc47\\ud835\\udc5a =\\n\\n\\u23a1\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a2\\n\\n\\u23a3\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2 \\u22ef RSI 2\\n\\n\\u22ee \\u22f1 \\u22ee\\n\\ud835\\udc40\\ud835\\udc345\\ud835\\udc5a MA15 \\ud835\\udc5a \\u22ef RSI \\ud835\\udc5a\\n\\n\\u23a4\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a5\\n\\n\\u23a6\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n\\ud835\\udc49\\ud835\\udc5a1, \\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc49\\ud835\\udc5a3,\\u2026 , \\ud835\\udc49\\ud835\\udc5a\\ud835\\udc58 of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a, the COVID-19 Index \\ud835\\udc36\\ud835\\udc5a and\\nhe stock price technical indicator sequence \\ud835\\udc47\\ud835\\udc5a, as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence \\ud835\\udc49\\ud835\\udc5a1, the\\nmarket sentiment indicator sequence \\ud835\\udc40\\ud835\\udc5a and the stock price technical\\nindicator sequence \\ud835\\udc47\\ud835\\udc5a 3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\ud835\\udc3b\\n\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a1,\\ud835\\udc40\\ud835\\udc5a, \\ud835\\udc47\\ud835\\udc5a\\n]\\n\\n, and because the feature\\nsequences of the three dimensions in \\ud835\\udc3b all reflect the long-term trend\\nof stock prices, \\ud835\\udc3b can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix \\ud835\\udc3b is input, and the objective is to extract\\nthe long-term trend features of the stock price changes. \\ud835\\udc3b with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n\\ud835\\udc3b1 = Attention (\\ud835\\udc44,\\ud835\\udc3e, \\ud835\\udc49 ) = sof tmax\\n\\n(\\n\\n\\ud835\\udc44\\ud835\\udc3e\\ud835\\udc47\\n\\u221a\\n\\n\\ud835\\udc51\\n\\n)\\n\\n\\ud835\\udc49 (10)\\n\\nWhere \\ud835\\udc44, \\ud835\\udc3e, \\ud835\\udc49 are the same tensor as \\ud835\\udc3b as shown in Eq. (11), \\ud835\\udc51\\ndenotes the feature dimension of \\ud835\\udc44, and \\ud835\\udc60\\ud835\\udc5c\\ud835\\udc53\\ud835\\udc61\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 denotes the activation\\nfunction.\\n\\ud835\\udc44 = \\ud835\\udc7e \\ud835\\udc5e\\ud835\\udc3b\\n\\n\\ud835\\udc3e = \\ud835\\udc7e \\ud835\\udc58\\ud835\\udc3b\\n\\n\\ud835\\udc49 = \\ud835\\udc7e \\ud835\\udc63\\ud835\\udc3b\\n\\n(11)\\n\\nWhere \\ud835\\udc7e \\ud835\\udc5e ,\\ud835\\udc7e \\ud835\\udc58,\\ud835\\udc7e \\ud835\\udc63 denote the parameter matrix. Then the obtained\\n\\ud835\\udc3b1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 (\\ud835\\udc61) =\\n\\ud835\\udc58\\n\\u2211\\n\\n\\ud835\\udc53\\ud835\\udc56\\ud835\\udc3b\\n1\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56 (12)\\n9\\n\\n\\ud835\\udc56=1\\nwhere \\ud835\\udc53 =\\n(\\n\\n\\ud835\\udc531, \\ud835\\udc532,\\u2026 , \\ud835\\udc53\\ud835\\udc58\\n)\\n\\ndenotes the convolutional kernel, \\ud835\\udc58 is the\\nsize of convolutional kernels, \\ud835\\udc51 is the expansion coefficient, and \\ud835\\udc3b1\\n\\n\\ud835\\udc61\\u2212\\ud835\\udc51\\u22c5\\ud835\\udc56\\nrepresents the feature matrix before moment \\ud835\\udc61. Where each residual\\nmodule is subjected to two \\ue232 (\\u22c5) transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n\\ud835\\udc3b1 + \\ue232\\n(\\n\\n\\ud835\\udc3b1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n\\ud835\\udc3a\\ud835\\udc59 =\\n\\ud835\\udc59\\n\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\nexp\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udefdT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc5f\\ue232 (\\ud835\\udc61) + \\ud835\\udc4f\\ud835\\udc5f\\n))\\ue232 (\\ud835\\udc61) (14)\\n\\nWhere \\ud835\\udefdT, \\ud835\\udf14\\ud835\\udc5f are the parameter matrices, \\ud835\\udc4f\\ud835\\udc5f denotes the bias vector,\\n\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e is the activation function, and \\ud835\\udc59 is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\ud835\\udc3a\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc3a1, \\ud835\\udc3a2 \\u2026\\ud835\\udc3a\\ud835\\udc59\\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences \\ud835\\udc49 , \\ud835\\udc49 ,\\u2026 , \\ud835\\udc49 in\\n\\ud835\\udc5a2 \\ud835\\udc5a3 \\ud835\\udc5a\\ud835\\udc58\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n\\ud835\\udc461\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a2, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n, \\ud835\\udc462\\n[\\n\\n\\ud835\\udc49\\ud835\\udc5a3, \\ud835\\udc36\\ud835\\udc5a\\n]\\n\\n,\\u2026 , of number \\ud835\\udc58 \\u2212 1 and length \\ud835\\udc5a The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix \\ud835\\udc46 into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)\\u2013(21).\\n\\n\\ud835\\udc56\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc56\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc56\\n)\\n\\n(15)\\n\\n\\ud835\\udc53\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc53\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc53\\n)\\n\\n(16)\\n\\n\\ufffd\\u0303\\ufffd\\ud835\\udc61 = tanh\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc36\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc36\\n)\\n\\n(17)\\n\\n\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udf0e\\n(\\n\\n\\ud835\\udc4a\\ud835\\udc5c\\n[\\n\\n\\u210e\\ud835\\udc61\\u22121, \\ud835\\udc65\\ud835\\udc61\\n]\\n\\n+ \\ud835\\udc4f\\ud835\\udc5c\\n)\\n\\n(18)\\n\\n\\ud835\\udc36\\ud835\\udc61 = \\ud835\\udc53\\ud835\\udc61\\u25e6\\ud835\\udc36\\ud835\\udc61\\u22121 + \\ud835\\udc56\\ud835\\udc61\\u25e6\\ufffd\\u0303\\ufffd\\ud835\\udc61 (19)\\n\\n\\u210e\\ud835\\udc61 = \\ud835\\udc5c\\ud835\\udc61\\u25e6 tanh\\n(\\n\\n\\ud835\\udc36\\ud835\\udc61\\n)\\n\\n(20)\\n\\n\\ud835\\udc35 = \\u20d6\\u20d6\\u20d6\\u20d6\\u20d6\\u20d7[\\n\\n\\u210e , \\u20d6\\u20d6 \\u20d6\\u210e\\n]\\n\\n(21)\\n10\\n\\n\\ud835\\udc61 \\ud835\\udc61 \\ud835\\udc61\\nWhere Eq. (15)\\u2013Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. \\ud835\\udf0e, \\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e denote the activation function, \\ud835\\udc4a\\ud835\\udc56,\\ud835\\udc4a\\ud835\\udc36 ,\\ud835\\udc4a\\ud835\\udc53 ,\\ud835\\udc4a\\ud835\\udc5c\\ndenote the parameter matrix, \\ud835\\udc4f\\ud835\\udc56, \\ud835\\udc4f\\ud835\\udc50 , \\ud835\\udc4f\\ud835\\udc53 , \\ud835\\udc4f\\ud835\\udc5c denote the bias vectors, where\\n\\u25e6 denotes the Hadamard product (element-wise multiplication), \\u210e\\ud835\\udc61\\u22121\\ndenotes the hidden state value at the previous moment, \\ud835\\udc65\\ud835\\udc61 denotes the\\ninput at the current moment, \\ufffd\\u0303\\ufffd\\ud835\\udc61 denotes the temporary hidden variable\\nat the current moment, \\u210e\\u20d7\\ud835\\udc61 denotes the cell forward structural state, \\u20d6\\u20d6 \\u20d6\\u210e\\ud835\\udc61\\ndenotes the cell backward structural state, and \\ud835\\udc35\\ud835\\udc61 is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n\\ud835\\udf01\\ud835\\udc61 = \\ud835\\udc4eT tanh\\n(\\n\\n\\ud835\\udf14\\ud835\\udc35\\ud835\\udc61 + \\ud835\\udc4f\\ud835\\udc63\\n)\\n\\n(22)\\n\\n\\ud835\\udc43\\ud835\\udc61 =\\nexp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n)\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc61=1 exp\\n\\n(\\n\\n\\ud835\\udf01\\ud835\\udc61\\n) (23)\\n\\n\\ud835\\udc37\\ud835\\udc61 =\\n\\ud835\\udc5b\\n\\u2211\\n\\n\\ud835\\udc61=1\\n\\ud835\\udc43\\ud835\\udc61\\ud835\\udc35\\ud835\\udc61 (24)\\n\\nwhere \\ud835\\udc4e, \\ud835\\udf14 denote the parameter matrix, \\ud835\\udf01 calculates the attention\\nweights for \\ud835\\udc35\\ud835\\udc61. Finally, after calculating the probability \\ud835\\udc43\\ud835\\udc61 of the\\nattention weight, perform a weighted summation,calculate output \\ud835\\udc37\\ud835\\udc61\\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted \\ud835\\udc58\\u22121 local\\nfeatures \\ud835\\udc37\\ud835\\udc59\\n\\n[\\n\\n\\ud835\\udc371, \\ud835\\udc372,\\u2026 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole model\\u2019s results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\ud835\\udc51\\n(\\n\\n\\ud835\\udc65\\ud835\\udc57 , \\ud835\\udc65\\ud835\\udc56\\n)\\n\\n= 1\\n\\u221a\\n\\n\\u2211\\ud835\\udc5b\\n\\ud835\\udc5d=1\\n\\n(\\n\\n\\ud835\\udc65\\u2217\\ud835\\udc5d \\u2212 \\ud835\\udc65\\ud835\\udc5d\\n)2\\n\\n, \\ud835\\udc5d = 1, 2,\\u2026 , \\ud835\\udc59 (25)\\n\\nwhere \\ud835\\udc65\\u2217\\ud835\\udc57 (\\ud835\\udc57 = 1, 2,\\u2026 , \\ud835\\udc5b) is the data to be classified in the test set and\\n\\ud835\\udc65\\ud835\\udc56(\\ud835\\udc56 = 1, 2,\\u2026 , \\ud835\\udc59) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series \\ud835\\udc4b\\ud835\\udc59 and the global features \\ud835\\udc3a\\ud835\\udc59 (feature 1)\\nand local features \\ud835\\udc37\\ud835\\udc59 (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix \\ud835\\udc4a\\ud835\\udc59 =\\n\\n[\\n\\n\\ud835\\udc4b\\ud835\\udc59 , \\ud835\\udc3a\\ud835\\udc59 , \\ud835\\udc37\\ud835\\udc59\\n]\\n\\n, and set the stock price series \\ud835\\udc4b\\ud835\\udc61 up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n\\ud835\\udc4b\\ud835\\udc61 =\\n\\n{\\n\\n1 \\ud835\\udc4b\\ud835\\udc61+1 \\u2265 \\ud835\\udc4b\\ud835\\udc61\\n\\n0 \\ud835\\udc4b\\ud835\\udc61+1 < \\ud835\\udc4b\\ud835\\udc61\\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n\\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) = \\ud835\\udc39\\n(\\n\\n\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15\\n\\ud835\\udc59 ,\\ud835\\udc4a \\ud835\\udc61\\u2212\\ud835\\udf15+1\\n\\n\\ud835\\udc59 ,\\u2026 ,\\ud835\\udc4a \\ud835\\udc61\\n\\ud835\\udc59\\n)\\n\\n(27)\\n\\nwhere \\ufffd\\u0302\\ufffd(\\ud835\\udc61+1) is the prediction result, \\ud835\\udc39 (\\u22c5) is the set KNN classification\\nmodel, and \\ud835\\udf15 is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\ud835\\udc59\\n\\n\\ud835\\udc59\\n\\u2211\\n\\n\\ud835\\udc56=1\\n\\n(\\n\\n\\ufffd\\u0302\\ufffd\\ud835\\udc56 \\u2212 \\ud835\\udc66\\ud835\\udc56\\n)2 (28)\\n\\nwhere \\ufffd\\u0302\\ufffd\\ud835\\udc56 denotes the predicted value of the network, \\ud835\\udc66\\ud835\\udc56 denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n\\ud835\\udc65\\u2217 =\\n\\ud835\\udc65 \\u2212 \\ud835\\udc65min\\n\\n\\ud835\\udc65max \\u2212 \\ud835\\udc65min\\n(29)\\n\\nAmong of them, \\ud835\\udc65 is the original data, \\ud835\\udc65 is the normalized data.\\n11\\n\\n\\u2217\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy = \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41\\n\\n(30)\\n\\n\\ud835\\udc40\\ud835\\udc36\\ud835\\udc36 = \\ud835\\udc47\\ud835\\udc43 \\u00d7 \\ud835\\udc47\\ud835\\udc41 \\u2212 \\ud835\\udc39\\ud835\\udc43 \\u00d7 \\ud835\\udc39\\ud835\\udc41\\n\\u221a\\n\\n(\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc43 ) \\u00d7 (\\ud835\\udc47\\ud835\\udc41 + \\ud835\\udc39\\ud835\\udc41)\\n(31)\\n\\n\\ud835\\udc39 \\u2212 score = 2 \\u22c5 Precision \\u22c5 Recall\\nPrecision + Recall (32)\\n\\nwhere \\ud835\\udc47\\ud835\\udc43 denotes the number of positive examples predicted by the\\nclassifier, which means are positive value, \\ud835\\udc39\\ud835\\udc43 denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue, \\ud835\\udc39\\ud835\\udc41 denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value, \\ud835\\udc47\\ud835\\udc41 denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value. \\ud835\\udc43\\ud835\\udc61 is the net value of the product in a certain day,\\nand \\ud835\\udc43\\ud835\\udc66 is the net value of the product in a certain day after \\ud835\\udc61, \\ud835\\udc58 is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\ud835\\udc43\\ud835\\udc61\\n\\ud835\\udc43\\ud835\\udc61\\u2212\\ud835\\udc58\\n\\n\\u2212 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n\\ud835\\udc43\\ud835\\udc65 \\u2212 \\ud835\\udc43\\ud835\\udc66\\n)\\n\\n\\ud835\\udc43\\ud835\\udc65\\n(34)\\n\\nwhere \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 denotes the recall rate, \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc41\\n\\n(35)\\n\\nPrecision = \\ud835\\udc47\\ud835\\udc43\\n\\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc39\\ud835\\udc43\\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% \\u22127.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% \\u221210.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% \\u22127.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% \\u22122.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% \\u22126.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% \\u22122.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% \\u22123.76% 10.86%\\nNaive 43.23% \\u221213.58% 44.10% \\u221216.75% 18.59%\\nBuy and Hold \\u2013 \\u2013 \\u2013 \\u221214.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use today\\u2019s up and down as tomorrow\\u2019s buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% \\u22126.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% \\u22125.97% 10.67%\\nKNN 50.52% 1.38% 43.11% \\u22125.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days \\ud835\\udf15, along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days \\ud835\\udf15 and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days \\ud835\\udf15.\\n\\nEnter days \\ud835\\udf15=15 \\ud835\\udf15=20 \\ud835\\udf15=25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing \\u2013 original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing \\u2013 review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357\\u2013386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151\\u2013156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 1645\\u20131680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129\\u2013152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340\\u2013355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381\\u2013402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merri\\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160\\u2013167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 2965\\u20132969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 1177\\u20131183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383\\u2013417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324\\u2013328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\u0160\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 2833\\u20132854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 1440\\u20131448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965\\u2013989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of China\\u2019s economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 1735\\u20131780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261\\u2013269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104\\u2013109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 23\\u201327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268\\u2013273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n1141\\u20131151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 64\\u201382.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483\\u2013497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 1\\u20138). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239\\u2013255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 0078\\u20130086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Na\\u00efve SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670\\u2013680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381\\u2013392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 3285\\u20133292). IEEE.\\n\\ntifani\\u0107, D., Musulin, J., Mio\\u010devi\\u0107, A., Baressi \\u0160egota, S., \\u0160ubi\\u0107, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on China\\u2019s stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 18\\u201325.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174\\u2013184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221\\u2013228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n2710\\u20132719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n\",\n",
      "  \"metadata_cid\": \"QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\",\n",
      "  \"title\": \"covid19-mlsf: a multi-task learning-based stock market forecasting framework during the covid-19 pandemic\",\n",
      "  \"format\": \"application/pdf; version=1.7\",\n",
      "  \"created\": \"2023-02-04t09:40:15z\",\n",
      "  \"publisher\": \"unknown\",\n",
      "  \"creator\": \"chenxun yuan, xiang ma, hua wang, caiming zhang, xuemei li\",\n",
      "  \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "  \"language\": \"en-us\",\n",
      "  \"date\": \"\",\n",
      "  \"project_id\": \"37355@test\",\n",
      "  \"modified\": \"2023-02-07t16:52:03z\",\n",
      "  \"description\": \"expert systems with applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\"\n",
      "}\n",
      "\u001b[32m2025-01-13 22:51:07.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Keyword Search\n",
      "\u001b[32m2025-01-13 22:51:07.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Search Results\n",
      "\u001b[32m2025-01-13 22:51:07.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Metadata CID: Qmda3UGvN1Ywmc2FkxuKSEHK8iy5vW5YrRFE9sqKKxdUVw\n",
      "\u001b[32m2025-01-13 22:51:07.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 22:51:07.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m266\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m274\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 22:51:07.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 22:51:07.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 22:51:07.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 22:51:07.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m28\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m33\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m37\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 22:51:07.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Metadata CID: QmNjaCTeNdmrJfLYUpD8qhpjndXXX7QrWagRMhNSAtQkC6\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m266\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m274\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Validation Result for 73243@test: {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 22:51:07.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 22:51:07.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 22:51:07.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 22:51:07.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m28\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m33\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m37\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Metadata CID: QmdyAE132FSeSQaqUHzE5GtMrEwy821ScAYKEXsxpWSnV5\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m266\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m274\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Validation Result for 73243@test: {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 22:51:07.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 22:51:07.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 22:51:07.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 22:51:07.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m28\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m33\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m37\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Metadata CID: QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\n",
      "\u001b[32m2025-01-13 22:51:07.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - Fetched project details for 73243@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmPiZKhXpmKCJ7scjBNGeU2BxuDEac3AaDrNr55PwPuZZV\", \"linked_user\" : \"elated_noether@test\", \"project_metadata_cid\" : \"QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg\" } }\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m266\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m274\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Validation Result for 73243@test: {'is_valid': True, 'project_metadata_cid': 'QmW6MDJSfQD8pgMNkqCxNMYzeKkC8YDkCgHtkP5mkKzEqg', 'linked_user': 'elated_noether@test'}\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This paper analyzes how digital twins influences precision medicine, providing insights into how to maximize its energy reliability.', 'schema:endDate': '2025-03-10', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['digital twins', 'precision medicine', 'energy reliability'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Analyzing the Influence of digital twins on precision medicine', 'schema:startDate': '2023-05-12'}\n",
      "\u001b[32m2025-01-13 22:51:07.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 22:51:07.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'elated_noether@test', 'schema:publicKey': 'f26542c817bef9db2133e2a67fde4cbf07f408d897b9ce323b2d463cffe2598a', 'schema:roleName': 'author'}, 'foaf:mbox': 'elated_noether@email.com', 'foaf:name': 'Elated Noether', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Karachi School of Art'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '2182-3432-2982-X'}}\n",
      "\u001b[32m2025-01-13 22:51:07.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: elated_noether@test\n",
      "\u001b[32m2025-01-13 22:51:07.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m28\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m33\u001b[0m - Download directory ready: download/73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m37\u001b[0m - Downloading file to: download/73243@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 73243@test\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Metadata CID: QmWcdZFjgVaocJrPvDqKzf5KSFDcxypn5Ffyq9SNxQM1dN\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m266\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m274\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 22:51:07.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 22:51:07.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 22:51:07.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 22:51:07.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m28\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m33\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m37\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 22:51:07.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - File CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - Metadata CID: QmY3c4tCzveKDUZKjqyj9a6U8vDkuAs3q88D1UkcmWdBtJ\n",
      "\u001b[32m2025-01-13 22:51:07.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - Fetched project details for 37355@test: { \"admin@test\" : { \"file_1\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmVJ11wDAeAKEPamDTtW8UZKkQwxiHJcQ2kLZfes1eEjHF\", \"linked_user\" : \"wizardly_murdock@test\", \"project_metadata_cid\" : \"QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd\" } }\n",
      "\u001b[32m2025-01-13 22:51:07.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Fetching Project Details\n",
      "\u001b[32m2025-01-13 22:51:07.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Parsing Blockchain Data\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m266\u001b[0m - Validating and fetching details for CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mfetch_project_details\u001b[0m:\u001b[36m274\u001b[0m - File CID QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW found under file_1.\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - Validation Result for 37355@test: {'is_valid': True, 'project_metadata_cid': 'QmVqM2d9FhPwQNAhQ2mUCi9mzw8EdF3oqM4wzAHMUqcWWd', 'linked_user': 'wizardly_murdock@test'}\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Validating File CID\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - Downloaded project metadata: {'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This research focuses on the benefits and challenges posed by virtual reality for urban planning, with an emphasis on its potential for environmental restoration.', 'schema:endDate': '2025-05-16', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'Bill and Melinda Gates Foundation'}, 'schema:keywords': ['virtual reality', 'urban planning', 'environmental restoration'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Tokyo, Japan'}, 'schema:name': 'Assessing the Benefits of virtual reality for urban planning', 'schema:startDate': '2022-05-05'}\n",
      "\u001b[32m2025-01-13 22:51:07.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Project Metadata\n",
      "\u001b[32m2025-01-13 22:51:07.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 22:51:07.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - Downloaded user metadata: {'@type': 'foaf:Person', 'foaf:holdsAccount': {'schema:identifier': 'wizardly_murdock@test', 'schema:publicKey': '944f6ca0b600f7d9705a9dc1853ea6432221b91836251196630c02bf465cbf20', 'schema:roleName': 'author'}, 'foaf:mbox': 'wizardly_murdock@email.com', 'foaf:name': 'Wizardly Murdock', 'foaf:organization': {'@type': 'foaf:Organization', 'foaf:name': 'Baqai Medical University'}, 'schema:identifier': {'@type': 'PropertyValue', 'propertyID': 'ORCID', 'value': '3202-1900-4101-X'}}\n",
      "\u001b[32m2025-01-13 22:51:07.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Linked User: wizardly_murdock@test\n",
      "\u001b[32m2025-01-13 22:51:07.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m16\u001b[0m - \n",
      "==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m17\u001b[0m - STARTING BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m18\u001b[0m - ==================================================\n",
      "\u001b[32m2025-01-13 22:51:07.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m28\u001b[0m - Cleaned file name: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m33\u001b[0m - Download directory ready: download/37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msuper_helper\u001b[0m:\u001b[36mdownload_file\u001b[0m:\u001b[36m37\u001b[0m - Downloading file to: download/37355@test/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "\u001b[32m2025-01-13 22:51:07.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - Downloaded file metadata: None\n",
      "\u001b[32m2025-01-13 22:51:07.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Metadata CID\n",
      "\u001b[32m2025-01-13 22:51:07.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Result for Project ID: 37355@test\n",
      "\u001b[32m2025-01-13 22:51:07.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n",
      "\u001b[32m2025-01-13 22:51:07.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m24\u001b[0m - COMPLETED BLOCK: Processing Search Results\n",
      "\u001b[32m2025-01-13 22:51:07.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mwith_logging_block\u001b[0m:\u001b[36m25\u001b[0m - --------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def with_logging_block(block_name, logger):\n",
    "    \"\"\"\n",
    "    A reusable context manager for logging structured execution blocks.\n",
    "\n",
    "    Args:\n",
    "        block_name (str): The name of the block being executed.\n",
    "        logger (Logger): The logger instance.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"\\n\" + \"=\" * 50)\n",
    "        logger.info(f\"STARTING BLOCK: {block_name}\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        yield  # Code within the `with` block will execute here\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in block '{block_name}': {e}. Exiting.\")\n",
    "        sys.exit(1)  # Graceful exit on error\n",
    "    finally:\n",
    "        logger.info(f\"COMPLETED BLOCK: {block_name}\")\n",
    "        logger.info(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# Main Code Logic\n",
    "\n",
    "with with_logging_block(\"Keyword Search\", logger):\n",
    "    if not search_results:\n",
    "        logger.warning(f\"No search results found for keyword: '{keyword}'. Exiting the script.\")\n",
    "        sys.exit(1)\n",
    "    logger.info(f\"Search results for keyword '{keyword}':\")\n",
    "    for idx, result in enumerate(search_results, 1):\n",
    "        logger.info(f\"Result {idx}: {json.dumps(result, indent=2)}\")\n",
    "\n",
    "with with_logging_block(\"Processing Search Results\", logger):\n",
    "    for result_dict in search_results:\n",
    "        project_id = result_dict.get('project_id')\n",
    "        file_cid = result_dict.get('file_cid')\n",
    "        metadata_cid = result_dict.get('metadata_cid')\n",
    "\n",
    "        with with_logging_block(f\"Processing Result for Project ID: {project_id or 'Unknown'}\", logger):\n",
    "            if not project_id or not file_cid or not metadata_cid:\n",
    "                logger.error(f\"Missing required data in result: {result_dict}\")\n",
    "                continue\n",
    "\n",
    "            logger.info(f\"File CID: {file_cid}\")\n",
    "            logger.info(f\"Metadata CID: {metadata_cid}\")\n",
    "\n",
    "            # Fetch project details\n",
    "            with with_logging_block(\"Fetching Project Details\", logger):\n",
    "                project_details = get_account_detail(project_id)\n",
    "                if not project_details:\n",
    "                    logger.error(f\"No project details found for Project ID: {project_id}.\")\n",
    "                    continue\n",
    "                logger.info(f\"Fetched project details for {project_id}: {project_details}\")\n",
    "\n",
    "            # Parse blockchain data\n",
    "            with with_logging_block(\"Parsing Blockchain Data\", logger):\n",
    "                try:\n",
    "                    blockchain_data = json.loads(project_details)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(f\"Error decoding project details JSON for {project_id}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Validate file CID\n",
    "            with with_logging_block(\"Validating File CID\", logger):\n",
    "                validation_result = fetch_project_details(file_cid, blockchain_data)\n",
    "                logger.info(f\"Validation Result for {project_id}: {validation_result}\")\n",
    "                if not validation_result[\"is_valid\"]:\n",
    "                    logger.warning(f\"Invalid File CID for Project ID: {project_id}. Skipping metadata processing.\")\n",
    "                    continue\n",
    "\n",
    "            project_metadata_cid = validation_result.get(\"project_metadata_cid\")\n",
    "            linked_user = validation_result.get(\"linked_user\")\n",
    "\n",
    "            # Process project metadata\n",
    "            if project_metadata_cid:\n",
    "                with with_logging_block(\"Processing Project Metadata\", logger):\n",
    "                    project_metadata = download_json_from_ipfs(project_metadata_cid)\n",
    "                    logger.info(f\"Downloaded project metadata: {project_metadata}\")\n",
    "\n",
    "            # Process linked user details\n",
    "            if linked_user:\n",
    "                with with_logging_block(f\"Processing Linked User: {linked_user}\", logger):\n",
    "                    user_details = get_account_detail(linked_user)\n",
    "                    try:\n",
    "                        user_details = json.loads(user_details)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        logger.error(f\"Error decoding user details JSON for {linked_user}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    user_json_ld_cid = user_details.get(\"admin@test\", {}).get(\"user_json_ld_cid\")\n",
    "                    if user_json_ld_cid:\n",
    "                        user_metadata = download_json_from_ipfs(user_json_ld_cid)\n",
    "                        logger.info(f\"Downloaded user metadata: {user_metadata}\")\n",
    "                    else:\n",
    "                        logger.warning(f\"User JSON-LD CID not found for linked user {linked_user}.\")\n",
    "\n",
    "            # Process metadata CID\n",
    "            if metadata_cid:\n",
    "                with with_logging_block(\"Processing Metadata CID\", logger):\n",
    "                    file_metadata = download_json_from_ipfs(metadata_cid)\n",
    "                    file_metadata_json = download_file(file_metadata, download_path, project_id, file_cid)\n",
    "                    logger.info(f\"Downloaded file metadata: {file_metadata_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9596fe-6623-48ab-85f4-2de7974801ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
