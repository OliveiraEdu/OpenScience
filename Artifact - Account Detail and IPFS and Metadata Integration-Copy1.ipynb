{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11965914-6a6a-43b4-a793-01a3eda28617",
   "metadata": {},
   "source": [
    "Artifact - Account Detail and IPFS Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f965815-8625-49cb-9627-267ef1a19069",
   "metadata": {},
   "source": [
    "** For requirements and initial setup go to https://github.com/OliveiraEdu/OpenScience/Readme.md **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb3de9-bc7c-4300-9c29-c1388298331a",
   "metadata": {},
   "source": [
    "1 - Artifact - IPFS Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc02088-ba55-4f8e-bcc4-9c2e3afd3cca",
   "metadata": {},
   "source": [
    "# 1 - Account Detail with IPFS and Metadata Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1650332-a687-4cdb-aed9-cfb3ad2fbce3",
   "metadata": {},
   "source": [
    "As the user stores research artifacts such as articles, graphics and datasets into the platform it is necessary to establish a logical link of each artifact between the Iroha and the IPFS networks, such a link is implemented by: \n",
    "\n",
    "a) A metadata description of each artifact as an JSON object at ``assets.json``, the attributes can be freely anotated by the user strictyly following the [JSON standard specifications](https://www.json.org/json-en.html).\n",
    "\n",
    "b) The artifact file name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921ad3f2-fa0a-4f10-b9a5-6e98ad428844",
   "metadata": {},
   "source": [
    "## 1.1 - JSON Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c363a0-9fc3-4b54-b392-c16bad568b61",
   "metadata": {},
   "source": [
    "#### 1.1.1 - Here we extract the JSON metadata of each file from ``assets.json`` and the respective file and send them to the IPFS network node, the CID from both the metadata and the file are retrieved for further insertion as attributes of the user account on the Iroha network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b074d9-3edc-410d-9972-222d9cbb551f",
   "metadata": {},
   "source": [
    "## 1.2 -  Contract Deployment and Account Detail Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0a038-b871-411a-8ad1-5d23f65ab3bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Crypto.Hash import keccak\n",
    "import os\n",
    "import binascii\n",
    "from iroha import IrohaCrypto\n",
    "from iroha import Iroha, IrohaGrpc\n",
    "from iroha.ed25519 import H\n",
    "import integration_helpers\n",
    "from iroha.primitive_pb2 import can_set_my_account_detail\n",
    "import sys\n",
    "import csv\n",
    "import ipfshttpclient\n",
    "\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Python 3 or a more recent version is required.\")\n",
    "\n",
    "IROHA_HOST_ADDR = os.getenv(\"IROHA_HOST_ADDR\", \"10.0.0.100\")\n",
    "IROHA_PORT = os.getenv(\"IROHA_PORT\", \"50051\")\n",
    "ADMIN_ACCOUNT_ID = os.getenv(\"ADMIN_ACCOUNT_ID\", \"admin@test\")\n",
    "ADMIN_PRIVATE_KEY = os.getenv(\n",
    "    \"ADMIN_PRIVATE_KEY\",\n",
    "    \"f101537e319568c765b2cc89698325604991dca57b9716b58016b253506cab70\",\n",
    ")\n",
    "\n",
    "user_private_key = IrohaCrypto.private_key()\n",
    "user_public_key = IrohaCrypto.derive_public_key(user_private_key)\n",
    "iroha = Iroha(ADMIN_ACCOUNT_ID)\n",
    "net = IrohaGrpc(\"{}:{}\".format(IROHA_HOST_ADDR, IROHA_PORT))\n",
    "\n",
    "# Connect to the IPFS node at a specific IP address\n",
    "ipfs_client = ipfshttpclient.connect('/dns/10.0.0.100/tcp/5001/http')\n",
    "\n",
    "\n",
    "# Read account attributes from a csv\n",
    "def read_accounts_from_csv(file_path):\n",
    "    accounts = []\n",
    "    with open(file_path, mode='r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            accounts.append({\n",
    "                'account_id': row['account_id']\n",
    "            })\n",
    "    return accounts\n",
    "\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = 'datasets/accounts.csv'\n",
    "\n",
    "\n",
    "# Read accounts from CSV\n",
    "accounts = read_accounts_from_csv(csv_file_path)\n",
    "\n",
    "# Use the [n] account from the CSV for the example\n",
    "account = accounts[7]\n",
    "\n",
    "\n",
    "# # Specify the path to the file you want to upload\n",
    "# local_file_path = 'upload/Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf'\n",
    "\n",
    "\n",
    "# # Get the file name from the path\n",
    "# # FILE_NAME = os.path.basename(local_file_path)\n",
    "# # print(FILE_NAME)\n",
    "\n",
    "\n",
    "@integration_helpers.trace\n",
    "def create_contract():\n",
    "    bytecode = \"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\"\n",
    "    \"\"\"Bytecode was generated using remix editor  https://remix.ethereum.org/ from file detail.sol. \"\"\"\n",
    "    tx = iroha.transaction(\n",
    "        [iroha.command(\"CallEngine\", caller=ADMIN_ACCOUNT_ID, input=bytecode)]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    net.send_tx(tx)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    return hex_hash\n",
    "\n",
    "\n",
    "@integration_helpers.trace\n",
    "def set_account_detail(address, account, file_cid, metadata_cid):\n",
    "    params = integration_helpers.get_first_four_bytes_of_keccak(\n",
    "        b\"setAccountDetail(string,string,string)\"\n",
    "    )\n",
    "    no_of_param = 3\n",
    "    for x in range(no_of_param):\n",
    "        params = params + integration_helpers.left_padded_address_of_param(\n",
    "            x, no_of_param\n",
    "        )\n",
    "    params = params + integration_helpers.argument_encoding(account['account_id'])  # source account id\n",
    "    params = params + integration_helpers.argument_encoding(file_cid)  # key\n",
    "    params = params + integration_helpers.argument_encoding(metadata_cid)  #  value\n",
    "    tx = iroha.transaction(\n",
    "        [\n",
    "            iroha.command(\n",
    "                \"CallEngine\", caller=ADMIN_ACCOUNT_ID, callee=address, input=params\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    response = net.send_tx(tx)\n",
    "    print(response)\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    return hex_hash\n",
    "\n",
    "\n",
    "@integration_helpers.trace\n",
    "def get_account_details():\n",
    "    params = integration_helpers.get_first_four_bytes_of_keccak(b\"getAccountDetail()\")\n",
    "    no_of_param = 0\n",
    "    tx = iroha.transaction(\n",
    "        [\n",
    "            iroha.command(\n",
    "                \"CallEngine\", caller=ADMIN_ACCOUNT_ID, callee=address, input=params\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    response = net.send_tx(tx)\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    return hex_hash\n",
    "\n",
    "\n",
    "hash = create_contract()\n",
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "# hash = get_account_details()\n",
    "integration_helpers.get_engine_receipts_result(hash)\n",
    "hash = set_account_detail(address, account)\n",
    "print(account)\n",
    "\n",
    "# hash = get_account_details()\n",
    "# integration_helpers.get_engine_receipts_result(hash)\n",
    "\n",
    "# hash = create_contract()\n",
    "# address = integration_helpers.get_engine_receipts_address(hash)\n",
    "# integration_helpers.get_engine_receipts_result(hash)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "# #Working Example - Looks goog 22AUG2024\n",
    "\n",
    "# from json_ipfs_functions import *\n",
    "\n",
    "# def main():\n",
    "#     file_path = os.path.join('upload', 'assets.json')\n",
    "#     try:\n",
    "#         with open(file_path, 'r') as f:\n",
    "#             data = json.load(f)\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(f\"File not found: {e}\")\n",
    "#     else:\n",
    "        \n",
    "#         result = process_json_data(data)\n",
    "        \n",
    "#         metadata_cids = []\n",
    "#         file_cids = []\n",
    "\n",
    "#         for i in range(len(result['file_cids'])):\n",
    "#             file_cid = result['file_cids'][i][\"cid\"]\n",
    "#             json_cid_value = result['file_cids'][i][\"json_cid_value\"]\n",
    "\n",
    "#             metadata_cids.append(json_cid_value)\n",
    "#             file_cids.append(file_cid)\n",
    "\n",
    "#         metadata_index = 0\n",
    "#         file_index = 0\n",
    "\n",
    "#         while metadata_index < len(metadata_cids) and file_index < len(file_cids):\n",
    "#             variable_1 = f\"file_{metadata_index+1}_metadata_CID\"\n",
    "#             variable_2 = metadata_cids[metadata_index]\n",
    "#             print(f\"{variable_1} = {variable_2}\")\n",
    "#             metadata_index += 1\n",
    "#             hash = set_account_detail(address, account, variable_1, variable_2)\n",
    "#             print(account)\n",
    "\n",
    "#             if metadata_index <= len(metadata_cids) and file_index < len(file_cids):\n",
    "#                 variable_1 = f\"file_{metadata_index}_CID\"\n",
    "#                 variable_2 = file_cids[file_index]\n",
    "#                 print(f\"{variable_1} = {variable_2}\")\n",
    "#                 file_index += 1\n",
    "#                 hash = set_account_detail(address, account, variable_1, variable_2)\n",
    "#                 print(account)\n",
    "\n",
    "                \n",
    "       \n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec737a95-5e50-4e2d-8016-c7bb2f05596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=account['account_id'])\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "data = response.account_detail_response\n",
    "ic(data.detail)\n",
    "print(f'Account id = {account}, details = {data.detail}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04a47a-ca5e-496e-8e07-194d88b32dad",
   "metadata": {},
   "source": [
    "Retrieving an object from the IPFS node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3550b2-f580-439b-8ebb-cc41a45dfd03",
   "metadata": {},
   "source": [
    "1. From `data.detail` read `file_n_metadata_CID`\n",
    "2. Call function `download_json_from_ipfs` passing the `file_n_metada_CID` as the argument.\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c828ef9-1dc2-410d-87da-67446e6bc072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_ipfs_functions import *\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from icecream import ic\n",
    "\n",
    "def main():\n",
    "     \n",
    "    accounts = json.loads(data.detail)  # Since 'admin@test' is the top-level key, we'll consider it as an account\n",
    "    ic(accounts)\n",
    "    \n",
    "\n",
    "    for account in accounts.values():\n",
    "        ic(account)\n",
    "        \n",
    "        # Extract file metadata from the JSON data\n",
    "        files_metadata = {}\n",
    "        for key, value in account.items():\n",
    "            if '_CID' in key:\n",
    "                cid_key = key.replace('_CID', '')\n",
    "                if f'{cid_key}_metadata_CID' in account.keys():\n",
    "                    cid_value = value\n",
    "                    metadata_cid_value = account[f'{cid_key}_metadata_CID']\n",
    "                    files_metadata[cid_key] = {'cid': cid_value, 'metadata_cid': metadata_cid_value}\n",
    "\n",
    "    ic(files_metadata)\n",
    "\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        tasks = []\n",
    "        for file_name, file_data in files_metadata.items():\n",
    "            cid = file_data['cid']\n",
    "            metadata_cid = file_data['metadata_cid']\n",
    "\n",
    "            task = executor.submit(download_file_from_ipfs, cid, f\"download/{file_name}\")\n",
    "            tasks.append((file_name, task))\n",
    "\n",
    "        for i, (file_name, task) in enumerate(tasks):\n",
    "            try:\n",
    "                task.result()\n",
    "                print(f\"Downloaded file {i+1} successfully.\")\n",
    "            except Exception as e:\n",
    "                ic(file_name)\n",
    "                ic(e)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19802433-b931-40eb-a7a6-9096a41ef6b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| accounts: {'admin@test': {'file_1_CID': 'QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv',\n",
      "                              'file_1_metadata_CID': 'QmfJmXYxRGJXSbCXgHJrnQWVXKRsxJ2sAubPwU8iZf68ca',\n",
      "                              'file_2_CID': 'QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ',\n",
      "                              'file_2_metadata_CID': 'QmNPnr5bUAt4WKC4Rgh4w5gZfwmHAEdU6a24qehjBxXkCC',\n",
      "                              'file_3_CID': 'QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj',\n",
      "                              'file_3_metadata_CID': 'QmUMn338ahX7vynkMyRz5H4KdQe2HDZ4y6LnHHG591WuhC',\n",
      "                              'file_4_CID': 'QmVTTcqbGvYRn7n7uPYwk4vi8NdbeYvnZkX9MVT3byrAx2',\n",
      "                              'file_4_metadata_CID': 'QmXa3ZiZBHtgptXz161yHiPxcT6xRnJ6dku5SVtrSqvDpA',\n",
      "                              'file_5_CID': 'QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW',\n",
      "                              'file_5_metadata_CID': 'QmUSDqEVZ7pkHDzY8BMA83YzFgnDo7Nnf6VeqaUU579gDd',\n",
      "                              'user_account_email': 'vigorous_khayyam@email.com',\n",
      "                              'user_account_full_name': 'Vigorous Khayyam',\n",
      "                              'user_account_institution': 'Daniel Webster College',\n",
      "                              'user_account_orcid': '5575-3697-5104-X',\n",
      "                              'user_private_key': \"b'abee112bad494be2fca048fd429d98a6daf0ad90880871eaacf9e9f13956abf1'\",\n",
      "                              'user_public_key': 'd5c256be4494697650c3807e85de3805a056f7b5f8cb8d53d46349d3734b48cd'}}\n",
      "ic| account: {'file_1_CID': 'QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv',\n",
      "              'file_1_metadata_CID': 'QmfJmXYxRGJXSbCXgHJrnQWVXKRsxJ2sAubPwU8iZf68ca',\n",
      "              'file_2_CID': 'QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ',\n",
      "              'file_2_metadata_CID': 'QmNPnr5bUAt4WKC4Rgh4w5gZfwmHAEdU6a24qehjBxXkCC',\n",
      "              'file_3_CID': 'QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj',\n",
      "              'file_3_metadata_CID': 'QmUMn338ahX7vynkMyRz5H4KdQe2HDZ4y6LnHHG591WuhC',\n",
      "              'file_4_CID': 'QmVTTcqbGvYRn7n7uPYwk4vi8NdbeYvnZkX9MVT3byrAx2',\n",
      "              'file_4_metadata_CID': 'QmXa3ZiZBHtgptXz161yHiPxcT6xRnJ6dku5SVtrSqvDpA',\n",
      "              'file_5_CID': 'QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW',\n",
      "              'file_5_metadata_CID': 'QmUSDqEVZ7pkHDzY8BMA83YzFgnDo7Nnf6VeqaUU579gDd',\n",
      "              'user_account_email': 'vigorous_khayyam@email.com',\n",
      "              'user_account_full_name': 'Vigorous Khayyam',\n",
      "              'user_account_institution': 'Daniel Webster College',\n",
      "              'user_account_orcid': '5575-3697-5104-X',\n",
      "              'user_private_key': \"b'abee112bad494be2fca048fd429d98a6daf0ad90880871eaacf9e9f13956abf1'\",\n",
      "              'user_public_key': 'd5c256be4494697650c3807e85de3805a056f7b5f8cb8d53d46349d3734b48cd'}\n",
      "ic| f\"  - {file_name}:\": '  - file_1:'\n",
      "ic| f\"  - {file_name}:\": '  - file_2:'\n",
      "ic| f\"  - {file_name}:\": '  - file_3:'\n",
      "ic| f\"  - {file_name}:\": '  - file_4:'\n",
      "ic| f\"  - {file_name}:\": '  - file_5:'\n",
      "ic| file_name: 'file_1'\n",
      "ic| cid: 'QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m                 tasks\u001b[38;5;241m.\u001b[39mappend((file_name, task))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 70\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_metadata_json \u001b[38;5;129;01min\u001b[39;00m [file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata_cid\u001b[39m\u001b[38;5;124m'\u001b[39m]]:  \u001b[38;5;66;03m# assuming there's only one metadata json per file\u001b[39;00m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m file_metadata_json \u001b[38;5;129;01min\u001b[39;00m [file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata_cid\u001b[39m\u001b[38;5;124m'\u001b[39m]]:  \u001b[38;5;66;03m# assuming there's only one metadata json per file\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m             original_file_name \u001b[38;5;241m=\u001b[39m \u001b[43mfile_metadata_json\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m             output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownload/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m original_file_name\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;66;03m# original_file_name = file_metadata_json.get('file_name', 'Unknown')\u001b[39;00m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;66;03m# output_path = f\"download/{original_file_name}\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "#Working version 24AUG2024\n",
    "from json_ipfs_functions import *\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# # Define the base directory for downloading files\n",
    "# BASE_DOWNLOAD_DIR = \"download\"\n",
    "\n",
    "# def get_output_path(file_name):\n",
    "#     \"\"\"Returns the output path for downloading a file to the 'download' directory.\"\"\"\n",
    "#     return f\"{BASE_DOWNLOAD_DIR}/{original_file_name}\"\n",
    "\n",
    "# def download_file_from_ipfs(cid):\n",
    "#     try:\n",
    "#         # Download the file from IPFS using the provided CID\n",
    "#         downloaded_file = ipfs.get(cid)\n",
    "#         return downloaded_file.path\n",
    "#     except Exception as e:\n",
    "#         ic(f\"Failed to download file: {str(e)}\")\n",
    "#         return None\n",
    "\n",
    "def main():\n",
    "    # 1 - Parse Script #1 Output and retrieve all files metadata\n",
    "    accounts = json.loads(data.detail)  # Since 'admin@test' is the top-level key, we'll consider it as an account\n",
    "    ic(accounts)\n",
    "    \n",
    "\n",
    "    for account in accounts.values():\n",
    "        ic(account)\n",
    "        \n",
    "        # Extract file metadata from the JSON data\n",
    "        files_metadata = {}\n",
    "        for key, value in account.items():\n",
    "            if '_CID' in key:\n",
    "                cid_key = key.replace('_CID', '')\n",
    "                if f'{cid_key}_metadata_CID' in account.keys():\n",
    "                    cid_value = value\n",
    "                    metadata_cid_value = account[f'{cid_key}_metadata_CID']\n",
    "                    files_metadata[cid_key] = {'cid': cid_value, 'metadata_cid': metadata_cid_value}\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        tasks = []\n",
    "        for file_name, file_data in files_metadata.items():\n",
    "            cid = file_data['cid']\n",
    "            metadata_cid = file_data['metadata_cid']\n",
    "\n",
    "            task = executor.submit(download_file_from_ipfs, cid, f\"download/{file_name}\")\n",
    "            tasks.append((file_name, task))\n",
    "\n",
    "        for i, (file_name, task) in enumerate(tasks):\n",
    "            try:\n",
    "                task.result()\n",
    "                print(f\"Downloaded file {i+1} successfully.\")\n",
    "            except Exception as e:\n",
    "                ic(file_name)\n",
    "                ic(e)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b9bcb0-9193-43dc-a353-518e8b7ea2a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| accounts: {'admin@test': {'file_1_CID': 'QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv',\n",
      "                              'file_1_metadata_CID': 'QmfJmXYxRGJXSbCXgHJrnQWVXKRsxJ2sAubPwU8iZf68ca',\n",
      "                              'file_2_CID': 'QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ',\n",
      "                              'file_2_metadata_CID': 'QmNPnr5bUAt4WKC4Rgh4w5gZfwmHAEdU6a24qehjBxXkCC',\n",
      "                              'file_3_CID': 'QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj',\n",
      "                              'file_3_metadata_CID': 'QmUMn338ahX7vynkMyRz5H4KdQe2HDZ4y6LnHHG591WuhC',\n",
      "                              'file_4_CID': 'QmVTTcqbGvYRn7n7uPYwk4vi8NdbeYvnZkX9MVT3byrAx2',\n",
      "                              'file_4_metadata_CID': 'QmXa3ZiZBHtgptXz161yHiPxcT6xRnJ6dku5SVtrSqvDpA',\n",
      "                              'file_5_CID': 'QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW',\n",
      "                              'file_5_metadata_CID': 'QmUSDqEVZ7pkHDzY8BMA83YzFgnDo7Nnf6VeqaUU579gDd',\n",
      "                              'user_account_email': 'vigorous_khayyam@email.com',\n",
      "                              'user_account_full_name': 'Vigorous Khayyam',\n",
      "                              'user_account_institution': 'Daniel Webster College',\n",
      "                              'user_account_orcid': '5575-3697-5104-X',\n",
      "                              'user_private_key': \"b'abee112bad494be2fca048fd429d98a6daf0ad90880871eaacf9e9f13956abf1'\",\n",
      "                              'user_public_key': 'd5c256be4494697650c3807e85de3805a056f7b5f8cb8d53d46349d3734b48cd'}}\n",
      "ic| account: {'file_1_CID': 'QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv',\n",
      "              'file_1_metadata_CID': 'QmfJmXYxRGJXSbCXgHJrnQWVXKRsxJ2sAubPwU8iZf68ca',\n",
      "              'file_2_CID': 'QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ',\n",
      "              'file_2_metadata_CID': 'QmNPnr5bUAt4WKC4Rgh4w5gZfwmHAEdU6a24qehjBxXkCC',\n",
      "              'file_3_CID': 'QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj',\n",
      "              'file_3_metadata_CID': 'QmUMn338ahX7vynkMyRz5H4KdQe2HDZ4y6LnHHG591WuhC',\n",
      "              'file_4_CID': 'QmVTTcqbGvYRn7n7uPYwk4vi8NdbeYvnZkX9MVT3byrAx2',\n",
      "              'file_4_metadata_CID': 'QmXa3ZiZBHtgptXz161yHiPxcT6xRnJ6dku5SVtrSqvDpA',\n",
      "              'file_5_CID': 'QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW',\n",
      "              'file_5_metadata_CID': 'QmUSDqEVZ7pkHDzY8BMA83YzFgnDo7Nnf6VeqaUU579gDd',\n",
      "              'user_account_email': 'vigorous_khayyam@email.com',\n",
      "              'user_account_full_name': 'Vigorous Khayyam',\n",
      "              'user_account_institution': 'Daniel Webster College',\n",
      "              'user_account_orcid': '5575-3697-5104-X',\n",
      "              'user_private_key': \"b'abee112bad494be2fca048fd429d98a6daf0ad90880871eaacf9e9f13956abf1'\",\n",
      "              'user_public_key': 'd5c256be4494697650c3807e85de3805a056f7b5f8cb8d53d46349d3734b48cd'}\n",
      "ic| f\"  - {file_name}:\": '  - file_1:'\n",
      "ic| f\"  - {file_name}:\": '  - file_2:'\n",
      "ic| f\"  - {file_name}:\": '  - file_3:'\n",
      "ic| f\"  - {file_name}:\": '  - file_4:'\n",
      "ic| f\"  - {file_name}:\": '  - file_5:'\n",
      "ic| file_name: 'file_1'\n",
      "ic| cid: 'QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv'\n",
      "ic| output_path: 'download/Unknown'\n",
      "ic| file_name: 'file_2'\n",
      "ic| cid: 'QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ'\n",
      "ic| output_path: 'download/Unknown'\n",
      "ic| file_name: 'file_3'\n",
      "ic| cid: 'QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj'\n",
      "ic| output_path: 'download/Unknown'\n",
      "ic| file_name: 'file_4'\n",
      "ic| cid: 'QmVTTcqbGvYRn7n7uPYwk4vi8NdbeYvnZkX9MVT3byrAx2'\n",
      "ic| output_path: 'download/Unknown'\n",
      "ic| file_name: 'file_5'\n",
      "ic| cid: 'QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW'\n",
      "ic| output_path: 'download/Unknown'\n"
     ]
    }
   ],
   "source": [
    "#Working version 24AUG2024\n",
    "from json_ipfs_functions import *\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# # Define the base directory for downloading files\n",
    "# BASE_DOWNLOAD_DIR = \"download\"\n",
    "\n",
    "# def get_output_path(file_name):\n",
    "#     \"\"\"Returns the output path for downloading a file to the 'download' directory.\"\"\"\n",
    "#     return f\"{BASE_DOWNLOAD_DIR}/{original_file_name}\"\n",
    "\n",
    "# def download_file_from_ipfs(cid):\n",
    "#     try:\n",
    "#         # Download the file from IPFS using the provided CID\n",
    "#         downloaded_file = ipfs.get(cid)\n",
    "#         return downloaded_file.path\n",
    "#     except Exception as e:\n",
    "#         ic(f\"Failed to download file: {str(e)}\")\n",
    "#         return None\n",
    "\n",
    "def main():\n",
    "    # 1 - Parse Script #1 Output and retrieve all files metadata\n",
    "    accounts = json.loads(data.detail)  # Since 'admin@test' is the top-level key, we'll consider it as an account\n",
    "    ic(accounts)\n",
    "    \n",
    "\n",
    "    for account in accounts.values():\n",
    "        ic(account)\n",
    "        \n",
    "        # Extract file metadata from the JSON data\n",
    "        files_metadata = {}\n",
    "        for key, value in account.items():\n",
    "            if '_CID' in key:\n",
    "                cid_key = key.replace('_CID', '')\n",
    "                if f'{cid_key}_metadata_CID' in account.keys():\n",
    "                    cid_value = value\n",
    "                    metadata_cid_value = account[f'{cid_key}_metadata_CID']\n",
    "                    files_metadata[cid_key] = {'cid': cid_value, 'metadata_cid': metadata_cid_value}\n",
    "\n",
    "        # ic(\"Files metadata:\")\n",
    "        for file_name, file_data in files_metadata.items():\n",
    "            ic(f\"  - {file_name}:\")\n",
    "            # ic(f\"    CID: {file_data['cid']}\")\n",
    "            # ic(f\"    Metadata CID: {file_data['metadata_cid']}\")\n",
    "\n",
    "            # Call `download_json_from_ipfs` function and retrieves the actual json metadata\n",
    "            try:\n",
    "                file_metadata_json = download_json_from_ipfs(file_data['metadata_cid'])\n",
    "                # ic(\"File metadata:\")\n",
    "                # ic(json.dumps(file_metadata_json, indent=4))\n",
    "\n",
    "                # From the json key for file_name extracts its value\n",
    "                original_file_name = file_metadata_json.get('file_name', 'Unknown')\n",
    "                # output_path = get_output_path(original_file_name)\n",
    "            except Exception as e:\n",
    "                ic(f\"Failed to download metadata JSON for file '{file_name}': {str(e)}\")\n",
    "\n",
    "        # Download files from IPFS using their CID\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            tasks = []\n",
    "            for file_name, file_data in files_metadata.items():\n",
    "                cid = file_data['cid']\n",
    "                ic(file_name)\n",
    "                ic(cid)\n",
    "\n",
    "                # Assuming that each file has a corresponding metadata json\n",
    "                original_file_name = file_data.get('file_name', 'Unknown')\n",
    "                output_path = f\"download/{original_file_name}\"\n",
    "                ic(output_path)\n",
    "        \n",
    "                task = executor.submit(download_file_from_ipfs, cid, output_path)\n",
    "                tasks.append((file_name, task))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a31484-4d2b-4260-9391-bb79bb7722f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working version 24AUG2024\n",
    "from json_ipfs_functions import *\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# def download_file_from_ipfs(cid):\n",
    "#     try:\n",
    "#         downloaded_file = ipfs.get(cid)\n",
    "#         return downloaded_file.path\n",
    "#     except Exception as e:\n",
    "#         ic(f\"Failed to download file: {e}\")\n",
    "#         return None\n",
    "\n",
    "def main():\n",
    "\n",
    "    # 1 - Parse Script #1 Output and retrieve all files metadata\n",
    "    accounts = json.loads(data.detail)  # Since 'admin@test' is the top-level key, we'll consider it as an account\n",
    "    ic(accounts)\n",
    "    \n",
    "   \n",
    "    for account, metadata in accounts.items():\n",
    "        for original_file_name, cid_metadata_key in metadata.items():  # changed this line\n",
    "            if isinstance(cid_metadata_key, str):  # Check if the value is a string (assuming metadata CID key)\n",
    "                file_name = original_file_name.replace('_', ' ')\n",
    "                cid_keys = [k for k in metadata.keys() if k.endswith(f'{original_file_name}_metadata_CID')]  # get all keys that end with the suffix\n",
    "\n",
    "                if cid_keys:  # Check if there are any such keys\n",
    "                    cid = metadata.get(f'{original_file_name}_metadata_CID')\n",
    "                    if cid is None:\n",
    "                        ic(f\"No metadata found for file {file_name}\")\n",
    "\n",
    "                    \n",
    "                    output_path = f\"download/{file_name}\"\n",
    "                    if not os.path.exists(output_path):\n",
    "                        downloaded_file_path = download_file_from_ipfs(cid)\n",
    "                        if downloaded_file_path:\n",
    "                            shutil.copy(downloaded_file_path, output_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677ecd0-881b-47d3-8a0e-6edb338071d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_ipfs_functions import *\n",
    "\n",
    "def main():\n",
    "    file_metadata_json = download_json_from_ipfs(\"QmfJmXYxRGJXSbCXgHJrnQWVXKRsxJ2sAubPwU8iZf68ca\")\n",
    "    ic(file_metadata_json)\n",
    "    \n",
    "    file = download_file_from_ipfs(\"QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv\", \"download/\"+\"hello_word.py\")\n",
    "    ic(\"download succcess: \", file)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992444d-6a7b-46eb-9647-302b67486169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_ipfs_functions import *\n",
    "import json\n",
    "\n",
    "def main():\n",
    "    script1_output = json.loads((data.detail))\n",
    "    ic(script1_output)\n",
    "    \n",
    "    # 1 - Parse Script #1 Output and retrieve the values for file_1_metadata_CID\n",
    "    file_1_metadata_cid = script1_output['details']['admin@test']['file_1_metadata_CID']\n",
    "    ic(\"file_1_metadata_cid: \", file_1_metadata_cid)\n",
    "    \n",
    "    # 2 - Call `download_json_from_ipfs` function and retrieves the actual json metadata\n",
    "    file_metadata_json = download_json_from_ipfs(file_1_metadata_cid)\n",
    "    ic(file_metadata_json)\n",
    "    \n",
    "    # 3 - From the json key for file_name extracts its value\n",
    "    file_name = file_metadata_json['file_name']\n",
    "    ic(\"file_name: \", file_name)\n",
    "    \n",
    "    # 4 - Parse Script #1 Output and retrieve the values for file_1_CID\n",
    "    file_1_cid = script1_output['details']['admin@test']['file_1_CID']\n",
    "    ic(\"file_1_cid: \", file_1_cid)\n",
    "    \n",
    "    # 5 - Download the file calling function download_file_from_ipfs with the name obtained in step 3\n",
    "    downloaded_file = download_file_from_ipfs(file_1_cid, \"download/\" + file_name)\n",
    "    ic(\"Download success: \", downloaded_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0abe93-007a-4a1b-984f-3ee8b958b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_ipfs_functions import *\n",
    "import json\n",
    "\n",
    "def main():\n",
    "    script1_output = json.loads(data.detail)\n",
    "    ic(script1_output)\n",
    "\n",
    "    # 1 - Parse Script #1 Output and retrieve the values for file_1_metadata_CID\n",
    "    accounts = script1_output  # Since 'admin@test' is the top-level key, we'll consider it as an account\n",
    "\n",
    "    for account in accounts.values():\n",
    "        ic(account)\n",
    "        \n",
    "        file1_metadata_cid = account['file_1_metadata_CID']\n",
    "        ic(\"file_1_metadata_cid: \", file1_metadata_cid)\n",
    "\n",
    "        # 2 - Call `download_json_from_ipfs` function and retrieves the actual json metadata\n",
    "        file_metadata_json = download_json_from_ipfs(file1_metadata_cid)\n",
    "        ic(file_metadata_json)\n",
    "\n",
    "        # 3 - From the json key for file_name extracts its value\n",
    "        file_name = file_metadata_json['file_name']\n",
    "        ic(\"file_name: \", file_name)\n",
    "\n",
    "        # 4 - Parse Script #1 Output and retrieve the values for file_1_CID\n",
    "        file1_cid = account['file_1_CID']\n",
    "        ic(\"file_1_cid: \", file1_cid)\n",
    "\n",
    "        # 5 - Download the file from IPFS using its CID\n",
    "        try:\n",
    "            downloaded_file = download_file_from_ipfs(file1_cid, \"download/\"+file_name)\n",
    "            ic(\"Downloaded file: \", downloaded_file)\n",
    "        except Exception as e:\n",
    "            ic(f\"Failed to download file: {str(e)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305ab40-3ebf-428a-abf9-3ba43214a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_ipfs_functions import *\n",
    "import json\n",
    "\n",
    "def main():\n",
    "    script1_output = json.loads(data.detail)\n",
    "    ic(script1_output)\n",
    "\n",
    "    # 1 - Parse Script #1 Output and retrieve all files metadata\n",
    "    accounts = script1_output  # Since 'admin@test' is the top-level key, we'll consider it as an account\n",
    "\n",
    "    for account in accounts.values():\n",
    "        ic(account)\n",
    "        \n",
    "        # Extract file metadata from the JSON data\n",
    "        files_metadata = {}\n",
    "        for key, value in account.items():\n",
    "            if '_CID' in key:\n",
    "                cid_key = key.replace('_CID', '')\n",
    "                if f'{cid_key}_metadata_CID' in account.keys():\n",
    "                    cid_value = value\n",
    "                    metadata_cid_value = account[f'{cid_key}_metadata_CID']\n",
    "                    files_metadata[cid_key] = {'cid': cid_value, 'metadata_cid': metadata_cid_value}\n",
    "\n",
    "        ic(\"Files metadata:\")\n",
    "        for file_name, file_data in files_metadata.items():\n",
    "            ic(f\"  - {file_name}:\")\n",
    "            ic(f\"    CID: {file_data['cid']}\")\n",
    "            ic(f\"    Metadata CID: {file_data['metadata_cid']}\")\n",
    "\n",
    "            # Call `download_json_from_ipfs` function and retrieves the actual json metadata\n",
    "            try:\n",
    "                file_metadata_json = download_json_from_ipfs(file_data['metadata_cid'])\n",
    "                ic(\"File metadata:\")\n",
    "                ic(json.dumps(file_metadata_json, indent=4))\n",
    "\n",
    "                # From the json key for file_name extracts its value\n",
    "                file_name_value = file_metadata_json.get('file_name', 'Unknown')\n",
    "                ic(f\"  File name: {file_name_value}\")\n",
    "            except Exception as e:\n",
    "                ic(f\"Failed to download metadata JSON for file '{file_name}': {str(e)}\")\n",
    "\n",
    "        # Download files from IPFS using their CID\n",
    "        for file_name, file_data in files_metadata.items():\n",
    "            try:\n",
    "                downloaded_file = download_file_from_ipfs(file_data['cid'], \"download/\" + file_name_value)\n",
    "                ic(f\"Downloaded file: {downloaded_file}\")\n",
    "            except Exception as e:\n",
    "                ic(f\"Failed to download file '{file_name}': {str(e)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e37bac-6910-4766-8361-95aa7e5868da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
