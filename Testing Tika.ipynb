{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e258e2d-b1cd-4657-9cd5-f1c4ba7b38eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['metadata', 'content', 'status'])\n",
      "{'Number of Tables': '4 Huffman tables', 'File Modified Date': 'Sun Sep 15 00:33:54 +00:00 2024', 'Compression Type': 'Baseline', 'Data Precision': '8 bits', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.image.JpegParser'], 'Number of Components': '3', 'tiff:ImageLength': '623', 'resourceName': \"b'Jean-Baptiste_Perronneau_-_Magdaleine_Pinceloup_de_la_Grange,_n\\\\xc3\\\\xa9e_de_Parseval.jpg'\", 'Component 2': 'Cb component: Quantization table 1, Sampling factors 1 horiz/1 vert', 'Component 1': 'Y component: Quantization table 0, Sampling factors 2 horiz/2 vert', 'Image Height': '623 pixels', 'Image Width': '500 pixels', 'File Size': '72495 bytes', 'Component 3': 'Cr component: Quantization table 1, Sampling factors 1 horiz/1 vert', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.image.JpegParser'], 'X-TIKA:parse_time_millis': '11', 'X-TIKA:embedded_depth': '0', 'File Name': \"apache-tika-5331298663160343984.jpg'\", 'Content-Length': '72495', 'tiff:BitsPerSample': '8', 'tiff:ImageWidth': '500', 'Content-Type': 'image/jpeg'}\n",
      "<class 'dict'>\n",
      "200 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "from parse_documents import *\n",
    "\n",
    "filepath = 'upload/Jean-Baptiste_Perronneau_-_Magdaleine_Pinceloup_de_la_Grange,_née_de_Parseval.jpg'  # Replace with the path of your file\n",
    "# filepath = \"upload/World_Energy_By_Country_And_Region_1965_to_2023.csv\"\n",
    "# filepath = 'upload/Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf'\n",
    "parse_document(filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c73fd5a-459c-4cb0-9666-337c3be7b58a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tika.parser' has no attribute 'from_bytes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 7\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_bytes\u001b[49m(content, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# The 'filename' field of parser.metadata should now contain the original name with preserved encoding.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(parser\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tika.parser' has no attribute 'from_bytes'"
     ]
    }
   ],
   "source": [
    "from tika import parser\n",
    "\n",
    "# Open your file in binary mode to get its raw bytes\n",
    "with open(filepath, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "parser = parser.from_bytes(content, metadata=True)\n",
    "\n",
    "# The 'filename' field of parser.metadata should now contain the original name with preserved encoding.\n",
    "print(parser.metadata['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc35f9f1-0bce-454d-9043-aa561a058ca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chardet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Open your file in binary mode to get its raw bytes\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chardet'"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "# Open your file in binary mode to get its raw bytes\n",
    "with open(filepath, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "parser = tika.parser.from_bytes(content, metadata=True)\n",
    "encoding_guess = chardet.detect(parser.get_content())\n",
    "\n",
    "if encoding_guess['confidence'] > 0.9:  # Confidence threshold can be adjusted based on your needs\n",
    "    # Use the detected encoding to re-interpret the file name correctly.\n",
    "    original_filename = parser.metadata['resourceName'].decode(encoding_guess['encoding'])\n",
    "else:\n",
    "    # For cases where detection is uncertain or fails, you might consider falling back to UTF-8 (or another default).\n",
    "    original_filename = parser.metadata['resourceName'].decode('utf-8', errors='replace')\n",
    "\n",
    "print(original_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f581976-9cb0-449e-ae8e-e10e4cf05801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "\n",
    "def parse_document(filepath):\n",
    "    try:\n",
    "        parsed_document = parser.from_file(filepath)\n",
    "        \n",
    "        # Check if parsing was successful\n",
    "        if 'status' in parsed_document and parsed_document['status'] == 200:\n",
    "            print(f\"Parsing successful: {parsed_document['status']}\")\n",
    "        else:\n",
    "            print(f\"Parsing failed with status: {parsed_document.get('status')}\")\n",
    "            return\n",
    "        \n",
    "        # Print the type and keys of the parsed document\n",
    "        print(type(parsed_document))\n",
    "        print(parsed_document.keys())\n",
    "\n",
    "        # Extract and print metadata if available\n",
    "        metadata = parsed_document.get('metadata', {})\n",
    "        if metadata:\n",
    "            print(\"Metadata:\")\n",
    "            print(metadata)\n",
    "        else:\n",
    "            print(\"No metadata found.\")\n",
    "        \n",
    "        # Print content if needed (commented to avoid large outputs)\n",
    "        # print(parsed_document.get('content', 'No content available'))\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filepath}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "parse_document(\"upload/Jean-Baptiste_Perronneau_-_Magdaleine_Pinceloup_de_la_Grange,_née_de_Parseval.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcf833-4952-402e-a496-bcb2d1c68cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "\n",
    "def parse_document(filepath):\n",
    "    try:\n",
    "        parsed_document = parser.from_file(filepath)\n",
    "        \n",
    "        # Check if parsing was successful\n",
    "        if 'status' in parsed_document and parsed_document['status'] == 200:\n",
    "            print(f\"Parsing successful: {parsed_document['status']}\")\n",
    "        else:\n",
    "            print(f\"Parsing failed with status: {parsed_document.get('status')}\")\n",
    "            return\n",
    "        \n",
    "        # Extract and print list of keys in the parsed document\n",
    "        document_keys = list(parsed_document.keys())\n",
    "        print(\"Keys in the parsed document:\")\n",
    "        print(document_keys)\n",
    "\n",
    "        # Extract metadata keys if available\n",
    "        metadata = parsed_document.get('metadata', {})\n",
    "        if metadata:\n",
    "            metadata_keys = list(metadata.keys())\n",
    "            print(\"Keys in metadata:\")\n",
    "            print(metadata_keys)\n",
    "        else:\n",
    "            print(\"No metadata found.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filepath}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "parse_document(\"upload/Jean-Baptiste_Perronneau_-_Magdaleine_Pinceloup_de_la_Grange,_née_de_Parseval.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4fa24-1d10-49a4-90f8-a6d8f33f6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tika import parser\n",
    "from ipfs_functions import *\n",
    "\n",
    "def parse_documents_in_directory(directory_path):\n",
    "    temp_dir = \"tmp\" # Get the system's temporary directory\n",
    "    print(f\"Saving metadata files in temporary directory: {temp_dir}\")\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        upload_file_to_ipfs(directory_path + \"/\" + filename)\n",
    "        \n",
    "        # Check if it's a file and not a directory\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                parsed_document = parser.from_file(file_path)\n",
    "                \n",
    "                # Check if parsing was successful\n",
    "                if 'status' in parsed_document and parsed_document['status'] == 200:\n",
    "                    metadata = parsed_document.get('metadata', {})\n",
    "                    print(metadata)\n",
    "                    upload_json_to_ipfs(metadata)\n",
    "                    \n",
    "                    # Save metadata as JSON\n",
    "                    if metadata:\n",
    "                        json_filename = f\"{os.path.splitext(filename)[0]}.json\"\n",
    "                        json_path = os.path.join(temp_dir, json_filename)\n",
    "\n",
    "                        with open(json_path, 'w') as json_file:\n",
    "                            json.dump(metadata, json_file, indent=4)\n",
    "                        \n",
    "                        print(f\"Metadata saved for '{filename}' as '{json_filename}'\")\n",
    "                    else:\n",
    "                        print(f\"No metadata found for '{filename}'\")\n",
    "                else:\n",
    "                    print(f\"Parsing failed for '{filename}' with status: {parsed_document.get('status')}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred with file '{filename}': {e}\")\n",
    "\n",
    "# Example usage\n",
    "parse_documents_in_directory(\"upload\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c0b2c9-a661-41c0-b40f-f90aa2562cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| result['Name']: 'assets.csv'\n",
      "    result['Hash']: 'QmWRMwc5taM4BaapEhLPpmZVPrN7WmxoEyyaQvoSgUqfWW'\n",
      "ic| file_metadata_CID: 'QmaufPiaidvwUQz9gWxZXsBdMsyAEDd3MyyuLF4Y8btnzo'\n",
      "ic| result['Name']: 'Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf'\n",
      "    result['Hash']: 'QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload/assets.csv\n",
      "upload/Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| file_metadata_CID: 'QmUaGWKsvakqW7Vu2pBpEsjApc6UYd2yrsLaE7P73ESW9c'\n",
      "ic| result['Name']: 'Munafò et al. - 2022 - The reproducibility debate is an opportunity, not .pdf'\n",
      "    result['Hash']: 'QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW'\n",
      "ic| file_metadata_CID: 'QmW21d1oEvzw3cjEPkxMDZ1uhxgQ3LrPEfhLyp4d6ZJ2yA'\n",
      "ic| result['Name']: 'assets.json'\n",
      "    result['Hash']: 'QmZ9tmsiUTt22eyHqkA84wns29sWwZ94LGHBZzUjbaGwFu'\n",
      "ic| file_metadata_CID: 'QmdDXTjH47hf9X6LkSVb8pxWnV3CbLfNzm69Bvo8QBiKWK'\n",
      "ic| result['Name']: 'Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf'\n",
      "    result['Hash']: 'QmXquoApMLCcauNkz4tYw1Sp2tsqZ4edv1YtnQi5pmbw6C'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload/Munafò et al. - 2022 - The reproducibility debate is an opportunity, not .pdf\n",
      "upload/assets.json\n",
      "upload/Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| file_metadata_CID: 'QmPgVNGQYSacGPMMPdxnZUySX19hLoa7hiHVeF59bZwsbE'\n",
      "ic| result['Name']: 'Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf'\n",
      "    result['Hash']: 'QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload/Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| file_metadata_CID: 'QmcKLJJjPzK3DPbKuogfvKhfmbUfdvRmzDfV43M7nhwKL4'\n",
      "ic| result['Name']: 'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\n",
      "    result['Hash']: 'QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW'\n",
      "ic| file_metadata_CID: 'QmYNLkMVn78vk3hb47SpaqMsTmsCbjHxUfqUKbZm43WsmV'\n",
      "ic| result['Name']: 'World_Energy_By_Country_And_Region_1965_to_2023.csv'\n",
      "    result['Hash']: 'QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ'\n",
      "ic| file_metadata_CID: 'QmPWyTKJ5kArkhtfU3sFqeBe5gzPCj8NEC964av3r3rmMc'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload/COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "upload/World_Energy_By_Country_And_Region_1965_to_2023.csv\n",
      "upload/Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| result['Name']: 'Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf'\n",
      "    result['Hash']: 'QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q'\n",
      "ic| file_metadata_CID: 'QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh'\n",
      "ic| result['Name']: 'Jean-Baptiste_Perronneau_-_Magdaleine_Pinceloup_de_la_Grange,_née_de_Parseval.jpg'\n",
      "    result['Hash']: 'QmVTTcqbGvYRn7n7uPYwk4vi8NdbeYvnZkX9MVT3byrAx2'\n",
      "ic| file_metadata_CID: 'QmRAMLeY5eeV7HwexwcmP2SgnTghyHKvXXTQisipBvmD3E'\n",
      "ic| result['Name']: 'bitcoin.pdf'\n",
      "    result['Hash']: 'QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj'\n",
      "ic| file_metadata_CID: 'QmUa22LAJeLd2Zf57bKgyLm9Ja9BDCfhmxXkxJzX55Jpvw'\n",
      "ic| result['Name']: 'hello_world.py'\n",
      "    result['Hash']:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload/Jean-Baptiste_Perronneau_-_Magdaleine_Pinceloup_de_la_Grange,_née_de_Parseval.jpg\n",
      "upload/bitcoin.pdf\n",
      "upload/hello_world.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 'QmeBTz4ZwyqPkPigpASZ3wJodBXzJRpeXQMwNcsWRqU5Jv'\n",
      "ic| file_metadata_CID: 'QmWwZb9S8tE764UCs6Lvzfevjuv7wWjKbYQMqNpJmZba14'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tika import parser\n",
    "from ipfs_functions import *\n",
    "\n",
    "def parse_documents_in_directory(directory_path):\n",
    "    \n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        print(file_path)\n",
    "        upload_file_to_ipfs(file_path)\n",
    "        \n",
    "        # Check if it's a file and not a directory\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                parsed_document = parser.from_file(file_path)\n",
    "                \n",
    "                # Check if parsing was successful\n",
    "                if 'status' in parsed_document and parsed_document['status'] == 200:\n",
    "                    metadata = parsed_document.get('metadata', {})\n",
    "                    upload_json_to_ipfs(metadata)\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"Parsing failed for '{filename}' with status: {parsed_document.get('status')}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred with file '{filename}': {e}\")\n",
    "\n",
    "# Example usage\n",
    "parse_documents_in_directory(\"upload\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02066a-d88e-4818-a33a-6165a12c4422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
