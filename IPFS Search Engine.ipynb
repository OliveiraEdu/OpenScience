{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa98ba-1b7d-4c82-b8ff-137f5b8ef387",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "import ipfshttpclient\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID, NUMERIC\n",
    "from whoosh.qparser import QueryParser\n",
    "import os\n",
    "\n",
    "# Load configuration from config.json file\n",
    "config_path = \"config.json\"  # Update this path as needed\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IPFS_ADDRESS = config[\"IPFS_ADDRESS\"]\n",
    "\n",
    "# Connect to the IPFS node at a specific IP address and port\n",
    "ipfs_address = f\"/dns/{config['IPFS_ADDRESS']}/tcp/{config['IPFS_PORT']}/http\"\n",
    "client = ipfshttpclient.connect(ipfs_address)\n",
    "\n",
    "# Define schema for indexing\n",
    "schema = Schema(\n",
    "    cid=ID(stored=True),               # The IPFS CID\n",
    "    name=TEXT(stored=True),            # Filename\n",
    "    size=NUMERIC(stored=True),         # File size\n",
    "    filetype=TEXT(stored=True),        # File type (MIME type)\n",
    ")\n",
    "\n",
    "# Create the index directory\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "\n",
    "# Create index in the directory\n",
    "ix = create_in(\"indexdir\", schema)\n",
    "\n",
    "# Function to index IPFS content\n",
    "def index_ipfs_content(cid, filename):\n",
    "    try:\n",
    "        # Fetch file stats from IPFS\n",
    "        stats = client.object.stat(cid)\n",
    "        file_size = stats['CumulativeSize']\n",
    "        \n",
    "        # Fetch file info (you can expand this for more file types)\n",
    "        filetype = filename.split(\".\")[-1] if \".\" in filename else \"unknown\"\n",
    "\n",
    "        # Index the content\n",
    "        writer = ix.writer()\n",
    "        writer.add_document(\n",
    "            cid=cid,\n",
    "            name=filename,\n",
    "            size=file_size,\n",
    "            filetype=filetype,\n",
    "        )\n",
    "        writer.commit()\n",
    "        print(f\"Indexed {filename} with CID: {cid}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to index CID {cid}: {e}\")\n",
    "\n",
    "# Search IPFS index based on keyword\n",
    "def search_ipfs(keyword):\n",
    "    with ix.searcher() as searcher:\n",
    "        query = QueryParser(\"name\", ix.schema).parse(keyword)\n",
    "        results = searcher.search(query)\n",
    "        if results:\n",
    "            for result in results:\n",
    "                print(f\"CID: {result['cid']}, Name: {result['name']}, Size: {result['size']} bytes, File Type: {result['filetype']}\")\n",
    "        else:\n",
    "            print(f\"No results found for '{keyword}'\")\n",
    "\n",
    "# Example usage: Index some files on your local IPFS node\n",
    "index_ipfs_content(\"QmXj...\", \"example.txt\")  # Replace with actual CID and filename\n",
    "index_ipfs_content(\"QmYk...\", \"document.pdf\")  # Replace with actual CID and filename\n",
    "\n",
    "# Example search\n",
    "search_ipfs(\"example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a637ea22-9742-4fa8-ace4-6b8a185c33eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed upload/Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf with CID: QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4\n",
      "Indexed upload/World_Energy_By_Country_And_Region_1965_to_2023.csv with CID: QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ\n",
      "Indexed upload/Munafò et al. - 2022 - The reproducibility debate is an opportunity, not .pdf with CID: QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW\n",
      "CID: QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW, Name: upload/Munafò et al. - 2022 - The reproducibility debate is an opportunity, not .pdf, Size: 694719 bytes, File Type: pdf\n"
     ]
    }
   ],
   "source": [
    "import ipfshttpclient\n",
    "import whoosh\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID, NUMERIC\n",
    "from whoosh.qparser import QueryParser\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Load configuration from config.json file\n",
    "config_path = \"config.json\"  # Update this path as needed\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IPFS_ADDRESS = config[\"IPFS_ADDRESS\"]\n",
    "\n",
    "# Connect to the IPFS node at a specific IP address and port\n",
    "ipfs_address = f\"/dns/{config['IPFS_ADDRESS']}/tcp/{config['IPFS_PORT']}/http\"\n",
    "client = ipfshttpclient.connect(ipfs_address)\n",
    "\n",
    "\n",
    "# Connect to local IPFS\n",
    "# client = ipfshttpclient.connect()\n",
    "\n",
    "# Define schema for indexing\n",
    "schema = Schema(\n",
    "    cid=ID(stored=True),               # The IPFS CID\n",
    "    name=TEXT(stored=True),            # Filename\n",
    "    size=NUMERIC(stored=True),         # File size\n",
    "    filetype=TEXT(stored=True),        # File type (MIME type)\n",
    ")\n",
    "\n",
    "# Create the index directory\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "\n",
    "# Create index in the directory\n",
    "ix = create_in(\"indexdir\", schema)\n",
    "\n",
    "# Function to index IPFS content\n",
    "def index_ipfs_content(cid, filename):\n",
    "    try:\n",
    "        # Fetch file stats from IPFS\n",
    "        stats = client.object.stat(cid)\n",
    "        file_size = stats['CumulativeSize']\n",
    "        \n",
    "        # Fetch file info (you can expand this for more file types)\n",
    "        filetype = filename.split(\".\")[-1] if \".\" in filename else \"unknown\"\n",
    "\n",
    "        # Index the content\n",
    "        writer = ix.writer()\n",
    "        writer.add_document(\n",
    "            cid=cid,\n",
    "            name=filename,\n",
    "            size=file_size,\n",
    "            filetype=filetype,\n",
    "        )\n",
    "        writer.commit()\n",
    "        print(f\"Indexed {filename} with CID: {cid}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to index CID {cid}: {e}\")\n",
    "\n",
    "# Search IPFS index based on keyword\n",
    "def search_ipfs(keyword):\n",
    "    with ix.searcher() as searcher:\n",
    "        query = QueryParser(\"name\", ix.schema).parse(keyword)\n",
    "        results = searcher.search(query)\n",
    "        if results:\n",
    "            for result in results:\n",
    "                print(f\"CID: {result['cid']}, Name: {result['name']}, Size: {result['size']} bytes, File Type: {result['filetype']}\")\n",
    "        else:\n",
    "            print(f\"No results found for '{keyword}'\")\n",
    "\n",
    "# Example usage: Index some files on your local IPFS node\n",
    "index_ipfs_content(\"QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4\", \"upload/Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf\")  # Replace with actual CID and filename\n",
    "index_ipfs_content(\"QmSSY49SnmbCZ3oSaTki7CYZe1ZaWZfE1CsWHpt8Ge7acJ\", \"upload/World_Energy_By_Country_And_Region_1965_to_2023.csv\")  # Replace with actual CID and filename\n",
    "index_ipfs_content(\"QmdiRawzVNUiB28ENKQ7WefeFLEJ1xMjsJjwtHL2jnJ9xW\", \"upload/Munafò et al. - 2022 - The reproducibility debate is an opportunity, not .pdf\")  # Replace with actual CID and filename\n",
    "\n",
    "# Example search\n",
    "search_ipfs(\"reproducibility\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da3d47-0802-4438-84ff-e59bbcd5c79e",
   "metadata": {},
   "source": [
    "Here's a basic Python script to implement a simple IPFS search engine for your local IPFS server. It will crawl through the IPFS content, extract basic metadata (like file size, type, and CID), and enable a keyword-based search for files with the help of well-known Python modules.\n",
    "\n",
    "### Prerequisites:\n",
    "1. **Install the IPFS HTTP client library**:\n",
    "   - You can use the `ipfshttpclient` module to interact with your IPFS server. Install it with:\n",
    "     ```bash\n",
    "     pip install ipfshttpclient\n",
    "     ```\n",
    "   \n",
    "2. **Install `Whoosh` for search indexing**:\n",
    "   - We'll use `Whoosh` for building and querying the search index. Install it with:\n",
    "     ```bash\n",
    "     pip install whoosh\n",
    "     ```\n",
    "\n",
    "### Basic Python Search Engine for IPFS\n",
    "\n",
    "```python\n",
    "import ipfshttpclient\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID, NUMERIC\n",
    "from whoosh.qparser import QueryParser\n",
    "import os\n",
    "\n",
    "# Load configuration from config.json file\n",
    "config_path = \"config.json\"  # Update this path as needed\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IPFS_ADDRESS = config[\"IPFS_ADDRESS\"]\n",
    "\n",
    "# Connect to the IPFS node at a specific IP address and port\n",
    "ipfs_address = f\"/dns/{config['IPFS_ADDRESS']}/tcp/{config['IPFS_PORT']}/http\"\n",
    "client = ipfshttpclient.connect(ipfs_address)\n",
    "\n",
    "# Define schema for indexing\n",
    "schema = Schema(\n",
    "    cid=ID(stored=True),               # The IPFS CID\n",
    "    name=TEXT(stored=True),            # Filename\n",
    "    size=NUMERIC(stored=True),         # File size\n",
    "    filetype=TEXT(stored=True),        # File type (MIME type)\n",
    ")\n",
    "\n",
    "# Create the index directory\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "\n",
    "# Create index in the directory\n",
    "ix = create_in(\"indexdir\", schema)\n",
    "\n",
    "# Function to index IPFS content\n",
    "def index_ipfs_content(cid, filename):\n",
    "    try:\n",
    "        # Fetch file stats from IPFS\n",
    "        stats = client.object.stat(cid)\n",
    "        file_size = stats['CumulativeSize']\n",
    "        \n",
    "        # Fetch file info (you can expand this for more file types)\n",
    "        filetype = filename.split(\".\")[-1] if \".\" in filename else \"unknown\"\n",
    "\n",
    "        # Index the content\n",
    "        writer = ix.writer()\n",
    "        writer.add_document(\n",
    "            cid=cid,\n",
    "            name=filename,\n",
    "            size=file_size,\n",
    "            filetype=filetype,\n",
    "        )\n",
    "        writer.commit()\n",
    "        print(f\"Indexed {filename} with CID: {cid}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to index CID {cid}: {e}\")\n",
    "\n",
    "# Search IPFS index based on keyword\n",
    "def search_ipfs(keyword):\n",
    "    with ix.searcher() as searcher:\n",
    "        query = QueryParser(\"name\", ix.schema).parse(keyword)\n",
    "        results = searcher.search(query)\n",
    "        if results:\n",
    "            for result in results:\n",
    "                print(f\"CID: {result['cid']}, Name: {result['name']}, Size: {result['size']} bytes, File Type: {result['filetype']}\")\n",
    "        else:\n",
    "            print(f\"No results found for '{keyword}'\")\n",
    "\n",
    "# Example usage: Index some files on your local IPFS node\n",
    "index_ipfs_content(\"QmXj...\", \"example.txt\")  # Replace with actual CID and filename\n",
    "index_ipfs_content(\"QmYk...\", \"document.pdf\")  # Replace with actual CID and filename\n",
    "\n",
    "# Example search\n",
    "search_ipfs(\"example\")\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Connecting to IPFS**:\n",
    "   - The script connects to your local IPFS node using `ipfshttpclient`.\n",
    "   \n",
    "2. **Indexing Files**:\n",
    "   - The `index_ipfs_content` function takes an IPFS CID and a filename as input.\n",
    "   - It fetches file metadata (such as file size) using the `object.stat` function from the IPFS client and stores this data in an index using `Whoosh`.\n",
    "\n",
    "3. **Schema**:\n",
    "   - The schema defines how the files are indexed. We store the CID, filename, file size, and type.\n",
    "\n",
    "4. **Searching**:\n",
    "   - The `search_ipfs` function allows you to search the index based on filenames.\n",
    "   - It uses `Whoosh`'s `QueryParser` to search the index and print out the search results.\n",
    "\n",
    "### Running the Script:\n",
    "- Run the script in Python, and it will index files from your local IPFS server and allow you to search for them using keywords.\n",
    "- Replace `\"QmXj...\"` and `\"QmYk...\"` with actual IPFS CIDs and filenames from your server.\n",
    "\n",
    "This setup keeps the search engine simple and easily expandable for more metadata or complex searches later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fbbcab-4c82-46ca-bd07-70e122baa7e1",
   "metadata": {},
   "source": [
    "To integrate **Apache Tika** for metadata extraction into the search engine, we need to parse and extract metadata from each file uploaded to IPFS using Tika. This metadata will be indexed alongside the existing file information (like CID and size) and then made searchable.\n",
    "\n",
    "### Steps to implement Tika-based metadata extraction:\n",
    "1. **Install the `tika` library**:\n",
    "   Apache Tika provides a Python wrapper (`tika` library) to access its file metadata extraction features. Install it using:\n",
    "   ```bash\n",
    "   pip install tika\n",
    "   ```\n",
    "\n",
    "2. **Modify the Python script**:\n",
    "   We will update the `index_ipfs_content` function to:\n",
    "   - Download the file from IPFS.\n",
    "   - Use Tika to extract the file's metadata.\n",
    "   - Index both the CID and the metadata (like author, title, content type) in Whoosh.\n",
    "\n",
    "Here's the updated code:\n",
    "\n",
    "```python\n",
    "import ipfshttpclient\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID, NUMERIC\n",
    "from whoosh.qparser import QueryParser\n",
    "import os\n",
    "from tika import parser  # Apache Tika for metadata extraction\n",
    "\n",
    "# Connect to local IPFS\n",
    "client = ipfshttpclient.connect()\n",
    "\n",
    "# Define schema for indexing (now includes metadata fields from Tika)\n",
    "schema = Schema(\n",
    "    cid=ID(stored=True),                 # The IPFS CID\n",
    "    name=TEXT(stored=True),              # Filename\n",
    "    size=NUMERIC(stored=True),           # File size\n",
    "    filetype=TEXT(stored=True),          # File type (MIME type)\n",
    "    title=TEXT(stored=True),             # Extracted title (from Tika metadata)\n",
    "    author=TEXT(stored=True),            # Extracted author (from Tika metadata)\n",
    "    keywords=TEXT(stored=True),          # Extracted keywords (from Tika metadata)\n",
    "    full_text=TEXT(stored=False),        # Extracted full text of document (if applicable)\n",
    ")\n",
    "\n",
    "# Create the index directory\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "\n",
    "# Create index in the directory\n",
    "ix = create_in(\"indexdir\", schema)\n",
    "\n",
    "# Function to download file from IPFS and save locally\n",
    "def download_file_from_ipfs(cid, filename):\n",
    "    file_path = f\"./{filename}\"\n",
    "    try:\n",
    "        # Fetch the file from IPFS and save it locally\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            client.get(cid, file=file_path)\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download file with CID {cid}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract metadata using Apache Tika\n",
    "def extract_metadata(file_path):\n",
    "    try:\n",
    "        parsed = parser.from_file(file_path)\n",
    "        metadata = parsed.get(\"metadata\", {})\n",
    "        content = parsed.get(\"content\", \"\").strip()\n",
    "\n",
    "        # Extract relevant metadata fields\n",
    "        title = metadata.get(\"title\", \"Unknown\")\n",
    "        author = metadata.get(\"Author\", \"Unknown\")\n",
    "        keywords = metadata.get(\"Keywords\", \"\")\n",
    "        \n",
    "        return title, author, keywords, content\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract metadata for file {file_path}: {e}\")\n",
    "        return \"Unknown\", \"Unknown\", \"\", \"\"\n",
    "\n",
    "# Function to index IPFS content along with Tika metadata\n",
    "def index_ipfs_content(cid, filename):\n",
    "    try:\n",
    "        # Step 1: Download file from IPFS\n",
    "        file_path = download_file_from_ipfs(cid, filename)\n",
    "        if not file_path:\n",
    "            return\n",
    "        \n",
    "        # Step 2: Extract metadata using Tika\n",
    "        title, author, keywords, full_text = extract_metadata(file_path)\n",
    "        \n",
    "        # Step 3: Fetch file stats from IPFS\n",
    "        stats = client.object.stat(cid)\n",
    "        file_size = stats['CumulativeSize']\n",
    "\n",
    "        # Step 4: Get file type (basic MIME type)\n",
    "        filetype = filename.split(\".\")[-1] if \".\" in filename else \"unknown\"\n",
    "\n",
    "        # Step 5: Index the content\n",
    "        writer = ix.writer()\n",
    "        writer.add_document(\n",
    "            cid=cid,\n",
    "            name=filename,\n",
    "            size=file_size,\n",
    "            filetype=filetype,\n",
    "            title=title,\n",
    "            author=author,\n",
    "            keywords=keywords,\n",
    "            full_text=full_text,  # Not stored, just used for searching\n",
    "        )\n",
    "        writer.commit()\n",
    "        print(f\"Indexed {filename} with CID: {cid}, Title: {title}, Author: {author}\")\n",
    "\n",
    "        # Optionally: Clean up local file\n",
    "        os.remove(file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to index CID {cid}: {e}\")\n",
    "\n",
    "# Search IPFS index based on keyword or metadata\n",
    "def search_ipfs(keyword):\n",
    "    with ix.searcher() as searcher:\n",
    "        query = QueryParser(\"full_text\", ix.schema).parse(keyword)\n",
    "        results = searcher.search(query)\n",
    "        if results:\n",
    "            for result in results:\n",
    "                print(f\"CID: {result['cid']}, Name: {result['name']}, Title: {result['title']}, Author: {result['author']}, Size: {result['size']} bytes\")\n",
    "        else:\n",
    "            print(f\"No results found for '{keyword}'\")\n",
    "\n",
    "# Example usage: Index some files on your local IPFS node\n",
    "index_ipfs_content(\"QmXj...\", \"example.txt\")  # Replace with actual CID and filename\n",
    "index_ipfs_content(\"QmYk...\", \"document.pdf\")  # Replace with actual CID and filename\n",
    "\n",
    "# Example search\n",
    "search_ipfs(\"example\")\n",
    "```\n",
    "\n",
    "### Breakdown of the changes:\n",
    "\n",
    "1. **Apache Tika Metadata Extraction**:\n",
    "   - The function `extract_metadata(file_path)` uses Tika to extract metadata (like title, author, keywords) and the full text (if applicable) from the file.\n",
    "\n",
    "2. **Downloading Files from IPFS**:\n",
    "   - The `download_file_from_ipfs` function downloads files from IPFS using the CID and saves them locally for Tika to process.\n",
    "\n",
    "3. **Schema Updates**:\n",
    "   - Added `title`, `author`, `keywords`, and `full_text` fields to the search index schema. This allows us to index and search by these additional metadata fields.\n",
    "\n",
    "4. **Indexing Content**:\n",
    "   - The `index_ipfs_content` function now downloads the file from IPFS, extracts metadata using Tika, and indexes the file and its metadata in Whoosh.\n",
    "\n",
    "5. **Search Enhancements**:\n",
    "   - The `search_ipfs` function searches not only by filenames but also by the full text of the document and metadata extracted by Tika.\n",
    "\n",
    "### Running the Script:\n",
    "1. Replace `\"QmXj...\"` and `\"QmYk...\"` with actual CIDs of files uploaded to your local IPFS server.\n",
    "2. Run the script to download, index, and search files with their metadata and content using Apache Tika.\n",
    "\n",
    "This approach extracts rich metadata and makes it searchable, improving the ability to find relevant content on your IPFS server."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
