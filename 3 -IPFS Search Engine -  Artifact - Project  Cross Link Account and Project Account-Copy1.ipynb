{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759b5251-2d99-444d-890b-0272c036750d",
   "metadata": {},
   "source": [
    "**IMPORTANT** \n",
    "\n",
    "- For requirements and initial setup go to https://github.com/OliveiraEdu/OpenScience/Readme.md;\n",
    "- To execute the notebook run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11965914-6a6a-43b4-a793-01a3eda28617",
   "metadata": {},
   "source": [
    "# Part - 1 Cross Linking Account and Project accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab571c6-459e-4d8c-a14f-8ea40c12fdbe",
   "metadata": {},
   "source": [
    "## Activities\n",
    "\n",
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;\n",
    "\n",
    "2 - User and Project id extraction from CSVs;\n",
    "\n",
    "3 - Queries Iroha 1 for User and Project accounts and checks the present values;\n",
    "\n",
    "4 - Sets details for both User and Project accounts in Iroha 1 providing a logical link between them for later references;\n",
    "\n",
    "5 - Queries the User and Project accounts again and checks the proper setting of details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79226aee-cfb3-4a03-b85a-18468e43a9aa",
   "metadata": {},
   "source": [
    "## Sequence Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aad64b-9986-49bf-bf43-1039243c4dd3",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "\n",
    "    Note over Platform, Blockchain: Deploy smart contract for details setting\n",
    "    Platform->>Blockchain: Deploy Smart Contract\n",
    "    Blockchain->>Platform: Smart Contract Deployed Successfully\n",
    "\n",
    "    Note over Platform, Blockchain: Extract user and project IDs from CSVs\n",
    "    Platform->>self: User ID Extraction\n",
    "    Platform->>self: Project ID Extraction\n",
    "\n",
    "    Note over Platform, Blockchain: Queries the blockchain for User and Project accounts details\n",
    "    Platform->>Blockchain: Get User Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "    Platform->>Blockchain: Get Project Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "    \n",
    "    Note over Platform, Blockchain: Set details for User and Project accounts\n",
    "    Platform->>Blockchain: Set User Details in Blockchain\n",
    "    Blockchain->>Platform: User Details Set Successfully\n",
    "    Platform->>Blockchain: Set Project Details in Blockchain\n",
    "    Blockchain->>Platform: Project Details Set Successfully\n",
    "    \n",
    "    Note over Platform, Blockchain: Queries the blockchain to confirm proper setting of details\n",
    "    Platform->>Blockchain: Get User Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "    Platform->>Blockchain: Get Project Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a043d51-4a22-4186-975e-7e3e8a4b54ef",
   "metadata": {},
   "source": [
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a1c5a2-75c3-482e-999c-70eb25226078",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntering \"create_contract\"\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "\tLeaving \"create_contract\"\n",
      "\tEntering \"get_engine_receipts_result\"\n",
      "\n",
      "\tLeaving \"get_engine_receipts_result\"\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from Crypto.Hash import keccak\n",
    "import os\n",
    "import binascii\n",
    "from iroha import IrohaCrypto\n",
    "from iroha import Iroha, IrohaGrpc\n",
    "from iroha.ed25519 import H\n",
    "import integration_helpers\n",
    "from iroha.primitive_pb2 import can_set_my_account_detail\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Python 3 or a more recent version is required.\")\n",
    "\n",
    "# Load configuration from config.json file\n",
    "config_path = \"config.json\"  # Update this path as needed\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IROHA_HOST_ADDR = config[\"IROHA_HOST_ADDR\"]\n",
    "IROHA_PORT = config[\"IROHA_PORT\"]\n",
    "ADMIN_ACCOUNT_ID = config[\"ADMIN_ACCOUNT_ID\"]\n",
    "ADMIN_PRIVATE_KEY = config[\"ADMIN_PRIVATE_KEY\"]\n",
    "\n",
    "iroha = Iroha(ADMIN_ACCOUNT_ID)\n",
    "net = IrohaGrpc(\"{}:{}\".format(IROHA_HOST_ADDR, IROHA_PORT))\n",
    "\n",
    "\n",
    "@integration_helpers.trace\n",
    "def create_contract():\n",
    "    bytecode = \"608060405234801561001057600080fd5b5073a6abc17819738299b3b2c1ce46d55c74f04e290c6000806101000a81548173ffffffffffffffffffffffffffffffffffffffff021916908373ffffffffffffffffffffffffffffffffffffffff160217905550610b4c806100746000396000f3fe608060405234801561001057600080fd5b506004361061004c5760003560e01c80635bdb3a41146100515780637949a1b31461006f578063b7d66df71461009f578063d4e804ab146100cf575b600080fd5b6100596100ed565b6040516100669190610879565b60405180910390f35b61008960048036038101906100849190610627565b61024c565b6040516100969190610879565b60405180910390f35b6100b960048036038101906100b49190610693565b6103bb565b6040516100c69190610879565b60405180910390f35b6100d761059b565b6040516100e4919061085e565b60405180910390f35b606060006040516024016040516020818303038152906040527f5bdb3a41000000000000000000000000000000000000000000000000000000007bffffffffffffffffffffffffffffffffffffffffffffffffffffffff19166020820180517bffffffffffffffffffffffffffffffffffffffffffffffffffffffff8381831617835250505050905060008060008054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16836040516101be9190610830565b600060405180830381855af49150503d80600081146101f9576040519150601f19603f3d011682016040523d82523d6000602084013e6101fe565b606091505b509150915081610243576040517f08c379a000000000000000000000000000000000000000000000000000000000815260040161023a9061091e565b60405180910390fd5b80935050505090565b60606000838360405160240161026392919061089b565b6040516020818303038152906040527f7949a1b3000000000000000000000000000000000000000000000000000000007bffffffffffffffffffffffffffffffffffffffffffffffffffffffff19166020820180517bffffffffffffffffffffffffffffffffffffffffffffffffffffffff8381831617835250505050905060008060008054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff168360405161032a9190610830565b600060405180830381855af49150503d8060008114610365576040519150601f19603f3d011682016040523d82523d6000602084013e61036a565b606091505b5091509150816103af576040517f08c379a00000000000000000000000000000000000000000000000000000000081526004016103a69061091e565b60405180910390fd5b80935050505092915050565b606060008484846040516024016103d4939291906108d2565b6040516020818303038152906040527fb7d66df7000000000000000000000000000000000000000000000000000000007bffffffffffffffffffffffffffffffffffffffffffffffffffffffff19166020820180517bffffffffffffffffffffffffffffffffffffffffffffffffffffffff8381831617835250505050905060008060008054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff168360405161049b9190610830565b600060405180830381855af49150503d80600081146104d6576040519150601f19603f3d011682016040523d82523d6000602084013e6104db565b606091505b509150915081610520576040517f08c379a00000000000000000000000000000000000000000000000000000000081526004016105179061091e565b60405180910390fd5b8460405161052e9190610847565b6040518091039020866040516105449190610847565b60405180910390208860405161055a9190610847565b60405180910390207f5e1b38cd47cf21b75d5051af29fa321eedd94877db5ac62067a076770eddc9d060405160405180910390a48093505050509392505050565b60008054906101000a900473ffffffffffffffffffffffffffffffffffffffff1681565b60006105d26105cd84610963565b61093e565b9050828152602081018484840111156105ea57600080fd5b6105f5848285610a14565b509392505050565b600082601f83011261060e57600080fd5b813561061e8482602086016105bf565b91505092915050565b6000806040838503121561063a57600080fd5b600083013567ffffffffffffffff81111561065457600080fd5b610660858286016105fd565b925050602083013567ffffffffffffffff81111561067d57600080fd5b610689858286016105fd565b9150509250929050565b6000806000606084860312156106a857600080fd5b600084013567ffffffffffffffff8111156106c257600080fd5b6106ce868287016105fd565b935050602084013567ffffffffffffffff8111156106eb57600080fd5b6106f7868287016105fd565b925050604084013567ffffffffffffffff81111561071457600080fd5b610720868287016105fd565b9150509250925092565b610733816109e2565b82525050565b600061074482610994565b61074e81856109aa565b935061075e818560208601610a23565b61076781610ab6565b840191505092915050565b600061077d82610994565b61078781856109bb565b9350610797818560208601610a23565b80840191505092915050565b60006107ae8261099f565b6107b881856109c6565b93506107c8818560208601610a23565b6107d181610ab6565b840191505092915050565b60006107e78261099f565b6107f181856109d7565b9350610801818560208601610a23565b80840191505092915050565b600061081a6027836109c6565b915061082582610ac7565b604082019050919050565b600061083c8284610772565b915081905092915050565b600061085382846107dc565b915081905092915050565b6000602082019050610873600083018461072a565b92915050565b600060208201905081810360008301526108938184610739565b905092915050565b600060408201905081810360008301526108b581856107a3565b905081810360208301526108c981846107a3565b90509392505050565b600060608201905081810360008301526108ec81866107a3565b9050818103602083015261090081856107a3565b9050818103604083015261091481846107a3565b9050949350505050565b600060208201905081810360008301526109378161080d565b9050919050565b6000610948610959565b90506109548282610a56565b919050565b6000604051905090565b600067ffffffffffffffff82111561097e5761097d610a87565b5b61098782610ab6565b9050602081019050919050565b600081519050919050565b600081519050919050565b600082825260208201905092915050565b600081905092915050565b600082825260208201905092915050565b600081905092915050565b60006109ed826109f4565b9050919050565b600073ffffffffffffffffffffffffffffffffffffffff82169050919050565b82818337600083830152505050565b60005b83811015610a41578082015181840152602081019050610a26565b83811115610a50576000848401525b50505050565b610a5f82610ab6565b810181811067ffffffffffffffff82111715610a7e57610a7d610a87565b5b80604052505050565b7f4e487b7100000000000000000000000000000000000000000000000000000000600052604160045260246000fd5b6000601f19601f8301169050919050565b7f4572726f722063616c6c696e67207365727669636520636f6e7472616374206660008201527f756e6374696f6e0000000000000000000000000000000000000000000000000060208201525056fea26469706673582212206ad40afbd4cc9c87ae154542d003c9538e4b89473a13cadd3cbf618ea181206864736f6c63430008040033\"\n",
    "    \"\"\"Bytecode was generated using remix editor  https://remix.ethereum.org/ from file detail.sol. \"\"\"\n",
    "    tx = iroha.transaction(\n",
    "        [iroha.command(\"CallEngine\", caller=ADMIN_ACCOUNT_ID, input=bytecode)]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    net.send_tx(tx)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    return hex_hash\n",
    "\n",
    "hash = create_contract()\n",
    "integration_helpers.get_engine_receipts_result(hash)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea1051-cb1c-4c29-97e5-38ba90248081",
   "metadata": {},
   "source": [
    "2 - Data extraction from CSVs.\n",
    "\n",
    "Extracts account ids from `datasets/accounts.csv` and `datasets/projects.csv`.\n",
    "\n",
    "Must update `csv_index` with a line number related to an existing row in `datasets/accounts.csv` and `datasets/projects.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8384a9-49db-44a2-b222-f3657a3bc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for rows in both user account and project account CSVs.\n",
    "csv_index = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "126df4cd-d358-43cc-997f-e17453a5b8dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntering \"get_engine_receipts_address\"\n",
      "\tLeaving \"get_engine_receipts_address\"\n",
      "5\n",
      "{'account_id': 'admiring_nightingale@test'}\n",
      "admiring_nightingale@test\n",
      "{'account_id': '54202@test'}\n",
      "54202@test\n"
     ]
    }
   ],
   "source": [
    "@integration_helpers.trace\n",
    "def set_account_detail(address, account, variable_1, variable_2):\n",
    "    params = integration_helpers.get_first_four_bytes_of_keccak(\n",
    "        b\"setAccountDetail(string,string,string)\"\n",
    "    )\n",
    "    no_of_param = 3\n",
    "    for x in range(no_of_param):\n",
    "        params = params + integration_helpers.left_padded_address_of_param(\n",
    "            x, no_of_param\n",
    "        )\n",
    "    params = params + integration_helpers.argument_encoding(\n",
    "        entity_id\n",
    "    )  # source user or project account id\n",
    "    params = params + integration_helpers.argument_encoding(variable_1)  # key\n",
    "    params = params + integration_helpers.argument_encoding(variable_2)  #  value\n",
    "    tx = iroha.transaction(\n",
    "        [\n",
    "            iroha.command(\n",
    "                \"CallEngine\", caller=ADMIN_ACCOUNT_ID, callee=address, input=params\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    response = net.send_tx(tx)\n",
    "    print(response)\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    return hex_hash\n",
    "\n",
    "\n",
    "@integration_helpers.trace\n",
    "def get_account_details():\n",
    "    params = integration_helpers.get_first_four_bytes_of_keccak(b\"getAccountDetail()\")\n",
    "    no_of_param = 0\n",
    "    tx = iroha.transaction(\n",
    "        [\n",
    "            iroha.command(\n",
    "                \"CallEngine\", caller=ADMIN_ACCOUNT_ID, callee=address, input=params\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "    response = net.send_tx(tx)\n",
    "    for status in net.tx_status_stream(tx):\n",
    "        print(status)\n",
    "    hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "    return hex_hash\n",
    "\n",
    "\n",
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "\n",
    "\n",
    "\n",
    "# Reads user account attributes from a datasets/accounts.csv\n",
    "def read_user_accounts_from_csv(file_path):\n",
    "    user_accounts = []\n",
    "    with open(file_path, mode='r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            user_accounts.append({\n",
    "                'account_id': row['account_id']\n",
    "            })\n",
    "    return user_accounts\n",
    "\n",
    "\n",
    "# Path to the CSV file\n",
    "user_accounts_csv_file_path = 'datasets/accounts.csv'\n",
    "\n",
    "# Read accounts from CSV\n",
    "user_accounts = read_user_accounts_from_csv(user_accounts_csv_file_path)\n",
    "\n",
    "# Use the [n] row from the CSV for the example\n",
    "user_account = user_accounts[csv_index]\n",
    "print(csv_index)\n",
    "print(user_account)\n",
    "print(user_account['account_id'])\n",
    "\n",
    " \n",
    "\n",
    "# Reads project account attributes from csv datasets/projects.csv\n",
    "def read_project_accounts_from_csv(file_path):\n",
    "    project_accounts = []\n",
    "    with open(file_path, mode='r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            project_accounts.append({\n",
    "                'account_id': row['project_id']\n",
    "            })\n",
    "    return project_accounts\n",
    "\n",
    "# Path to the CSV file\n",
    "project_accounts_csv_file_path = 'datasets/projects.csv'\n",
    "\n",
    "# Read accounts from CSV\n",
    "project_accounts = read_project_accounts_from_csv(project_accounts_csv_file_path)\n",
    "\n",
    "# Use the [n] row from the CSV for the example\n",
    "project_account = project_accounts[csv_index]\n",
    "print(project_account)\n",
    "print(project_account['account_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562857c-d86d-42cf-a24b-23a5c3f5cb4e",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for User and Project accounts and checks the present values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "931dbcd1-80b5-43a4-a855-4ddba9083450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payload {\n",
      "  meta {\n",
      "    created_time: 1728267867634\n",
      "    creator_account_id: \"admin@test\"\n",
      "    query_counter: 1\n",
      "  }\n",
      "  get_account_detail {\n",
      "    account_id: \"admiring_nightingale@test\"\n",
      "  }\n",
      "}\n",
      "\n",
      "error_response {\n",
      "  reason: NO_ACCOUNT_DETAIL\n",
      "  message: \"no details in account with such id: admiring_nightingale@test\"\n",
      "}\n",
      "query_hash: \"a94a17697ef87e10d0d03146cc0cb8a98c9ac1c52cb86bdc1387042e10fbdd00\"\n",
      "\n",
      "User Account id = {'account_id': 'admiring_nightingale@test'}, details = \n",
      "--------------------\n",
      "error_response {\n",
      "  reason: NO_ACCOUNT_DETAIL\n",
      "  message: \"no details in account with such id: 54202@test\"\n",
      "}\n",
      "query_hash: \"097d4f8256bdad8b20b62eae2d7c7fefbc28d53fa39955b47a3ad9a08a46390e\"\n",
      "\n",
      "Project Account id = {'account_id': '54202@test'}, details = \n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=user_account['account_id'])\n",
    "print(query)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "print(response)\n",
    "data = response.account_detail_response\n",
    "print(f'User Account id = {user_account}, details = {data.detail}')\n",
    "\n",
    "print (\"-\" * 20)\n",
    "\n",
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=project_account['account_id'])\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "print(response)\n",
    "data = response.account_detail_response\n",
    "print(f'Project Account id = {project_account}, details = {data.detail}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e068d0-2247-4fd3-827f-4144b66965e1",
   "metadata": {},
   "source": [
    "4 - Sets details for both User and Project accounts providing a logical link between them for later references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f6343e-7a08-4e24-90fe-7aaf22bdc60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiring_nightingale@test\n",
      "\tEntering \"set_account_detail\"\n",
      "None\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_FAILED', 2, 3)\n",
      "('REJECTED', 4, 0)\n",
      "\tLeaving \"set_account_detail\"\n",
      "54202@test\n",
      "\tEntering \"set_account_detail\"\n",
      "None\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_FAILED', 2, 3)\n",
      "('REJECTED', 4, 0)\n",
      "\tLeaving \"set_account_detail\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "entity_id = user_account['account_id']\n",
    "print(entity_id)\n",
    "hash = set_account_detail(address, entity_id, \"project\", project_account['account_id'])\n",
    "\n",
    "# print (\"-\" * 20)\n",
    "\n",
    "entity_id = project_account['account_id']\n",
    "print(entity_id)\n",
    "hash = set_account_detail(address, entity_id, \"project_owner\", user_account['account_id'])                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f46f4-e077-4bfa-9ef9-36a59d5c836d",
   "metadata": {},
   "source": [
    "5 - Queries the User and Project accounts again and checks the proper setting of details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df5c4ea-e3a3-41e8-9ba0-cc7ec832bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Account id = {'account_id': 'admiring_nightingale@test'}, details = \n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=user_account['account_id'])\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "user_account_data = response.account_detail_response\n",
    "print(f'User Account id = {user_account}, details = {user_account_data.detail}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad740c4-f176-44db-9036-7d973c83e76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Project Account id = {'account_id': '54202@test'}, details = \n"
     ]
    }
   ],
   "source": [
    "print (\"-\" * 20)\n",
    "\n",
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=project_account['account_id'])\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "data = response.account_detail_response\n",
    "print(f'Project Account id = {project_account}, details = {data.detail}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f660b-56d6-4ea0-bd2b-e3bb54ecd05b",
   "metadata": {},
   "source": [
    "# Part2 - Querying Project Metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986de21a-9ddc-4aea-b63d-47a6a0323871",
   "metadata": {},
   "source": [
    "## Activities\n",
    "\n",
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0445f-998d-4470-9dfa-252caf810921",
   "metadata": {},
   "source": [
    "## Sequence Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e812f7b-8439-4e65-883c-de57b8e81097",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "    participant FrontEnd as \"Front End\"\n",
    "\n",
    "    Note over Platform, Blockchain: Queries the user account and get the project id \n",
    "    Platform->>Blockchain: Query User Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "        \n",
    "    Note over Platform, Blockchain: Queries the Project Account details and get project metadata CID \n",
    "    Platform->>Blockchain: Query Project Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "\n",
    "    Note over Platform, IPFS: Process and displays the metadata CID \n",
    "    Platform->>IPFS: Sends the project metadata CID\n",
    "    IPFS->>Platform: Sends back the project metadata JSON\n",
    "    Platform->>FrontEnd: Displays the project metadata JSON   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f33098-43df-47f3-8708-f3212dec1c0f",
   "metadata": {},
   "source": [
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374843b3-6862-4a93-b298-1bdd0320c4c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipfs_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Process the account details response\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m account_details_dict \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_account_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetail\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert the string to a JSON object\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ic(account_details_dict)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Get the value of the dictionary\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from ipfs_functions import *\n",
    "\n",
    "# Process the account details response\n",
    "account_details_dict = json.loads(user_account_data.detail)  # Convert the string to a JSON object\n",
    "ic(account_details_dict)\n",
    "\n",
    "# Get the value of the dictionary\n",
    "user_account_metadata = account_details_dict['admin@test']\n",
    "ic(user_account_metadata['project'])\n",
    "\n",
    "\n",
    "for key, value in user_account_metadata.items():\n",
    "    if 'project' in key:  # Check if this is a file CID\n",
    "            \n",
    "        ic(key)\n",
    "        ic(value)\n",
    "        #Query - GetAccountDetail\n",
    "        query = iroha.query('GetAccountDetail',account_id = value)\n",
    "        # ic(query)\n",
    "        IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "        response = net.send_query(query)\n",
    "        # ic(response)\n",
    "        result = response.account_detail_response\n",
    "        # ic(result)\n",
    "        # ic(result.detail)        \n",
    "        # print(f'Project Account id = {value}, details = {result.detail}')\n",
    "        # details = {result.detail}\n",
    "        # ic(details)\n",
    "        # Process the account details response\n",
    "        details_dict = json.loads(result.detail)  # Convert the string to a JSON object\n",
    "        # ic(details_dict)\n",
    "\n",
    "        # # Get the value of the dictionary (the actual file metadata)\n",
    "        details_metadata = details_dict['admin@test']\n",
    "        # ic(details_metadata)\n",
    "        project_metadata_cid = details_metadata['project_metadata_cid']\n",
    "        # ic(project_metadata_cid)\n",
    "        project_metadata_json = download_json_from_ipfs(project_metadata_cid)\n",
    "        ic(project_metadata_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31163ee6-8c5a-4cd3-8951-9190665abd5a",
   "metadata": {},
   "source": [
    "# Part 3 - File Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d265a-50e1-423d-9e53-26226afe7756",
   "metadata": {},
   "source": [
    "7 -  Sends every file in the `upload` directory to IPFS, extracts theirs respective metadata with Apache Tika and sends it to IPFS, get the CIDs back and store in Iroha as details of the project account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419c69e-9fbb-474b-ab9b-4ffdc38403ee",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "\n",
    "    Note over Platform, IPFS: Upload Operations \n",
    "    Platform->>IPFS: Upload local files to IPFS\n",
    "    IPFS->>Platform: Send back file CIDs\n",
    "    Platform->>Blockchain: Set CID as Project Account Details\n",
    "    Blockchain->>Platform:Details set successfully\n",
    "         \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27b41f0-2cab-43c6-8bee-39381d57f546",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "ConnectionError: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /api/v0/version?stream-channels=true (Caused by NewConnectionError('<ipfshttpclient.requests_wrapper.HTTPConnection object at 0x7df7deb27070>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/requests_wrapper.py:107\u001b[0m, in \u001b[0;36mConnectionOverrideMixin._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \t\tdns_host \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39munquote(dns_host)\n\u001b[0;32m--> 107\u001b[0m \tconn \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/requests_wrapper.py:75\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options, family)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/requests_wrapper.py:66\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options, family)\u001b[0m\n\u001b[1;32m     65\u001b[0m \tsock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 66\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/connection.py:441\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/http/client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/http/client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/http/client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/connection.py:279\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/requests_wrapper.py:114\u001b[0m, in \u001b[0;36mConnectionOverrideMixin._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 114\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m urllib3\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mNewConnectionError(\n\u001b[1;32m    115\u001b[0m \t\t\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <ipfshttpclient.requests_wrapper.HTTPConnection object at 0x7df7deb27070>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /api/v0/version?stream-channels=true (Caused by NewConnectionError('<ipfshttpclient.requests_wrapper.HTTPConnection object at 0x7df7deb27070>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/http_requests.py:165\u001b[0m, in \u001b[0;36mClientSync._request\u001b[0;34m(self, method, path, params, auth, data, headers, timeout, chunk_size)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m \tres \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmap_args_to_requests\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m\t\t\t\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\t\t\t\u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m\t\t\t\u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m\t\t\t\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_timeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_proxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \tclosables\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, res)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/requests_wrapper.py:230\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \turl \u001b[38;5;241m=\u001b[39m url\u001b[38;5;241m.\u001b[39mgeturl()\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /api/v0/version?stream-channels=true (Caused by NewConnectionError('<ipfshttpclient.requests_wrapper.HTTPConnection object at 0x7df7deb27070>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtika\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parser  \u001b[38;5;66;03m# Apache Tika for metadata extraction\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Connect to local IPFS\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mipfshttpclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Define schema for indexing (now includes metadata fields from Tika)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m schema \u001b[38;5;241m=\u001b[39m Schema(\n\u001b[1;32m     18\u001b[0m     cid\u001b[38;5;241m=\u001b[39mID(stored\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),                 \u001b[38;5;66;03m# The IPFS CID\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     name\u001b[38;5;241m=\u001b[39mTEXT(stored\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),              \u001b[38;5;66;03m# Filename\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     full_text\u001b[38;5;241m=\u001b[39mTEXT(stored\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),        \u001b[38;5;66;03m# Extracted full text of document (if applicable)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/client/__init__.py:119\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(addr, base, chunk_size, offline, session, auth, cookies, headers, timeout, username, password)\u001b[0m\n\u001b[1;32m    111\u001b[0m client \u001b[38;5;241m=\u001b[39m Client(\n\u001b[1;32m    112\u001b[0m \taddr, base,\n\u001b[1;32m    113\u001b[0m \tchunk_size\u001b[38;5;241m=\u001b[39mchunk_size, offline\u001b[38;5;241m=\u001b[39moffline, session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m    114\u001b[0m \tauth\u001b[38;5;241m=\u001b[39mauth, cookies\u001b[38;5;241m=\u001b[39mcookies, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    115\u001b[0m \tusername\u001b[38;5;241m=\u001b[39musername, password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Query version number from daemon and validate it\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m assert_version(\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_workarounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/client/__init__.py:228\u001b[0m, in \u001b[0;36mClient.apply_workarounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_workarounds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m\"\"\"Query version information of the referenced daemon and enable any\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\t   workarounds known for the corresponding version\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m\t\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m\t\t\tThe version information returned by the daemon\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\t\"\"\"\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \tversion_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \tversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, version_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    232\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workarounds\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/client/base.py:245\u001b[0m, in \u001b[0;36mreturns_single_item.<locals>.wrapper1.<locals>.wrapper2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper2\u001b[39m(\u001b[38;5;241m*\u001b[39margs: ty\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: ty\u001b[38;5;241m.\u001b[39mAny) \\\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ty\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28;01mNone\u001b[39;00m, R, ResponseWrapIterator[T, R]]:\n\u001b[0;32m--> 245\u001b[0m \tresult \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    247\u001b[0m \t\t\u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalled IPFS HTTP-Client function should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m \t\t                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly ever return one item\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/client/miscellaneous.py:204\u001b[0m, in \u001b[0;36mBase.version\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@base\u001b[39m\u001b[38;5;241m.\u001b[39mreturns_single_item(base\u001b[38;5;241m.\u001b[39mResponseBase)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: base\u001b[38;5;241m.\u001b[39mCommonArgs):\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the software versions of the currently connected node\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\t\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m\t.. code-block:: python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m\t\t\tDaemon and system version information\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\t\"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/version\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/http_common.py:613\u001b[0m, in \u001b[0;36mClientSyncBase.request\u001b[0;34m(self, path, args, opts, decoder, stream, offline, return_result, auth, cookies, data, headers, timeout)\u001b[0m\n\u001b[1;32m    609\u001b[0m \tmethod \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    611\u001b[0m parser \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39mget_encoding(decoder)\n\u001b[0;32m--> 613\u001b[0m closables, res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_args_to_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ty.Tuple[ty.List[Closable], ty.Generator[bytes, ty.Any, ty.Any]]\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_result:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipfshttpclient/http_requests.py:190\u001b[0m, in \u001b[0;36mClientSync._request\u001b[0;34m(self, method, path, params, auth, data, headers, timeout, chunk_size)\u001b[0m\n\u001b[1;32m    187\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m], urllib3\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mProtocolError):\n\u001b[1;32m    188\u001b[0m \t\t\u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mProtocolError(error\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01margs\u001b[39;00m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 190\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mConnectionError(error) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Looks like the following error doesn't happen anymore with modern requests?\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPException \u001b[38;5;28;01mas\u001b[39;00m error:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ConnectionError: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /api/v0/version?stream-channels=true (Caused by NewConnectionError('<ipfshttpclient.requests_wrapper.HTTPConnection object at 0x7df7deb27070>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "from tika import parser\n",
    "from ipfs_functions import *\n",
    "import icecream as ic\n",
    "\n",
    "\n",
    "import ipfshttpclient\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID, NUMERIC\n",
    "from whoosh.qparser import QueryParser\n",
    "import os\n",
    "from tika import parser  # Apache Tika for metadata extraction\n",
    "\n",
    "# Connect to local IPFS\n",
    "client = ipfshttpclient.connect()\n",
    "\n",
    "# Define schema for indexing (now includes metadata fields from Tika)\n",
    "schema = Schema(\n",
    "    cid=ID(stored=True),                 # The IPFS CID\n",
    "    name=TEXT(stored=True),              # Filename\n",
    "    size=NUMERIC(stored=True),           # File size\n",
    "    filetype=TEXT(stored=True),          # File type (MIME type)\n",
    "    title=TEXT(stored=True),             # Extracted title (from Tika metadata)\n",
    "    author=TEXT(stored=True),            # Extracted author (from Tika metadata)\n",
    "    keywords=TEXT(stored=True),          # Extracted keywords (from Tika metadata)\n",
    "    full_text=TEXT(stored=False),        # Extracted full text of document (if applicable)\n",
    ")\n",
    "\n",
    "# Create the index directory\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "\n",
    "# Create index in the directory\n",
    "ix = create_in(\"indexdir\", schema)\n",
    "\n",
    "\n",
    "\n",
    "def parse_documents_in_directory(directory_path):\n",
    "    \n",
    "    index = 1\n",
    "\n",
    "    print(user_account['account_id'])\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "\n",
    "        # Block 1\n",
    "        # Skip hidden files by checking if it starts with a dot\n",
    "        if not os.path.basename(filename).startswith('.'):\n",
    "            \n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(file_path)\n",
    "            file_cid = upload_file_to_ipfs(file_path)\n",
    "               \n",
    "            variable_1 = f\"file_{index}_CID\"\n",
    "            print(variable_1)\n",
    "            \n",
    "            variable_2 = file_cid\n",
    "            print (variable_2)\n",
    "\n",
    "            hash = set_account_detail(address, user_account, variable_1, variable_2)\n",
    "            \n",
    "        # Block 2\n",
    "        # Check if it's a file and not a directory\n",
    "        # if not os.path.basename(filename).startswith('.'):\n",
    "            try:\n",
    "                parsed_document = parser.from_file(file_path)\n",
    "                         \n",
    "                \n",
    "                # Check if parsing was successful\n",
    "                if 'status' in parsed_document and parsed_document['status'] == 200:\n",
    "                    metadata = parsed_document.get('metadata', {})\n",
    "                    content = parsed_document.get(\"content\", \"\").strip()\n",
    "\n",
    "                    # Extract relevant metadata fields\n",
    "                    title = metadata.get(\"title\", \"Unknown\")\n",
    "                    author = metadata.get(\"Author\", \"Unknown\")\n",
    "                    keywords = metadata.get(\"Keywords\", \"\")\n",
    "\n",
    "                    \n",
    "                    # print(metadata)\n",
    "                    metadata_cid = upload_json_to_ipfs(metadata)\n",
    "                    \n",
    "                    variable_3 = f\"file_{index}_metadata_CID\"\n",
    "                    print (variable_3)\n",
    "\n",
    "                    variable_4 = metadata_cid\n",
    "                    print (variable_4)\n",
    "\n",
    "                    hash = set_account_detail(address, user_account, variable_3, variable_4)\n",
    "                    \n",
    "     \n",
    "                    \n",
    "                else:\n",
    "                    print(f\"Parsing failed for '{filename}' with status: {parsed_document.get('status')}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred with file '{filename}': {e}\")\n",
    "                return \"Unknown\", \"Unknown\", \"\", \"\"\n",
    "            \n",
    "            print (\"-\" * 40)\n",
    "            index += 1\n",
    "\n",
    "# Example usage\n",
    "parse_documents_in_directory(\"upload\")\n",
    "\n",
    "\n",
    "#----\n",
    "\n",
    "# # Function to download file from IPFS and save locally\n",
    "# def download_file_from_ipfs(cid, filename):\n",
    "#     file_path = f\"./{filename}\"\n",
    "#     try:\n",
    "#         # Fetch the file from IPFS and save it locally\n",
    "#         with open(file_path, \"wb\") as file:\n",
    "#             client.get(cid, file=file_path)\n",
    "#         return file_path\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to download file with CID {cid}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Function to extract metadata using Apache Tika\n",
    "# def extract_metadata(file_path):\n",
    "#     try:\n",
    "#         parsed = parser.from_file(file_path)\n",
    "#         metadata = parsed.get(\"metadata\", {})\n",
    "#         content = parsed.get(\"content\", \"\").strip()\n",
    "\n",
    "#         # Extract relevant metadata fields\n",
    "#         title = metadata.get(\"title\", \"Unknown\")\n",
    "#         author = metadata.get(\"Author\", \"Unknown\")\n",
    "#         keywords = metadata.get(\"Keywords\", \"\")\n",
    "        \n",
    "#         return title, author, keywords, content\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to extract metadata for file {file_path}: {e}\")\n",
    "#         return \"Unknown\", \"Unknown\", \"\", \"\"\n",
    "\n",
    "# Function to index IPFS content along with Tika metadata\n",
    "# def index_ipfs_content(cid, filename):\n",
    "#     try:\n",
    "#         # Step 1: Download file from IPFS\n",
    "#         file_path = download_file_from_ipfs(cid, filename)\n",
    "#         if not file_path:\n",
    "#             return\n",
    "        \n",
    "#         # Step 2: Extract metadata using Tika\n",
    "#         title, author, keywords, full_text = extract_metadata(file_path)\n",
    "        \n",
    "#         # Step 3: Fetch file stats from IPFS\n",
    "#         stats = client.object.stat(cid)\n",
    "#         file_size = stats['CumulativeSize']\n",
    "\n",
    "#         # Step 4: Get file type (basic MIME type)\n",
    "#         filetype = filename.split(\".\")[-1] if \".\" in filename else \"unknown\"\n",
    "\n",
    "#         # Step 5: Index the content\n",
    "#         writer = ix.writer()\n",
    "#         writer.add_document(\n",
    "#             cid=cid,\n",
    "#             name=filename,\n",
    "#             size=file_size,\n",
    "#             filetype=filetype,\n",
    "#             title=title,\n",
    "#             author=author,\n",
    "#             keywords=keywords,\n",
    "#             full_text=full_text,  # Not stored, just used for searching\n",
    "#         )\n",
    "#         writer.commit()\n",
    "#         print(f\"Indexed {filename} with CID: {cid}, Title: {title}, Author: {author}\")\n",
    "\n",
    "#         # Optionally: Clean up local file\n",
    "#         os.remove(file_path)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to index CID {cid}: {e}\")\n",
    "\n",
    "# # Search IPFS index based on keyword or metadata\n",
    "# def search_ipfs(keyword):\n",
    "#     with ix.searcher() as searcher:\n",
    "#         query = QueryParser(\"full_text\", ix.schema).parse(keyword)\n",
    "#         results = searcher.search(query)\n",
    "#         if results:\n",
    "#             for result in results:\n",
    "#                 print(f\"CID: {result['cid']}, Name: {result['name']}, Title: {result['title']}, Author: {result['author']}, Size: {result['size']} bytes\")\n",
    "#         else:\n",
    "#             print(f\"No results found for '{keyword}'\")\n",
    "\n",
    "# # Example usage: Index some files on your local IPFS node\n",
    "# index_ipfs_content(\"QmXj...\", \"example.txt\")  # Replace with actual CID and filename\n",
    "# index_ipfs_content(\"QmYk...\", \"document.pdf\")  # Replace with actual CID and filename\n",
    "\n",
    "# # Example search\n",
    "# search_ipfs(\"example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e6b78-9d2c-4543-b88c-ba216b3ed596",
   "metadata": {},
   "source": [
    "8 - Query the project account to verify the details update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfac8c-5f92-487a-87fd-067df3e26299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"-\" * 20)\n",
    "\n",
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=project_account['account_id'])\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "data = response.account_detail_response\n",
    "print(f'Project Account id = {project_account}, details = {data.detail}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6ee05-f89d-44ce-aab8-e57b2acff3a4",
   "metadata": {},
   "source": [
    "9 - Read CIDs from Iroha and download file metadata and files from IPFS to the project home directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbac27b-655e-47e9-859a-b88629f5af14",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Platform as \"Platform\"\n",
    "    participant Blockchain as \"Iroha 1 Blockchain\"\n",
    "    participant IPFS as \"Interplanetary File System\"\n",
    "    participant FrontEnd as \"Front End\"\n",
    "       \n",
    "    Note over Platform, Blockchain: Queries the Project Account details and get details\n",
    "    Platform->>Blockchain: Query Project Account Details\n",
    "    Blockchain->>Platform: Query Response\n",
    "\n",
    "    Note over Platform, IPFS: Process project account metadata\n",
    "    Platform->>Platform: Parse Project Details JSON and retrieve file CIDs\n",
    "\n",
    "    Note over Platform, IPFS: Download file from IPFS \n",
    "    Platform->>IPFS: Sends the file CID\n",
    "    IPFS->>Platform: Sends back the file\n",
    "    Platform->>FrontEnd:    Saves the file locally and display info and status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6ca74-7343-4109-b774-0582cb9bab9b",
   "metadata": {},
   "source": [
    "10 - Read details from the project account retrieve the CID of every file, download the it file from IPFS and store locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae73161-a508-408c-81fb-3bb08b13fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipfs_functions import *\n",
    "from clean_file_name import *\n",
    "\n",
    "# Process the account details response\n",
    "account_details_dict = json.loads(data.detail)  # Convert the string to a JSON object\n",
    "ic(account_details_dict)\n",
    "\n",
    "# Get the value of the dictionary (the actual file metadata)\n",
    "files_metadata = account_details_dict['admin@test']\n",
    "ic(files_metadata)\n",
    "\n",
    "for key, value in files_metadata.items():\n",
    "    if 'metadata_CID' not in key:  # Check if this is a file CID\n",
    "        key = '_'.join(key.split('_')[:-1])+\"_CID\"    \n",
    "        # ic(key)\n",
    "        file_CID = value\n",
    "        # ic(value)\n",
    "        \n",
    "    else:\n",
    "        file_metadata_key = '_'.join(key.split('_')[:-2])  # Extract the actual filename from the key\n",
    "        ic(file_metadata_key)\n",
    "        file_metadata_CID = value  # Get the corresponding metadata CID\n",
    "        ic(file_metadata_CID)\n",
    "        # print(f\"Downloading {file_metadata_CID} metadata...\")\n",
    "        file_metadata_json = download_json_from_ipfs(file_metadata_CID)\n",
    "        # ic(file_metadata_json)\n",
    "        if 'resourceName' in file_metadata_json:  # check if key exists in the dictionary\n",
    "            raw_original_file_name = file_metadata_json['resourceName']\n",
    "            ic(raw_original_file_name)\n",
    "            clean_original_file_name = clean_file_name(raw_original_file_name)  # Remove the 'b' prefix and quotes\n",
    "            ic(clean_original_file_name)\n",
    "\n",
    "            # Create a home directory for the user with the account ID as the username under /download/\n",
    "            user_id = project_account['account_id']\n",
    "            download_directory = os.path.join(\"download\", user_id)\n",
    "            if not os.path.exists(download_directory):\n",
    "                os.makedirs(download_directory)  # Create the directory if it doesn't exist\n",
    "\n",
    "            file_path = os.path.join(download_directory, clean_original_file_name)\n",
    "            download_file_from_ipfs(file_CID, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704db6c7-13c4-463a-b329-ce5078c46bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
